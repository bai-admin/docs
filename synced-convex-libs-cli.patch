diff --git a/synced/convex/libs/cli/auth.ts b/synced/convex/libs/cli/auth.ts
new file mode 100644
index 0000000..806a864
--- /dev/null
+++ b/synced/convex/libs/cli/auth.ts
@@ -0,0 +1,55 @@
+import { Command, Option } from "@commander-js/extra-typings";
+import { oneoffContext } from "../bundler/context.js";
+
+const list = new Command("list").action(async () => {
+  const ctx = await oneoffContext({
+    url: undefined,
+    adminKey: undefined,
+    envFile: undefined,
+  });
+  await ctx.crash({
+    exitCode: 1,
+    errorType: "fatal",
+    errForSentry: "Ran deprecated `convex auth list`",
+    printedMessage:
+      "convex auth commands were removed, see https://docs.convex.dev/auth for up to date instructions.",
+  });
+});
+
+const rm = new Command("remove").action(async () => {
+  const ctx = await oneoffContext({
+    url: undefined,
+    adminKey: undefined,
+    envFile: undefined,
+  });
+  await ctx.crash({
+    exitCode: 1,
+    errorType: "fatal",
+    errForSentry: "Ran deprecated `convex auth remove`",
+    printedMessage:
+      "convex auth commands were removed, see https://docs.convex.dev/auth for up to date instructions.",
+  });
+});
+
+const add = new Command("add")
+  .addOption(new Option("--identity-provider-url <url>").hideHelp())
+  .addOption(new Option("--application-id <applicationId>").hideHelp())
+  .action(async () => {
+    const ctx = await oneoffContext({
+      url: undefined,
+      adminKey: undefined,
+      envFile: undefined,
+    });
+    await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      errForSentry: "Ran deprecated `convex auth add`",
+      printedMessage:
+        "convex auth commands were removed, see https://docs.convex.dev/auth for up to date instructions.",
+    });
+  });
+
+export const auth = new Command("auth")
+  .addCommand(list)
+  .addCommand(rm)
+  .addCommand(add);
diff --git a/synced/convex/libs/cli/codegen.ts b/synced/convex/libs/cli/codegen.ts
new file mode 100644
index 0000000..6455128
--- /dev/null
+++ b/synced/convex/libs/cli/codegen.ts
@@ -0,0 +1,52 @@
+import { Command, Option } from "@commander-js/extra-typings";
+import { oneoffContext } from "../bundler/context.js";
+import { runCodegen } from "./lib/components.js";
+import { getDeploymentSelection } from "./lib/deploymentSelection.js";
+export const codegen = new Command("codegen")
+  .summary("Generate backend type definitions")
+  .description(
+    "Generate types in `convex/_generated/` based on the current contents of `convex/`.",
+  )
+  .allowExcessArguments(false)
+  .option(
+    "--dry-run",
+    "Print out the generated configuration to stdout instead of writing to convex directory",
+  )
+  .addOption(new Option("--debug").hideHelp())
+  .addOption(
+    new Option(
+      "--typecheck <mode>",
+      `Whether to check TypeScript files with \`tsc --noEmit\`.`,
+    )
+      .choices(["enable", "try", "disable"] as const)
+      .default("try" as const),
+  )
+  .option(
+    "--init",
+    "Also (over-)write the default convex/README.md and convex/tsconfig.json files, otherwise only written when creating a new Convex project.",
+  )
+  .addOption(new Option("--admin-key <adminKey>").hideHelp())
+  .addOption(new Option("--url <url>").hideHelp())
+  .addOption(new Option("--live-component-sources").hideHelp())
+  // Experimental option
+  .addOption(
+    new Option(
+      "--commonjs",
+      "Generate CommonJS modules (CJS) instead of ECMAScript modules, the default. Bundlers typically take care of this conversion while bundling, so this setting is generally only useful for projects which do not use a bundler, typically Node.js projects. Convex functions can be written with either syntax.",
+    ).hideHelp(),
+  )
+  .action(async (options) => {
+    const ctx = await oneoffContext(options);
+    const deploymentSelection = await getDeploymentSelection(ctx, options);
+
+    await runCodegen(ctx, deploymentSelection, {
+      dryRun: !!options.dryRun,
+      debug: !!options.debug,
+      typecheck: options.typecheck,
+      init: !!options.init,
+      commonjs: !!options.commonjs,
+      url: options.url,
+      adminKey: options.adminKey,
+      liveComponentSources: !!options.liveComponentSources,
+    });
+  });
diff --git a/synced/convex/libs/cli/codegen_templates/api.test.ts b/synced/convex/libs/cli/codegen_templates/api.test.ts
new file mode 100644
index 0000000..05884e0
--- /dev/null
+++ b/synced/convex/libs/cli/codegen_templates/api.test.ts
@@ -0,0 +1,18 @@
+import { test, expect } from "vitest";
+import { importPath, moduleIdentifier } from "./api.js";
+
+test("importPath", () => {
+  expect(importPath("foo.ts")).toEqual("foo");
+  expect(importPath("foo.tsx")).toEqual("foo");
+  expect(importPath("foo\\bar.ts")).toEqual("foo/bar");
+  expect(importPath("foo/bar.ts")).toEqual("foo/bar");
+});
+
+test("moduleIdentifier", () => {
+  expect(moduleIdentifier("foo.ts")).toEqual("foo");
+  // This mapping is ambiguous! This is a codegen implementation detail so
+  // this can be changed without requiring changes beyond running codegen.
+  expect(moduleIdentifier("foo/bar.ts")).toEqual("foo_bar");
+  expect(moduleIdentifier("foo_bar.ts")).toEqual("foo_bar");
+  expect(moduleIdentifier("foo-bar.ts")).toEqual("foo_bar");
+});
diff --git a/synced/convex/libs/cli/codegen_templates/api.ts b/synced/convex/libs/cli/codegen_templates/api.ts
new file mode 100644
index 0000000..72d1dc9
--- /dev/null
+++ b/synced/convex/libs/cli/codegen_templates/api.ts
@@ -0,0 +1,74 @@
+import { header } from "./common.js";
+
+export function importPath(modulePath: string) {
+  // Replace backslashes with forward slashes.
+  const filePath = modulePath.replace(/\\/g, "/");
+  // Strip off the file extension.
+  const lastDot = filePath.lastIndexOf(".");
+  return filePath.slice(0, lastDot === -1 ? undefined : lastDot);
+}
+
+export function moduleIdentifier(modulePath: string) {
+  // TODO: This encoding is ambiguous (`foo/bar` vs `foo_bar` vs `foo-bar`).
+  // Also we should be renaming keywords like `delete`.
+  let safeModulePath = importPath(modulePath)
+    .replace(/\//g, "_")
+    .replace(/-/g, "_");
+  // Escape existing variable names in this file
+  if (["fullApi", "api", "internal", "components"].includes(safeModulePath)) {
+    safeModulePath = `${safeModulePath}_`;
+  }
+  return safeModulePath;
+}
+
+export function apiCodegen(modulePaths: string[]) {
+  const apiDTS = `${header("Generated `api` utility.")}
+  import type { ApiFromModules, FilterApi, FunctionReference } from "convex/server";
+  ${modulePaths
+    .map(
+      (modulePath) =>
+        `import type * as ${moduleIdentifier(modulePath)} from "../${importPath(
+          modulePath,
+        )}.js";`,
+    )
+    .join("\n")}
+
+  /**
+   * A utility for referencing Convex functions in your app's API.
+   *
+   * Usage:
+   * \`\`\`js
+   * const myFunctionReference = api.myModule.myFunction;
+   * \`\`\`
+   */
+  declare const fullApi: ApiFromModules<{
+    ${modulePaths
+      .map(
+        (modulePath) =>
+          `"${importPath(modulePath)}": typeof ${moduleIdentifier(modulePath)},`,
+      )
+      .join("\n")}
+  }>;
+  export declare const api: FilterApi<typeof fullApi, FunctionReference<any, "public">>;
+  export declare const internal: FilterApi<typeof fullApi, FunctionReference<any, "internal">>;
+  `;
+
+  const apiJS = `${header("Generated `api` utility.")}
+  import { anyApi } from "convex/server";
+
+  /**
+   * A utility for referencing Convex functions in your app's API.
+   *
+   * Usage:
+   * \`\`\`js
+   * const myFunctionReference = api.myModule.myFunction;
+   * \`\`\`
+   */
+  export const api = anyApi;
+  export const internal = anyApi;
+  `;
+  return {
+    DTS: apiDTS,
+    JS: apiJS,
+  };
+}
diff --git a/synced/convex/libs/cli/codegen_templates/api_cjs.ts b/synced/convex/libs/cli/codegen_templates/api_cjs.ts
new file mode 100644
index 0000000..863f231
--- /dev/null
+++ b/synced/convex/libs/cli/codegen_templates/api_cjs.ts
@@ -0,0 +1,17 @@
+import { apiCodegen as esmApiCodegen } from "./api.js";
+import { header } from "./common.js";
+
+export function apiCjsCodegen(modulePaths: string[]) {
+  const { DTS } = esmApiCodegen(modulePaths);
+  const apiJS = `${header("Generated `api` utility.")}
+  const { anyApi } = require("convex/server");
+  module.exports = {
+    api: anyApi,
+    internal: anyApi,
+  };
+  `;
+  return {
+    DTS,
+    JS: apiJS,
+  };
+}
diff --git a/synced/convex/libs/cli/codegen_templates/common.ts b/synced/convex/libs/cli/codegen_templates/common.ts
new file mode 100644
index 0000000..0c38103
--- /dev/null
+++ b/synced/convex/libs/cli/codegen_templates/common.ts
@@ -0,0 +1,12 @@
+export function header(oneLineDescription: string) {
+  return `/* eslint-disable */
+  /**
+   * ${oneLineDescription}
+   *
+   * THIS CODE IS AUTOMATICALLY GENERATED.
+   *
+   * To regenerate, run \`npx convex dev\`.
+   * @module
+   */
+  `;
+}
diff --git a/synced/convex/libs/cli/codegen_templates/component_api.ts b/synced/convex/libs/cli/codegen_templates/component_api.ts
new file mode 100644
index 0000000..1587037
--- /dev/null
+++ b/synced/convex/libs/cli/codegen_templates/component_api.ts
@@ -0,0 +1,575 @@
+import path from "path";
+import { Context } from "../../bundler/context.js";
+import { entryPoints } from "../../bundler/index.js";
+import {
+  ComponentDirectory,
+  toComponentDefinitionPath,
+} from "../lib/components/definition/directoryStructure.js";
+import { StartPushResponse } from "../lib/deployApi/startPush.js";
+import { importPath, moduleIdentifier } from "./api.js";
+import { header } from "./common.js";
+import {
+  ComponentExports,
+  EvaluatedComponentDefinition,
+} from "../lib/deployApi/componentDefinition.js";
+import { ComponentDefinitionPath } from "../lib/deployApi/paths.js";
+import { Identifier, Reference } from "../lib/deployApi/types.js";
+import { CanonicalizedModulePath } from "../lib/deployApi/paths.js";
+import {
+  AnalyzedFunction,
+  AnalyzedModule,
+  Visibility,
+} from "../lib/deployApi/modules.js";
+import { parseValidator, validatorToType } from "./validator_helpers.js";
+
+export function componentApiJs() {
+  const lines = [];
+  lines.push(header("Generated `api` utility."));
+  lines.push(`
+    import { anyApi, componentsGeneric } from "convex/server";
+
+    /**
+     * A utility for referencing Convex functions in your app's API.
+     *
+     * Usage:
+     * \`\`\`js
+     * const myFunctionReference = api.myModule.myFunction;
+     * \`\`\`
+     */
+    export const api = anyApi;
+    export const internal = anyApi;
+    export const components = componentsGeneric();
+  `);
+  return lines.join("\n");
+}
+
+export function rootComponentApiCJS() {
+  const lines = [];
+  lines.push(header("Generated `api` utility."));
+  lines.push(`const { anyApi } = require("convex/server");`);
+  lines.push(`module.exports = {
+    api: anyApi,
+    internal: anyApi,
+  };`);
+  return lines.join("\n");
+}
+
+export function componentApiStubDTS() {
+  const lines = [];
+  lines.push(header("Generated `api` utility."));
+  lines.push(`import type { AnyApi, AnyComponents } from "convex/server";`);
+  lines.push(`
+    export declare const api: AnyApi;
+    export declare const internal: AnyApi;
+    export declare const components: AnyComponents;
+  `);
+
+  return lines.join("\n");
+}
+
+export async function componentApiDTS(
+  ctx: Context,
+  startPush: StartPushResponse,
+  rootComponent: ComponentDirectory,
+  componentDirectory: ComponentDirectory,
+  opts: { staticApi: boolean },
+) {
+  const definitionPath = toComponentDefinitionPath(
+    rootComponent,
+    componentDirectory,
+  );
+
+  const analysis = startPush.analysis[definitionPath];
+  if (!analysis) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: `No analysis found for component ${definitionPath} orig: ${definitionPath}\nin\n${Object.keys(startPush.analysis).toString()}`,
+    });
+  }
+
+  const lines = [];
+  lines.push(header("Generated `api` utility."));
+  let apiLines: AsyncGenerator<string>;
+  if (opts.staticApi) {
+    apiLines = codegenStaticApiObjects(ctx, analysis);
+  } else {
+    apiLines = codegenDynamicApiObjects(
+      ctx,
+      componentDirectory,
+      startPush,
+      definitionPath,
+    );
+  }
+  for await (const line of apiLines) {
+    lines.push(line);
+  }
+
+  lines.push(`
+  export declare const components: {`);
+  for (const childComponent of analysis.definition.childComponents) {
+    const childComponentAnalysis = startPush.analysis[childComponent.path];
+    if (!childComponentAnalysis) {
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage: `No analysis found for child component ${childComponent.path}`,
+      });
+    }
+    for await (const line of codegenExports(
+      ctx,
+      childComponent.name,
+      childComponentAnalysis,
+    )) {
+      lines.push(line);
+    }
+  }
+
+  lines.push("};");
+
+  return lines.join("\n");
+}
+
+async function* codegenStaticApiObjects(
+  ctx: Context,
+  analysis: EvaluatedComponentDefinition,
+) {
+  yield `import type { FunctionReference } from "convex/server";`;
+
+  const apiTree = await buildApiTree(ctx, analysis.functions, {
+    kind: "public",
+  });
+  yield `
+  /**
+   * A utility for referencing Convex functions in your app's public API.
+   *
+   * Usage:
+   * \`\`\`js
+   * const myFunctionReference = api.myModule.myFunction;
+   * \`\`\`
+   */`;
+  yield `export declare const api:`;
+  yield* codegenApiTree(ctx, apiTree);
+  yield ";";
+
+  yield `
+  /**
+   * A utility for referencing Convex functions in your app's internal API.
+   *
+   * Usage:
+   * \`\`\`js
+   * const myFunctionReference = internal.myModule.myFunction;
+   * \`\`\`
+   */`;
+  const internalTree = await buildApiTree(ctx, analysis.functions, {
+    kind: "internal",
+  });
+  yield `export declare const internal:`;
+  yield* codegenApiTree(ctx, internalTree);
+  yield ";";
+}
+
+async function* codegenDynamicApiObjects(
+  ctx: Context,
+  componentDirectory: ComponentDirectory,
+  startPush: StartPushResponse,
+  definitionPath: ComponentDefinitionPath,
+) {
+  const absModulePaths = await entryPoints(ctx, componentDirectory.path);
+  const modulePaths = absModulePaths.map((p) =>
+    path.relative(componentDirectory.path, p),
+  );
+  for (const modulePath of modulePaths) {
+    const ident = moduleIdentifier(modulePath);
+    const path = importPath(modulePath);
+    yield `import type * as ${ident} from "../${path}.js";`;
+  }
+  yield `
+    import type {
+      ApiFromModules,
+      FilterApi,
+      FunctionReference,
+    } from "convex/server";
+
+    /**
+     * A utility for referencing Convex functions in your app's API.
+     *
+     * Usage:
+     * \`\`\`js
+     * const myFunctionReference = api.myModule.myFunction;
+     * \`\`\`
+     */
+    declare const fullApi: ApiFromModules<{
+  `;
+  for (const modulePath of modulePaths) {
+    const ident = moduleIdentifier(modulePath);
+    const path = importPath(modulePath);
+    yield `  "${path}": typeof ${ident},`;
+  }
+  yield `}>;`;
+  yield* codegenApiWithMounts(ctx, startPush, definitionPath);
+  yield `
+    export declare const api: FilterApi<typeof fullApiWithMounts, FunctionReference<any, "public">>;
+    export declare const internal: FilterApi<typeof fullApiWithMounts, FunctionReference<any, "internal">>;
+  `;
+}
+
+interface ApiTree {
+  [identifier: string]:
+    | { type: "branch"; branch: ApiTree }
+    | { type: "leaf"; leaf: AnalyzedFunction };
+}
+
+async function buildApiTree(
+  ctx: Context,
+  functions: Record<CanonicalizedModulePath, AnalyzedModule>,
+  visibility: Visibility,
+): Promise<ApiTree> {
+  const root: ApiTree = {};
+  for (const [modulePath, module] of Object.entries(functions)) {
+    const p = importPath(modulePath);
+    if (p.startsWith("_deps/")) {
+      continue;
+    }
+    for (const f of module.functions) {
+      if (f.visibility?.kind !== visibility.kind) {
+        continue;
+      }
+      let current = root;
+      for (const pathComponent of p.split("/")) {
+        let next = current[pathComponent];
+        if (!next) {
+          next = { type: "branch", branch: {} };
+          current[pathComponent] = next;
+        }
+        if (next.type === "leaf") {
+          return await ctx.crash({
+            exitCode: 1,
+            errorType: "fatal",
+            printedMessage: `Ambiguous function name: ${f.name} in ${modulePath}`,
+          });
+        }
+        current = next.branch;
+      }
+      if (current[f.name]) {
+        return await ctx.crash({
+          exitCode: 1,
+          errorType: "fatal",
+          printedMessage: `Duplicate function name: ${f.name} in ${modulePath}`,
+        });
+      }
+      current[f.name] = { type: "leaf", leaf: f };
+    }
+  }
+  return root;
+}
+
+async function* codegenApiTree(
+  ctx: Context,
+  tree: ApiTree,
+): AsyncGenerator<string> {
+  yield "{";
+  for (const [identifier, subtree] of Object.entries(tree)) {
+    if (subtree.type === "branch") {
+      yield `"${identifier}":`;
+      yield* codegenApiTree(ctx, subtree.branch);
+      yield ",";
+    } else {
+      const visibility = subtree.leaf.visibility?.kind;
+      if (!visibility) {
+        return await ctx.crash({
+          exitCode: 1,
+          errorType: "fatal",
+          printedMessage: `Function ${subtree.leaf.name} has no visibility`,
+        });
+      }
+      const ref = await codegenFunctionReference(
+        ctx,
+        subtree.leaf,
+        visibility,
+        true,
+      );
+      yield `"${identifier}": ${ref},`;
+    }
+  }
+  yield "}";
+}
+
+async function* codegenApiWithMounts(
+  ctx: Context,
+  startPush: StartPushResponse,
+  definitionPath: ComponentDefinitionPath,
+): AsyncGenerator<string> {
+  const mountTree = await buildMountTree(ctx, startPush, definitionPath, []);
+  if (mountTree) {
+    yield "export type Mounts = ";
+    yield* codegenMountTree(mountTree);
+    yield `;`;
+    yield `// For now fullApiWithMounts is only fullApi which provides`;
+    yield `// jump-to-definition in component client code.`;
+    yield `// Use Mounts for the same type without the inference.`;
+    yield "declare const fullApiWithMounts: typeof fullApi;";
+  } else {
+    yield "declare const fullApiWithMounts: typeof fullApi;";
+  }
+}
+
+function* codegenMountTree(tree: MountTree): Generator<string> {
+  yield `{`;
+  for (const [identifier, subtree] of Object.entries(tree)) {
+    if (typeof subtree === "string") {
+      yield `"${identifier}": ${subtree},`;
+    } else {
+      yield `"${identifier}":`;
+      yield* codegenMountTree(subtree);
+      yield `,`;
+    }
+  }
+  yield `}`;
+}
+
+interface MountTree {
+  [identifier: string]: MountTree | string;
+}
+
+async function buildMountTree(
+  ctx: Context,
+  startPush: StartPushResponse,
+  definitionPath: ComponentDefinitionPath,
+  attributes: string[],
+): Promise<MountTree | null> {
+  // TODO make these types more precise when receiving analysis from server
+  const analysis = startPush.analysis[definitionPath];
+  if (!analysis) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: `No analysis found for component ${definitionPath} orig: ${definitionPath}\nin\n${Object.keys(startPush.analysis).toString()}`,
+    });
+  }
+  let current = analysis.definition.exports.branch;
+  for (const attribute of attributes) {
+    const componentExport = current.find(
+      ([identifier]) => identifier === attribute,
+    );
+    if (!componentExport) {
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage: `No export found for ${attribute}`,
+      });
+    }
+    const [_, node] = componentExport;
+    if (node.type !== "branch") {
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage: `Expected branch at ${attribute}`,
+      });
+    }
+    current = node.branch;
+  }
+  return buildComponentMountTree(ctx, startPush, analysis, current);
+}
+
+async function buildComponentMountTree(
+  ctx: Context,
+  startPush: StartPushResponse,
+  analysis: EvaluatedComponentDefinition,
+  exports: Array<[Identifier, ComponentExports]>,
+): Promise<MountTree | null> {
+  const result: MountTree = {};
+  let nonEmpty = false;
+  for (const [identifier, componentExport] of exports) {
+    if (componentExport.type === "leaf") {
+      // If we're at a child component reference, follow it and build its export tree.
+      if (componentExport.leaf.startsWith("_reference/childComponent/")) {
+        const suffix = componentExport.leaf.slice(
+          "_reference/childComponent/".length,
+        );
+        const [componentName, ...attributes] = suffix.split("/");
+        const childComponent = analysis.definition.childComponents.find(
+          (c) => c.name === componentName,
+        );
+        if (!childComponent) {
+          return await ctx.crash({
+            exitCode: 1,
+            errorType: "fatal",
+            printedMessage: `No child component found for ${componentName}`,
+          });
+        }
+        const childTree = await buildMountTree(
+          ctx,
+          startPush,
+          childComponent.path,
+          attributes,
+        );
+        if (childTree) {
+          result[identifier] = childTree;
+          nonEmpty = true;
+        }
+      }
+      // If we're at a function reference outside the root, codegen it as a leaf.
+      const isRoot = analysis.definition.definitionType.type === "app";
+      if (!isRoot && componentExport.leaf.startsWith("_reference/function/")) {
+        const leaf = await resolveFunctionReference(
+          ctx,
+          analysis,
+          componentExport.leaf,
+          "public",
+        );
+        result[identifier] = leaf;
+        nonEmpty = true;
+      }
+    } else {
+      const subTree = await buildComponentMountTree(
+        ctx,
+        startPush,
+        analysis,
+        componentExport.branch,
+      );
+      if (subTree) {
+        result[identifier] = subTree;
+        nonEmpty = true;
+      }
+    }
+  }
+  return nonEmpty ? result : null;
+}
+
+async function* codegenExports(
+  ctx: Context,
+  name: Identifier,
+  analysis: EvaluatedComponentDefinition,
+): AsyncGenerator<string> {
+  yield `${name}: {`;
+  for (const [name, componentExport] of analysis.definition.exports.branch) {
+    yield `${name}:`;
+    yield* codegenExport(ctx, analysis, componentExport);
+    yield ",";
+  }
+  yield "},";
+}
+
+async function* codegenExport(
+  ctx: Context,
+  analysis: EvaluatedComponentDefinition,
+  componentExport: ComponentExports,
+): AsyncGenerator<string> {
+  if (componentExport.type === "leaf") {
+    yield await resolveFunctionReference(
+      ctx,
+      analysis,
+      componentExport.leaf,
+      "internal",
+    );
+  } else if (componentExport.type === "branch") {
+    yield "{";
+    for (const [name, childExport] of componentExport.branch) {
+      yield `${name}:`;
+      yield* codegenExport(ctx, analysis, childExport);
+      yield ",";
+    }
+    yield "}";
+  }
+}
+
+export async function resolveFunctionReference(
+  ctx: Context,
+  analysis: EvaluatedComponentDefinition,
+  reference: Reference,
+  visibility: "public" | "internal",
+) {
+  if (!reference.startsWith("_reference/function/")) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: `Invalid function reference: ${reference}`,
+    });
+  }
+  const udfPath = reference.slice("_reference/function/".length);
+
+  const [modulePath, functionName] = udfPath.split(":");
+  const canonicalizedModulePath = canonicalizeModulePath(modulePath);
+
+  const analyzedModule = analysis.functions[canonicalizedModulePath];
+  if (!analyzedModule) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: `Module not found: ${modulePath}`,
+    });
+  }
+  const analyzedFunction = analyzedModule.functions.find(
+    (f) => f.name === functionName,
+  );
+  if (!analyzedFunction) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: `Function not found: ${functionName}`,
+    });
+  }
+  return await codegenFunctionReference(
+    ctx,
+    analyzedFunction,
+    visibility,
+    false,
+  );
+}
+
+async function codegenFunctionReference(
+  ctx: Context,
+  analyzedFunction: AnalyzedFunction,
+  visibility: "public" | "internal",
+  useIdType: boolean,
+): Promise<string> {
+  // The server sends down `udfType` capitalized.
+  const udfType = analyzedFunction.udfType.toLowerCase();
+
+  let argsType = "any";
+  try {
+    const argsValidator = parseValidator(analyzedFunction.args);
+    if (argsValidator) {
+      if (argsValidator.type === "object" || argsValidator.type === "any") {
+        argsType = validatorToType(argsValidator, useIdType);
+      } else {
+        // eslint-disable-next-line no-restricted-syntax
+        throw new Error(
+          `Unexpected argument validator type: ${argsValidator.type}`,
+        );
+      }
+    }
+  } catch (e) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: `Invalid function args: ${analyzedFunction.args}`,
+      errForSentry: e,
+    });
+  }
+
+  let returnsType = "any";
+  try {
+    const returnsValidator = parseValidator(analyzedFunction.returns);
+    if (returnsValidator) {
+      returnsType = validatorToType(returnsValidator, useIdType);
+    }
+  } catch (e) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: `Invalid function returns: ${analyzedFunction.returns}`,
+      errForSentry: e,
+    });
+  }
+
+  return `FunctionReference<"${udfType}", "${visibility}", ${argsType}, ${returnsType}>`;
+}
+
+function canonicalizeModulePath(modulePath: string): CanonicalizedModulePath {
+  if (!modulePath.endsWith(".js")) {
+    return modulePath + ".js";
+  }
+  return modulePath;
+}
diff --git a/synced/convex/libs/cli/codegen_templates/component_server.ts b/synced/convex/libs/cli/codegen_templates/component_server.ts
new file mode 100644
index 0000000..302445e
--- /dev/null
+++ b/synced/convex/libs/cli/codegen_templates/component_server.ts
@@ -0,0 +1,246 @@
+import { ComponentDirectory } from "../lib/components/definition/directoryStructure.js";
+import { header } from "./common.js";
+
+export function componentServerJS(): string {
+  const result = `
+  ${header(
+    "Generated utilities for implementing server-side Convex query and mutation functions.",
+  )}
+  import {
+    actionGeneric,
+    httpActionGeneric,
+    queryGeneric,
+    mutationGeneric,
+    internalActionGeneric,
+    internalMutationGeneric,
+    internalQueryGeneric,
+    componentsGeneric,
+  } from "convex/server";
+
+  /**
+   * Define a query in this Convex app's public API.
+   *
+   * This function will be allowed to read your Convex database and will be accessible from the client.
+   *
+   * @param func - The query function. It receives a {@link QueryCtx} as its first argument.
+   * @returns The wrapped query. Include this as an \`export\` to name it and make it accessible.
+   */
+  export const query = queryGeneric;
+
+  /**
+   * Define a query that is only accessible from other Convex functions (but not from the client).
+   *
+   * This function will be allowed to read from your Convex database. It will not be accessible from the client.
+   *
+   * @param func - The query function. It receives a {@link QueryCtx} as its first argument.
+   * @returns The wrapped query. Include this as an \`export\` to name it and make it accessible.
+   */
+  export const internalQuery = internalQueryGeneric;
+
+  /**
+   * Define a mutation in this Convex app's public API.
+   *
+   * This function will be allowed to modify your Convex database and will be accessible from the client.
+   *
+   * @param func - The mutation function. It receives a {@link MutationCtx} as its first argument.
+   * @returns The wrapped mutation. Include this as an \`export\` to name it and make it accessible.
+   */
+  export const mutation = mutationGeneric;
+
+  /**
+   * Define a mutation that is only accessible from other Convex functions (but not from the client).
+   *
+   * This function will be allowed to modify your Convex database. It will not be accessible from the client.
+   *
+   * @param func - The mutation function. It receives a {@link MutationCtx} as its first argument.
+   * @returns The wrapped mutation. Include this as an \`export\` to name it and make it accessible.
+   */
+  export const internalMutation = internalMutationGeneric;
+
+  /**
+   * Define an action in this Convex app's public API.
+   *
+   * An action is a function which can execute any JavaScript code, including non-deterministic
+   * code and code with side-effects, like calling third-party services.
+   * They can be run in Convex's JavaScript environment or in Node.js using the "use node" directive.
+   * They can interact with the database indirectly by calling queries and mutations using the {@link ActionCtx}.
+   *
+   * @param func - The action. It receives an {@link ActionCtx} as its first argument.
+   * @returns The wrapped action. Include this as an \`export\` to name it and make it accessible.
+   */
+  export const action = actionGeneric;
+
+  /**
+   * Define an action that is only accessible from other Convex functions (but not from the client).
+   *
+   * @param func - The function. It receives an {@link ActionCtx} as its first argument.
+   * @returns The wrapped function. Include this as an \`export\` to name it and make it accessible.
+   */
+  export const internalAction = internalActionGeneric;
+
+  /**
+   * Define a Convex HTTP action.
+   *
+   * @param func - The function. It receives an {@link ActionCtx} as its first argument, and a \`Request\` object
+   * as its second.
+   * @returns The wrapped endpoint function. Route a URL path to this function in \`convex/http.js\`.
+   */
+  export const httpAction = httpActionGeneric;
+  `;
+  return result;
+}
+
+function componentServerDTSPrelude(_isRoot: boolean): string {
+  return `
+    ${header(
+      "Generated utilities for implementing server-side Convex query and mutation functions.",
+    )}
+    import {
+      ActionBuilder,
+      AnyComponents,
+      HttpActionBuilder,
+      MutationBuilder,
+      QueryBuilder,
+      GenericActionCtx,
+      GenericMutationCtx,
+      GenericQueryCtx,
+      GenericDatabaseReader,
+      GenericDatabaseWriter,
+      FunctionReference,
+    } from "convex/server";
+    import type { DataModel } from "./dataModel.js";
+
+    type GenericCtx = GenericActionCtx<DataModel> | GenericMutationCtx<DataModel> | GenericQueryCtx<DataModel>;
+
+    /**
+     * Define a query in this Convex app's public API.
+     *
+     * This function will be allowed to read your Convex database and will be accessible from the client.
+     *
+     * @param func - The query function. It receives a {@link QueryCtx} as its first argument.
+     * @returns The wrapped query. Include this as an \`export\` to name it and make it accessible.
+     */
+    export declare const query: QueryBuilder<DataModel, "public">;
+
+    /**
+     * Define a query that is only accessible from other Convex functions (but not from the client).
+     *
+     * This function will be allowed to read from your Convex database. It will not be accessible from the client.
+     *
+     * @param func - The query function. It receives a {@link QueryCtx} as its first argument.
+     * @returns The wrapped query. Include this as an \`export\` to name it and make it accessible.
+     */
+    export declare const internalQuery: QueryBuilder<DataModel, "internal">;
+
+    /**
+     * Define a mutation in this Convex app's public API.
+     *
+     * This function will be allowed to modify your Convex database and will be accessible from the client.
+     *
+     * @param func - The mutation function. It receives a {@link MutationCtx} as its first argument.
+     * @returns The wrapped mutation. Include this as an \`export\` to name it and make it accessible.
+     */
+    export declare const mutation: MutationBuilder<DataModel, "public">;
+
+    /**
+     * Define a mutation that is only accessible from other Convex functions (but not from the client).
+     *
+     * This function will be allowed to modify your Convex database. It will not be accessible from the client.
+     *
+     * @param func - The mutation function. It receives a {@link MutationCtx} as its first argument.
+     * @returns The wrapped mutation. Include this as an \`export\` to name it and make it accessible.
+     */
+    export declare const internalMutation: MutationBuilder<DataModel, "internal">;
+
+    /**
+     * Define an action in this Convex app's public API.
+     *
+     * An action is a function which can execute any JavaScript code, including non-deterministic
+     * code and code with side-effects, like calling third-party services.
+     * They can be run in Convex's JavaScript environment or in Node.js using the "use node" directive.
+     * They can interact with the database indirectly by calling queries and mutations using the {@link ActionCtx}.
+     *
+     * @param func - The action. It receives an {@link ActionCtx} as its first argument.
+     * @returns The wrapped action. Include this as an \`export\` to name it and make it accessible.
+     */
+    export declare const action: ActionBuilder<DataModel, "public">;
+
+    /**
+     * Define an action that is only accessible from other Convex functions (but not from the client).
+     *
+     * @param func - The function. It receives an {@link ActionCtx} as its first argument.
+     * @returns The wrapped function. Include this as an \`export\` to name it and make it accessible.
+     */
+    export declare const internalAction: ActionBuilder<DataModel, "internal">;
+
+    /**
+     * Define an HTTP action.
+     *
+     * This function will be used to respond to HTTP requests received by a Convex
+     * deployment if the requests matches the path and method where this action
+     * is routed. Be sure to route your action in \`convex/http.js\`.
+     *
+     * @param func - The function. It receives an {@link ActionCtx} as its first argument.
+     * @returns The wrapped function. Import this function from \`convex/http.js\` and route it to hook it up.
+     */
+    export declare const httpAction: HttpActionBuilder;
+
+    /**
+     * A set of services for use within Convex query functions.
+     *
+     * The query context is passed as the first argument to any Convex query
+     * function run on the server.
+     *
+     * This differs from the {@link MutationCtx} because all of the services are
+     * read-only.
+     */
+    export type QueryCtx = GenericQueryCtx<DataModel>;
+
+    /**
+     * A set of services for use within Convex mutation functions.
+     *
+     * The mutation context is passed as the first argument to any Convex mutation
+     * function run on the server.
+     */
+    export type MutationCtx = GenericMutationCtx<DataModel>;
+
+    /**
+     * A set of services for use within Convex action functions.
+     *
+     * The action context is passed as the first argument to any Convex action
+     * function run on the server.
+     */
+    export type ActionCtx = GenericActionCtx<DataModel>;
+
+    /**
+     * An interface to read from the database within Convex query functions.
+     *
+     * The two entry points are {@link DatabaseReader.get}, which fetches a single
+     * document by its {@link Id}, or {@link DatabaseReader.query}, which starts
+     * building a query.
+     */
+    export type DatabaseReader = GenericDatabaseReader<DataModel>;
+
+    /**
+     * An interface to read from and write to the database within Convex mutation
+     * functions.
+     *
+     * Convex guarantees that all writes within a single mutation are
+     * executed atomically, so you never have to worry about partial writes leaving
+     * your data in an inconsistent state. See [the Convex Guide](https://docs.convex.dev/understanding/convex-fundamentals/functions#atomicity-and-optimistic-concurrency-control)
+     * for the guarantees Convex provides your functions.
+     */
+    export type DatabaseWriter = GenericDatabaseWriter<DataModel>;
+  `;
+}
+
+export function componentServerStubDTS(isRoot: boolean): string {
+  return componentServerDTSPrelude(isRoot);
+}
+
+export async function componentServerDTS(
+  componentDirectory: ComponentDirectory,
+): Promise<string> {
+  const result = [componentServerDTSPrelude(componentDirectory.isRoot)];
+  return result.join("\n");
+}
diff --git a/synced/convex/libs/cli/codegen_templates/dataModel.ts b/synced/convex/libs/cli/codegen_templates/dataModel.ts
new file mode 100644
index 0000000..b9b9dec
--- /dev/null
+++ b/synced/convex/libs/cli/codegen_templates/dataModel.ts
@@ -0,0 +1,364 @@
+import { Context } from "../../bundler/context.js";
+import { SystemIndexes } from "../../server/system_fields.js";
+import {
+  ComponentDirectory,
+  toComponentDefinitionPath,
+} from "../lib/components/definition/directoryStructure.js";
+import {
+  AnalyzedSchema,
+  TableDefinition,
+} from "../lib/deployApi/componentDefinition.js";
+import { StartPushResponse } from "../lib/deployApi/startPush.js";
+import { ConvexValidator } from "../lib/deployApi/validator.js";
+import { header } from "./common.js";
+import { validatorToType } from "./validator_helpers.js";
+
+export function noSchemaDataModelDTS() {
+  return `
+  ${header("Generated data model types.")}
+  import { AnyDataModel } from "convex/server";
+  import type { GenericId } from "convex/values";
+
+  /**
+   * No \`schema.ts\` file found!
+   *
+   * This generated code has permissive types like \`Doc = any\` because
+   * Convex doesn't know your schema. If you'd like more type safety, see
+   * https://docs.convex.dev/using/schemas for instructions on how to add a
+   * schema file.
+   *
+   * After you change a schema, rerun codegen with \`npx convex dev\`.
+   */
+
+  /**
+   * The names of all of your Convex tables.
+   */
+  export type TableNames = string;
+
+  /**
+   * The type of a document stored in Convex.
+   */
+  export type Doc = any;
+
+  /**
+   * An identifier for a document in Convex.
+   *
+   * Convex documents are uniquely identified by their \`Id\`, which is accessible
+   * on the \`_id\` field. To learn more, see [Document IDs](https://docs.convex.dev/using/document-ids).
+   *
+   * Documents can be loaded using \`db.get(id)\` in query and mutation functions.
+   *
+   * IDs are just strings at runtime, but this type can be used to distinguish them from other
+   * strings when type checking.
+   */
+  export type Id<TableName extends TableNames = TableNames> = GenericId<TableName>;
+
+  /**
+   * A type describing your Convex data model.
+   *
+   * This type includes information about what tables you have, the type of
+   * documents stored in those tables, and the indexes defined on them.
+   *
+   * This type is used to parameterize methods like \`queryGeneric\` and
+   * \`mutationGeneric\` to make them type-safe.
+   */
+  export type DataModel = AnyDataModel;`;
+}
+
+export function dynamicDataModelDTS() {
+  return `
+  ${header("Generated data model types.")}
+  import type { DataModelFromSchemaDefinition, DocumentByName, TableNamesInDataModel, SystemTableNames } from "convex/server";
+  import type { GenericId } from "convex/values";
+  import schema from "../schema.js";
+
+  /**
+   * The names of all of your Convex tables.
+   */
+  export type TableNames = TableNamesInDataModel<DataModel>;
+
+  /**
+   * The type of a document stored in Convex.
+   *
+   * @typeParam TableName - A string literal type of the table name (like "users").
+   */
+  export type Doc<TableName extends TableNames> = DocumentByName<DataModel, TableName>;
+
+  /**
+   * An identifier for a document in Convex.
+   *
+   * Convex documents are uniquely identified by their \`Id\`, which is accessible
+   * on the \`_id\` field. To learn more, see [Document IDs](https://docs.convex.dev/using/document-ids).
+   *
+   * Documents can be loaded using \`db.get(id)\` in query and mutation functions.
+   *
+   * IDs are just strings at runtime, but this type can be used to distinguish them from other
+   * strings when type checking.
+   *
+   * @typeParam TableName - A string literal type of the table name (like "users").
+   */
+  export type Id<TableName extends TableNames | SystemTableNames> = GenericId<TableName>;
+
+  /**
+   * A type describing your Convex data model.
+   *
+   * This type includes information about what tables you have, the type of
+   * documents stored in those tables, and the indexes defined on them.
+   *
+   * This type is used to parameterize methods like \`queryGeneric\` and
+   * \`mutationGeneric\` to make them type-safe.
+   */
+  export type DataModel = DataModelFromSchemaDefinition<typeof schema>;
+  `;
+}
+
+export async function staticDataModelDTS(
+  ctx: Context,
+  startPush: StartPushResponse,
+  rootComponent: ComponentDirectory,
+  componentDirectory: ComponentDirectory,
+) {
+  const definitionPath = toComponentDefinitionPath(
+    rootComponent,
+    componentDirectory,
+  );
+
+  const analysis = startPush.analysis[definitionPath];
+  if (!analysis) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: `No analysis found for component ${definitionPath} orig: ${definitionPath}\nin\n${Object.keys(startPush.analysis).toString()}`,
+    });
+  }
+  if (!analysis.schema) {
+    return noSchemaDataModelDTS();
+  }
+
+  const lines = [
+    header("Generated data model types."),
+    `import type { DocumentByName, TableNamesInDataModel, SystemTableNames, AnyDataModel } from "convex/server";`,
+    `import type { GenericId } from "convex/values";`,
+  ];
+  for await (const line of codegenDataModel(ctx, analysis.schema)) {
+    lines.push(line);
+  }
+  lines.push(`
+    /**
+     * The names of all of your Convex tables.
+     */
+    export type TableNames = TableNamesInDataModel<DataModel>;
+
+    /**
+     * The type of a document stored in Convex.
+     *
+     * @typeParam TableName - A string literal type of the table name (like "users").
+     */
+    export type Doc<TableName extends TableNames> = DocumentByName<DataModel, TableName>;
+
+    /**
+     * An identifier for a document in Convex.
+     *
+     * Convex documents are uniquely identified by their \`Id\`, which is accessible
+     * on the \`_id\` field. To learn more, see [Document IDs](https://docs.convex.dev/using/document-ids).
+     *
+     * Documents can be loaded using \`db.get(id)\` in query and mutation functions.
+     *
+     * IDs are just strings at runtime, but this type can be used to distinguish them from other
+     * strings when type checking.
+     *
+     * @typeParam TableName - A string literal type of the table name (like "users").
+     */
+    export type Id<TableName extends TableNames | SystemTableNames> = GenericId<TableName>;
+    `);
+
+  return lines.join("\n");
+}
+
+async function* codegenDataModel(ctx: Context, schema: AnalyzedSchema) {
+  yield `
+    /**
+     * A type describing your Convex data model.
+     *
+     * This type includes information about what tables you have, the type of
+     * documents stored in those tables, and the indexes defined on them.
+     *
+     * This type is used to parameterize methods like \`queryGeneric\` and
+     * \`mutationGeneric\` to make them type-safe.
+     */
+  `;
+  const tables = [...schema.tables];
+  tables.sort((a, b) => a.tableName.localeCompare(b.tableName));
+
+  yield `export type DataModel = {`;
+  for (const table of tables) {
+    yield `  ${table.tableName}:`;
+    yield* codegenTable(ctx, table);
+    yield `,`;
+  }
+  yield `}`;
+  if (!schema.schemaValidation) {
+    yield ` & AnyDataModel`;
+  }
+  yield `;`;
+}
+
+async function* codegenTable(ctx: Context, table: TableDefinition) {
+  const documentType = await addSystemFields(
+    ctx,
+    table.tableName,
+    table.documentType,
+  );
+
+  const indexJson: Record<string, string[]> = {};
+  for (const index of table.indexes) {
+    indexJson[index.indexDescriptor] = index.fields;
+  }
+
+  yield `{`;
+  yield `  document: ${validatorToType(documentType, true)},`;
+
+  const fieldPaths = new Set<string>();
+  for (const fieldPath of extractFieldPaths(documentType)) {
+    fieldPaths.add(fieldPath.join("."));
+  }
+  yield `  fieldPaths: ${stringLiteralUnionType(Array.from(fieldPaths).sort())},`;
+
+  yield `  indexes: {`;
+  const systemIndexes: SystemIndexes = {
+    by_id: ["_id"],
+    by_creation_time: ["_creationTime"],
+  };
+  const indexes: Record<string, string[]> = {};
+  for (const [indexDescriptor, fields] of Object.entries(systemIndexes)) {
+    indexes[indexDescriptor] = fields;
+  }
+  for (const index of table.indexes) {
+    if (indexes[index.indexDescriptor]) {
+      yield await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage: `Duplicate index name ${index.indexDescriptor} in table ${table.tableName}.`,
+      });
+    }
+    indexes[index.indexDescriptor] = index.fields;
+  }
+  for (const [indexDescriptor, fields] of Object.entries(indexes)) {
+    yield `    "${indexDescriptor}": ${JSON.stringify(fields)},`;
+  }
+  yield `  },`;
+
+  yield `  searchIndexes: {`;
+  for (const index of table.searchIndexes ?? []) {
+    yield `    "${index.indexDescriptor}": {`;
+    yield `      searchField: "${index.searchField}",`;
+    yield `      filterFields: ${stringLiteralUnionType(index.filterFields)},`;
+    yield `    },`;
+  }
+  yield `  },`;
+
+  yield `  vectorIndexes: {`;
+  for (const index of table.vectorIndexes ?? []) {
+    yield `    "${index.indexDescriptor}": {`;
+    yield `      vectorField: "${index.vectorField}",`;
+    yield `      dimensions: ${index.dimensions},`;
+    yield `      filterFields: ${stringLiteralUnionType(index.filterFields)},`;
+    yield `    },`;
+  }
+  yield `  },`;
+  yield `}`;
+}
+
+const SYSTEM_FIELDS = ["_id", "_creationTime"];
+
+async function addSystemFields(
+  ctx: Context,
+  tableName: string,
+  validator: ConvexValidator,
+): Promise<ConvexValidator> {
+  if (validator.type === "object") {
+    return addSystemFieldsToObject(ctx, tableName, validator);
+  } else if (validator.type === "any") {
+    return { type: "any" };
+  } else if (validator.type === "union") {
+    const newSubValidators = [];
+    for (const subValidator of validator.value) {
+      const newSubValidator = await addSystemFieldsToObject(
+        ctx,
+        tableName,
+        subValidator,
+      );
+      newSubValidators.push(newSubValidator);
+    }
+    return { type: "union", value: newSubValidators };
+  } else {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: `Invalid top-level validator for ${tableName}.`,
+    });
+  }
+}
+
+async function addSystemFieldsToObject(
+  ctx: Context,
+  tableName: string,
+  validator: ConvexValidator,
+): Promise<ConvexValidator> {
+  if (validator.type !== "object") {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: `System fields can only be added to objects.`,
+    });
+  }
+  for (const systemField of SYSTEM_FIELDS) {
+    if (Object.hasOwn(validator.value, systemField)) {
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage: `System field ${systemField} present in table ${tableName}.`,
+      });
+    }
+  }
+  return {
+    type: "object",
+    value: {
+      ...validator.value,
+      _id: {
+        fieldType: { type: "id", tableName },
+        optional: false,
+      },
+      _creationTime: {
+        fieldType: { type: "number" },
+        optional: false,
+      },
+    },
+  };
+}
+
+function* extractFieldPaths(validator: ConvexValidator): Generator<string[]> {
+  if (validator.type === "object") {
+    for (const [fieldName, fieldValidator] of Object.entries(validator.value)) {
+      for (const subFieldPath of extractFieldPaths(fieldValidator.fieldType)) {
+        yield [fieldName, ...subFieldPath];
+      }
+    }
+  } else if (validator.type === "union") {
+    for (const subValidator of validator.value) {
+      yield* extractFieldPaths(subValidator);
+    }
+  } else {
+    yield [];
+  }
+}
+
+function stringLiteralUnionType(fields: string[]) {
+  if (fields.length === 0) {
+    return "never";
+  } else if (fields.length === 1) {
+    return `"${fields[0]}"`;
+  } else {
+    return fields.map((field) => `"${field}"`).join(" | ");
+  }
+}
diff --git a/synced/convex/libs/cli/codegen_templates/readme.ts b/synced/convex/libs/cli/codegen_templates/readme.ts
new file mode 100644
index 0000000..e1aecd0
--- /dev/null
+++ b/synced/convex/libs/cli/codegen_templates/readme.ts
@@ -0,0 +1,89 @@
+export function readmeCodegen() {
+  return `# Welcome to your Convex functions directory!
+
+Write your Convex functions here.
+See https://docs.convex.dev/functions for more.
+
+A query function that takes two arguments looks like:
+
+\`\`\`ts
+// functions.js
+import { query } from "./_generated/server";
+import { v } from "convex/values";
+
+export const myQueryFunction = query({
+  // Validators for arguments.
+  args: {
+    first: v.number(),
+    second: v.string(),
+  },
+
+  // Function implementation.
+  handler: async (ctx, args) => {
+    // Read the database as many times as you need here.
+    // See https://docs.convex.dev/database/reading-data.
+    const documents = await ctx.db.query("tablename").collect();
+
+    // Arguments passed from the client are properties of the args object.
+    console.log(args.first, args.second)
+
+    // Write arbitrary JavaScript here: filter, aggregate, build derived data,
+    // remove non-public properties, or create new objects.
+    return documents;
+  },
+});
+\`\`\`
+
+Using this query function in a React component looks like:
+
+\`\`\`ts
+const data = useQuery(api.functions.myQueryFunction, { first: 10, second: "hello" });
+\`\`\`
+
+
+A mutation function looks like:
+
+\`\`\`ts
+// functions.js
+import { mutation } from "./_generated/server";
+import { v } from "convex/values";
+
+export const myMutationFunction = mutation({
+  // Validators for arguments.
+  args: {
+    first: v.string(),
+    second: v.string(),
+  },
+
+  // Function implementation.
+  handler: async (ctx, args) => {
+    // Insert or modify documents in the database here.
+    // Mutations can also read from the database like queries.
+    // See https://docs.convex.dev/database/writing-data.
+    const message = { body: args.first, author: args.second };
+    const id = await ctx.db.insert("messages", message);
+
+    // Optionally, return a value from your mutation.
+    return await ctx.db.get(id);
+  },
+});
+\`\`\`
+
+Using this mutation function in a React component looks like:
+
+\`\`\`ts
+const mutation = useMutation(api.functions.myMutationFunction);
+function handleButtonPress() {
+  // fire and forget, the most common way to use mutations
+  mutation({ first: "Hello!", second: "me" });
+  // OR
+  // use the result once the mutation has completed
+  mutation({ first: "Hello!", second: "me" }).then(result => console.log(result));
+}
+\`\`\`
+
+Use the Convex CLI to push your functions to a deployment. See everything
+the Convex CLI can do by running \`npx convex -h\` in your project root
+directory. To learn more, launch the docs with \`npx convex docs\`.
+`;
+}
diff --git a/synced/convex/libs/cli/codegen_templates/server.ts b/synced/convex/libs/cli/codegen_templates/server.ts
new file mode 100644
index 0000000..b05ff2f
--- /dev/null
+++ b/synced/convex/libs/cli/codegen_templates/server.ts
@@ -0,0 +1,230 @@
+import { header } from "./common.js";
+
+export function serverCodegen() {
+  const serverDTS = `
+    ${header(
+      "Generated utilities for implementing server-side Convex query and mutation functions.",
+    )}
+    import {
+      ActionBuilder,
+      HttpActionBuilder,
+      MutationBuilder,
+      QueryBuilder,
+      GenericActionCtx,
+      GenericMutationCtx,
+      GenericQueryCtx,
+      GenericDatabaseReader,
+      GenericDatabaseWriter,
+    } from "convex/server";
+    import type { DataModel } from "./dataModel.js";
+
+    /**
+     * Define a query in this Convex app's public API.
+     *
+     * This function will be allowed to read your Convex database and will be accessible from the client.
+     *
+     * @param func - The query function. It receives a {@link QueryCtx} as its first argument.
+     * @returns The wrapped query. Include this as an \`export\` to name it and make it accessible.
+     */
+    export declare const query: QueryBuilder<DataModel, "public">;
+
+    /**
+     * Define a query that is only accessible from other Convex functions (but not from the client).
+     *
+     * This function will be allowed to read from your Convex database. It will not be accessible from the client.
+     *
+     * @param func - The query function. It receives a {@link QueryCtx} as its first argument.
+     * @returns The wrapped query. Include this as an \`export\` to name it and make it accessible.
+     */
+    export declare const internalQuery: QueryBuilder<DataModel, "internal">;
+
+    /**
+     * Define a mutation in this Convex app's public API.
+     *
+     * This function will be allowed to modify your Convex database and will be accessible from the client.
+     *
+     * @param func - The mutation function. It receives a {@link MutationCtx} as its first argument.
+     * @returns The wrapped mutation. Include this as an \`export\` to name it and make it accessible.
+     */
+    export declare const mutation: MutationBuilder<DataModel, "public">;
+
+    /**
+     * Define a mutation that is only accessible from other Convex functions (but not from the client).
+     *
+     * This function will be allowed to modify your Convex database. It will not be accessible from the client.
+     *
+     * @param func - The mutation function. It receives a {@link MutationCtx} as its first argument.
+     * @returns The wrapped mutation. Include this as an \`export\` to name it and make it accessible.
+     */
+    export declare const internalMutation: MutationBuilder<DataModel, "internal">;
+
+    /**
+     * Define an action in this Convex app's public API.
+     *
+     * An action is a function which can execute any JavaScript code, including non-deterministic
+     * code and code with side-effects, like calling third-party services.
+     * They can be run in Convex's JavaScript environment or in Node.js using the "use node" directive.
+     * They can interact with the database indirectly by calling queries and mutations using the {@link ActionCtx}.
+     *
+     * @param func - The action. It receives an {@link ActionCtx} as its first argument.
+     * @returns The wrapped action. Include this as an \`export\` to name it and make it accessible.
+     */
+    export declare const action: ActionBuilder<DataModel, "public">;
+
+    /**
+     * Define an action that is only accessible from other Convex functions (but not from the client).
+     *
+     * @param func - The function. It receives an {@link ActionCtx} as its first argument.
+     * @returns The wrapped function. Include this as an \`export\` to name it and make it accessible.
+     */
+    export declare const internalAction: ActionBuilder<DataModel, "internal">;
+
+    /**
+     * Define an HTTP action.
+     *
+     * This function will be used to respond to HTTP requests received by a Convex
+     * deployment if the requests matches the path and method where this action
+     * is routed. Be sure to route your action in \`convex/http.js\`.
+     *
+     * @param func - The function. It receives an {@link ActionCtx} as its first argument.
+     * @returns The wrapped function. Import this function from \`convex/http.js\` and route it to hook it up.
+     */
+    export declare const httpAction: HttpActionBuilder;
+
+    /**
+     * A set of services for use within Convex query functions.
+     *
+     * The query context is passed as the first argument to any Convex query
+     * function run on the server.
+     *
+     * This differs from the {@link MutationCtx} because all of the services are
+     * read-only.
+     */
+    export type QueryCtx = GenericQueryCtx<DataModel>;
+
+    /**
+     * A set of services for use within Convex mutation functions.
+     *
+     * The mutation context is passed as the first argument to any Convex mutation
+     * function run on the server.
+     */
+    export type MutationCtx = GenericMutationCtx<DataModel>;
+
+    /**
+     * A set of services for use within Convex action functions.
+     *
+     * The action context is passed as the first argument to any Convex action
+     * function run on the server.
+     */
+    export type ActionCtx = GenericActionCtx<DataModel>;
+
+    /**
+     * An interface to read from the database within Convex query functions.
+     *
+     * The two entry points are {@link DatabaseReader.get}, which fetches a single
+     * document by its {@link Id}, or {@link DatabaseReader.query}, which starts
+     * building a query.
+     */
+    export type DatabaseReader = GenericDatabaseReader<DataModel>;
+
+    /**
+     * An interface to read from and write to the database within Convex mutation
+     * functions.
+     *
+     * Convex guarantees that all writes within a single mutation are
+     * executed atomically, so you never have to worry about partial writes leaving
+     * your data in an inconsistent state. See [the Convex Guide](https://docs.convex.dev/understanding/convex-fundamentals/functions#atomicity-and-optimistic-concurrency-control)
+     * for the guarantees Convex provides your functions.
+     */
+    export type DatabaseWriter = GenericDatabaseWriter<DataModel>;`;
+
+  const serverJS = `
+    ${header(
+      "Generated utilities for implementing server-side Convex query and mutation functions.",
+    )}
+    import {
+      actionGeneric,
+      httpActionGeneric,
+      queryGeneric,
+      mutationGeneric,
+      internalActionGeneric,
+      internalMutationGeneric,
+      internalQueryGeneric,
+    } from "convex/server";
+
+    /**
+     * Define a query in this Convex app's public API.
+     *
+     * This function will be allowed to read your Convex database and will be accessible from the client.
+     *
+     * @param func - The query function. It receives a {@link QueryCtx} as its first argument.
+     * @returns The wrapped query. Include this as an \`export\` to name it and make it accessible.
+     */
+    export const query = queryGeneric;
+
+    /**
+     * Define a query that is only accessible from other Convex functions (but not from the client).
+     *
+     * This function will be allowed to read from your Convex database. It will not be accessible from the client.
+     *
+     * @param func - The query function. It receives a {@link QueryCtx} as its first argument.
+     * @returns The wrapped query. Include this as an \`export\` to name it and make it accessible.
+     */
+    export const internalQuery = internalQueryGeneric;
+
+    /**
+     * Define a mutation in this Convex app's public API.
+     *
+     * This function will be allowed to modify your Convex database and will be accessible from the client.
+     *
+     * @param func - The mutation function. It receives a {@link MutationCtx} as its first argument.
+     * @returns The wrapped mutation. Include this as an \`export\` to name it and make it accessible.
+     */
+    export const mutation = mutationGeneric;
+
+    /**
+     * Define a mutation that is only accessible from other Convex functions (but not from the client).
+     *
+     * This function will be allowed to modify your Convex database. It will not be accessible from the client.
+     *
+     * @param func - The mutation function. It receives a {@link MutationCtx} as its first argument.
+     * @returns The wrapped mutation. Include this as an \`export\` to name it and make it accessible.
+     */
+    export const internalMutation = internalMutationGeneric;
+
+    /**
+     * Define an action in this Convex app's public API.
+     *
+     * An action is a function which can execute any JavaScript code, including non-deterministic
+     * code and code with side-effects, like calling third-party services.
+     * They can be run in Convex's JavaScript environment or in Node.js using the "use node" directive.
+     * They can interact with the database indirectly by calling queries and mutations using the {@link ActionCtx}.
+     *
+     * @param func - The action. It receives an {@link ActionCtx} as its first argument.
+     * @returns The wrapped action. Include this as an \`export\` to name it and make it accessible.
+     */
+    export const action = actionGeneric;
+
+    /**
+     * Define an action that is only accessible from other Convex functions (but not from the client).
+     *
+     * @param func - The function. It receives an {@link ActionCtx} as its first argument.
+     * @returns The wrapped function. Include this as an \`export\` to name it and make it accessible.
+     */
+    export const internalAction = internalActionGeneric;
+
+    /**
+     * Define a Convex HTTP action.
+     *
+     * @param func - The function. It receives an {@link ActionCtx} as its first argument, and a \`Request\` object
+     * as its second.
+     * @returns The wrapped endpoint function. Route a URL path to this function in \`convex/http.js\`.
+     */
+    export const httpAction = httpActionGeneric;
+    `;
+
+  return {
+    DTS: serverDTS,
+    JS: serverJS,
+  };
+}
diff --git a/synced/convex/libs/cli/codegen_templates/templates.test.ts b/synced/convex/libs/cli/codegen_templates/templates.test.ts
new file mode 100644
index 0000000..3c5297c
--- /dev/null
+++ b/synced/convex/libs/cli/codegen_templates/templates.test.ts
@@ -0,0 +1,16 @@
+import { test } from "vitest";
+import { tsconfigCodegen } from "./tsconfig.js";
+import { readmeCodegen } from "./readme.js";
+
+import prettier from "prettier";
+
+test("templates parse", async () => {
+  await prettier.format(tsconfigCodegen(), {
+    parser: "json",
+    pluginSearchDirs: false,
+  });
+  await prettier.format(readmeCodegen(), {
+    parser: "markdown",
+    pluginSearchDirs: false,
+  });
+});
diff --git a/synced/convex/libs/cli/codegen_templates/tsconfig.ts b/synced/convex/libs/cli/codegen_templates/tsconfig.ts
new file mode 100644
index 0000000..913e830
--- /dev/null
+++ b/synced/convex/libs/cli/codegen_templates/tsconfig.ts
@@ -0,0 +1,27 @@
+export function tsconfigCodegen() {
+  return `{
+  /* This TypeScript project config describes the environment that
+   * Convex functions run in and is used to typecheck them.
+   * You can modify it, but some settings are required to use Convex.
+   */
+  "compilerOptions": {
+    /* These settings are not required by Convex and can be modified. */
+    "allowJs": true,
+    "strict": true,
+    "moduleResolution": "Bundler",
+    "jsx": "react-jsx",
+    "skipLibCheck": true,
+    "allowSyntheticDefaultImports": true,
+
+    /* These compiler options are required by Convex */
+    "target": "ESNext",
+    "lib": ["ES2021", "dom"],
+    "forceConsistentCasingInFileNames": true,
+    "module": "ESNext",
+    "isolatedModules": true,
+    "noEmit": true,
+  },
+  "include": ["./**/*"],
+  "exclude": ["./_generated"]
+}`;
+}
diff --git a/synced/convex/libs/cli/codegen_templates/validator_helpers.ts b/synced/convex/libs/cli/codegen_templates/validator_helpers.ts
new file mode 100644
index 0000000..f334760
--- /dev/null
+++ b/synced/convex/libs/cli/codegen_templates/validator_helpers.ts
@@ -0,0 +1,86 @@
+import { z } from "zod";
+import { jsonToConvex, Value } from "../../values/index.js";
+import {
+  ConvexValidator,
+  convexValidator,
+} from "../lib/deployApi/validator.js";
+
+export function parseValidator(
+  validator: string | null,
+): ConvexValidator | null {
+  if (!validator) {
+    return null;
+  }
+  return z.nullable(convexValidator).parse(JSON.parse(validator));
+}
+
+export function validatorToType(
+  validator: ConvexValidator,
+  useIdType: boolean,
+): string {
+  if (validator.type === "null") {
+    return "null";
+  } else if (validator.type === "number") {
+    return "number";
+  } else if (validator.type === "bigint") {
+    return "bigint";
+  } else if (validator.type === "boolean") {
+    return "boolean";
+  } else if (validator.type === "string") {
+    return "string";
+  } else if (validator.type === "bytes") {
+    return "ArrayBuffer";
+  } else if (validator.type === "any") {
+    return "any";
+  } else if (validator.type === "literal") {
+    const convexValue = jsonToConvex(validator.value);
+    return convexValueToLiteral(convexValue);
+  } else if (validator.type === "id") {
+    return useIdType ? `Id<"${validator.tableName}">` : "string";
+  } else if (validator.type === "array") {
+    return `Array<${validatorToType(validator.value, useIdType)}>`;
+  } else if (validator.type === "record") {
+    return `Record<${validatorToType(validator.keys, useIdType)}, ${validatorToType(validator.values.fieldType, useIdType)}>`;
+  } else if (validator.type === "union") {
+    return validator.value
+      .map((v) => validatorToType(v, useIdType))
+      .join(" | ");
+  } else if (validator.type === "object") {
+    return objectValidatorToType(validator.value, useIdType);
+  } else {
+    // eslint-disable-next-line no-restricted-syntax
+    throw new Error(`Unsupported validator type`);
+  }
+}
+
+function objectValidatorToType(
+  fields: Record<string, { fieldType: ConvexValidator; optional: boolean }>,
+  useIdType: boolean,
+): string {
+  const fieldStrings: string[] = [];
+  for (const [fieldName, field] of Object.entries(fields)) {
+    const fieldType = validatorToType(field.fieldType, useIdType);
+    fieldStrings.push(`${fieldName}${field.optional ? "?" : ""}: ${fieldType}`);
+  }
+  return `{ ${fieldStrings.join(", ")} }`;
+}
+
+function convexValueToLiteral(value: Value): string {
+  if (value === null) {
+    return "null";
+  }
+  if (typeof value === "bigint") {
+    return `${value}n`;
+  }
+  if (typeof value === "number") {
+    return `${value}`;
+  }
+  if (typeof value === "boolean") {
+    return `${value}`;
+  }
+  if (typeof value === "string") {
+    return `"${value}"`;
+  }
+  // eslint-disable-next-line no-restricted-syntax
+  throw new Error(`Unsupported literal type`);
+}
diff --git a/synced/convex/libs/cli/configure.ts b/synced/convex/libs/cli/configure.ts
new file mode 100644
index 0000000..363540c
--- /dev/null
+++ b/synced/convex/libs/cli/configure.ts
@@ -0,0 +1,792 @@
+import chalk from "chalk";
+import {
+  Context,
+  logFailure,
+  logFinishedStep,
+  logMessage,
+  logWarning,
+  showSpinner,
+} from "../bundler/context.js";
+import {
+  DeploymentType,
+  DeploymentName,
+  fetchDeploymentCredentialsProvisioningDevOrProdMaybeThrows,
+  createProject,
+  DeploymentSelectionWithinProject,
+  loadSelectedDeploymentCredentials,
+  checkAccessToSelectedProject,
+  validateDeploymentSelectionForExistingDeployment,
+} from "./lib/api.js";
+import {
+  configFilepath,
+  configName,
+  readProjectConfig,
+  upgradeOldAuthInfoToAuthConfig,
+  writeProjectConfig,
+} from "./lib/config.js";
+import {
+  DeploymentDetails,
+  eraseDeploymentEnvVar,
+  writeDeploymentEnvVar,
+} from "./lib/deployment.js";
+import { finalizeConfiguration } from "./lib/init.js";
+import {
+  CONVEX_DEPLOYMENT_ENV_VAR_NAME,
+  functionsDir,
+  hasProjects,
+  logAndHandleFetchError,
+  selectDevDeploymentType,
+  validateOrSelectProject,
+  validateOrSelectTeam,
+} from "./lib/utils/utils.js";
+import { writeConvexUrlToEnvFile } from "./lib/envvars.js";
+import path from "path";
+import { projectDashboardUrl } from "./lib/dashboard.js";
+import { doCodegen, doInitCodegen } from "./lib/codegen.js";
+import { handleLocalDeployment } from "./lib/localDeployment/localDeployment.js";
+import {
+  promptOptions,
+  promptString,
+  promptYesNo,
+} from "./lib/utils/prompts.js";
+import { readGlobalConfig } from "./lib/utils/globalConfig.js";
+import {
+  DeploymentSelection,
+  ProjectSelection,
+  deploymentNameFromSelection,
+  shouldAllowAnonymousDevelopment,
+} from "./lib/deploymentSelection.js";
+import { ensureLoggedIn } from "./lib/login.js";
+import { handleAnonymousDeployment } from "./lib/localDeployment/anonymous.js";
+type DeploymentCredentials = {
+  url: string;
+  adminKey: string;
+};
+
+type ChosenConfiguration =
+  // `--configure new`
+  | "new"
+  // `--configure existing`
+  | "existing"
+  // `--configure`
+  | "ask"
+  // `--configure` was not specified
+  | null;
+
+type ConfigureCmdOptions = {
+  selectionWithinProject: DeploymentSelectionWithinProject;
+  prod: boolean;
+  localOptions: {
+    ports?: {
+      cloud: number;
+      site: number;
+    };
+    backendVersion?: string | undefined;
+    dashboardVersion?: string | undefined;
+    forceUpgrade: boolean;
+  };
+  team?: string | undefined;
+  project?: string | undefined;
+  devDeployment?: "cloud" | "local" | undefined;
+  local?: boolean | undefined;
+  cloud?: boolean | undefined;
+  url?: string | undefined;
+  adminKey?: string | undefined;
+  envFile?: string | undefined;
+  overrideAuthUrl?: string | undefined;
+  overrideAuthClient?: string | undefined;
+  overrideAuthUsername?: string | undefined;
+  overrideAuthPassword?: string | undefined;
+};
+
+/**
+ * As of writing, this is used by:
+ * - `npx convex dev`
+ * - `npx convex codegen`
+ *
+ * But is not used by `npx convex deploy` or other commands.
+ */
+export async function deploymentCredentialsOrConfigure(
+  ctx: Context,
+  deploymentSelection: DeploymentSelection,
+  chosenConfiguration: ChosenConfiguration,
+  cmdOptions: ConfigureCmdOptions,
+  partitionId?: number | undefined,
+): Promise<
+  DeploymentCredentials & {
+    deploymentFields: {
+      deploymentName: DeploymentName;
+      deploymentType: string;
+      projectSlug: string | null;
+      teamSlug: string | null;
+    } | null;
+  }
+> {
+  const selectedDeployment = await _deploymentCredentialsOrConfigure(
+    ctx,
+    deploymentSelection,
+    chosenConfiguration,
+    cmdOptions,
+    partitionId,
+  );
+
+  if (selectedDeployment.deploymentFields !== null) {
+    // Set the `CONVEX_DEPLOYMENT` env var + the `CONVEX_URL` env var
+    await updateEnvAndConfigForDeploymentSelection(
+      ctx,
+      {
+        url: selectedDeployment.url,
+        deploymentName: selectedDeployment.deploymentFields.deploymentName,
+        teamSlug: selectedDeployment.deploymentFields.teamSlug,
+        projectSlug: selectedDeployment.deploymentFields.projectSlug,
+        deploymentType: selectedDeployment.deploymentFields.deploymentType,
+      },
+      deploymentNameFromSelection(deploymentSelection),
+    );
+  } else {
+    // Clear the `CONVEX_DEPLOYMENT` env var + set the `CONVEX_URL` env var
+    await handleManuallySetUrlAndAdminKey(ctx, {
+      url: selectedDeployment.url,
+      adminKey: selectedDeployment.adminKey,
+    });
+  }
+  return {
+    url: selectedDeployment.url,
+    adminKey: selectedDeployment.adminKey,
+    deploymentFields: selectedDeployment.deploymentFields,
+  };
+}
+
+export async function _deploymentCredentialsOrConfigure(
+  ctx: Context,
+  deploymentSelection: DeploymentSelection,
+  chosenConfiguration: ChosenConfiguration,
+  cmdOptions: ConfigureCmdOptions,
+  partitionId?: number | undefined,
+): Promise<
+  DeploymentCredentials & {
+    deploymentFields: {
+      deploymentName: DeploymentName;
+      deploymentType: DeploymentType;
+      projectSlug: string | null;
+      teamSlug: string | null;
+    } | null;
+  }
+> {
+  const config = readGlobalConfig(ctx);
+  const globallyForceCloud = !!config?.optOutOfLocalDevDeploymentsUntilBetaOver;
+  if (globallyForceCloud && cmdOptions.local) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage:
+        "Can't specify --local when local deployments are disabled on this machine. Run `npx convex disable-local-deployments --undo-global` to allow use of --local.",
+    });
+  }
+
+  switch (deploymentSelection.kind) {
+    case "existingDeployment":
+      await validateDeploymentSelectionForExistingDeployment(
+        ctx,
+        cmdOptions.selectionWithinProject,
+        deploymentSelection.deploymentToActOn.source,
+      );
+      if (deploymentSelection.deploymentToActOn.deploymentFields === null) {
+        // erase `CONVEX_DEPLOYMENT` from .env.local + set the url env var
+        await handleManuallySetUrlAndAdminKey(ctx, {
+          url: deploymentSelection.deploymentToActOn.url,
+          adminKey: deploymentSelection.deploymentToActOn.adminKey,
+        });
+      }
+      return {
+        url: deploymentSelection.deploymentToActOn.url,
+        adminKey: deploymentSelection.deploymentToActOn.adminKey,
+        deploymentFields:
+          deploymentSelection.deploymentToActOn.deploymentFields,
+      };
+    case "chooseProject": {
+      await ensureLoggedIn(ctx, {
+        overrideAuthUrl: cmdOptions.overrideAuthUrl,
+        overrideAuthClient: cmdOptions.overrideAuthClient,
+        overrideAuthUsername: cmdOptions.overrideAuthUsername,
+        overrideAuthPassword: cmdOptions.overrideAuthPassword,
+      });
+      return await handleChooseProject(
+        ctx,
+        chosenConfiguration,
+        {
+          globallyForceCloud,
+          partitionId,
+        },
+        cmdOptions,
+      );
+    }
+    case "preview":
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage: "Use `npx convex deploy` to use preview deployments.",
+      });
+    case "deploymentWithinProject": {
+      return await handleDeploymentWithinProject(ctx, {
+        chosenConfiguration,
+        targetProject: deploymentSelection.targetProject,
+        cmdOptions,
+        globallyForceCloud,
+        partitionId,
+      });
+    }
+    case "anonymous": {
+      const hasAuth = ctx.bigBrainAuth() !== null;
+      if (hasAuth && deploymentSelection.deploymentName !== null) {
+        const shouldConfigure =
+          chosenConfiguration !== null ||
+          (await promptYesNo(ctx, {
+            message: `${CONVEX_DEPLOYMENT_ENV_VAR_NAME} is configured with deployment ${deploymentSelection.deploymentName}, which is not linked with your account. Would you like to choose a different project instead?`,
+          }));
+        if (!shouldConfigure) {
+          return await ctx.crash({
+            exitCode: 0,
+            errorType: "fatal",
+            printedMessage: `Run \`npx convex login --link-deployments\` first to link this deployment to your account, and then run \`npx convex dev\` again.`,
+          });
+        }
+        return await handleChooseProject(
+          ctx,
+          chosenConfiguration,
+          {
+            globallyForceCloud,
+            partitionId,
+          },
+          cmdOptions,
+        );
+      }
+      const alreadyHasConfiguredAnonymousDeployment =
+        deploymentSelection.deploymentName !== null &&
+        chosenConfiguration === null;
+      const shouldPromptForLogin = alreadyHasConfiguredAnonymousDeployment
+        ? "no"
+        : await promptOptions(ctx, {
+            message:
+              "Welcome to Convex! Would you like to login to your account?",
+            choices: [
+              {
+                name: "Start without an account (run Convex locally)",
+                value: "no",
+              },
+              { name: "Login or create an account", value: "yes" },
+            ],
+            default: "no",
+          });
+      if (shouldPromptForLogin === "no") {
+        const result = await handleAnonymousDeployment(ctx, {
+          chosenConfiguration,
+          deploymentName: deploymentSelection.deploymentName,
+          ...cmdOptions.localOptions,
+        });
+        return {
+          adminKey: result.adminKey,
+          url: result.deploymentUrl,
+          deploymentFields: {
+            deploymentName: result.deploymentName,
+            deploymentType: "anonymous",
+            projectSlug: null,
+            teamSlug: null,
+          },
+        };
+      }
+      return await handleChooseProject(
+        ctx,
+        chosenConfiguration,
+        {
+          globallyForceCloud,
+          partitionId,
+        },
+        cmdOptions,
+      );
+    }
+  }
+}
+
+async function handleDeploymentWithinProject(
+  ctx: Context,
+  {
+    chosenConfiguration,
+    targetProject,
+    cmdOptions,
+    globallyForceCloud,
+    partitionId,
+  }: {
+    chosenConfiguration: ChosenConfiguration;
+    targetProject: ProjectSelection;
+    cmdOptions: ConfigureCmdOptions;
+    globallyForceCloud: boolean;
+    partitionId?: number | undefined;
+  },
+) {
+  const hasAuth = ctx.bigBrainAuth() !== null;
+  const loginMessage =
+    hasAuth && shouldAllowAnonymousDevelopment()
+      ? undefined
+      : `Tip: You can try out Convex without creating an account by clearing the ${CONVEX_DEPLOYMENT_ENV_VAR_NAME} environment variable.`;
+  await ensureLoggedIn(ctx, {
+    message: loginMessage,
+    overrideAuthUrl: cmdOptions.overrideAuthUrl,
+    overrideAuthClient: cmdOptions.overrideAuthClient,
+    overrideAuthUsername: cmdOptions.overrideAuthUsername,
+    overrideAuthPassword: cmdOptions.overrideAuthPassword,
+  });
+  if (chosenConfiguration !== null) {
+    const result = await handleChooseProject(
+      ctx,
+      chosenConfiguration,
+      {
+        globallyForceCloud,
+        partitionId,
+      },
+      cmdOptions,
+    );
+    return result;
+  }
+
+  const accessResult = await checkAccessToSelectedProject(ctx, targetProject);
+  if (accessResult.kind === "noAccess") {
+    logMessage(ctx, "You don't have access to the selected project.");
+    const result = await handleChooseProject(
+      ctx,
+      chosenConfiguration,
+      {
+        globallyForceCloud,
+        partitionId,
+      },
+      cmdOptions,
+    );
+    return result;
+  }
+
+  const selectedDeployment = await loadSelectedDeploymentCredentials(
+    ctx,
+    {
+      kind: "deploymentWithinProject",
+      targetProject,
+    },
+    cmdOptions.selectionWithinProject,
+    // We'll start running it below
+    { ensureLocalRunning: false },
+  );
+  if (
+    selectedDeployment.deploymentFields !== null &&
+    selectedDeployment.deploymentFields.deploymentType === "local"
+  ) {
+    // Start running the local backend
+    await handleLocalDeployment(ctx, {
+      teamSlug: selectedDeployment.deploymentFields.teamSlug!,
+      projectSlug: selectedDeployment.deploymentFields.projectSlug!,
+      forceUpgrade: cmdOptions.localOptions.forceUpgrade,
+      ports: cmdOptions.localOptions.ports,
+      backendVersion: cmdOptions.localOptions.backendVersion,
+    });
+  }
+  return {
+    url: selectedDeployment.url,
+    adminKey: selectedDeployment.adminKey,
+    deploymentFields: selectedDeployment.deploymentFields,
+  };
+}
+
+async function handleChooseProject(
+  ctx: Context,
+  chosenConfiguration: ChosenConfiguration,
+  args: {
+    globallyForceCloud: boolean;
+    partitionId?: number | undefined;
+  },
+  cmdOptions: ConfigureCmdOptions,
+): Promise<
+  DeploymentCredentials & {
+    deploymentFields: {
+      deploymentName: DeploymentName;
+      deploymentType: DeploymentType;
+      projectSlug: string;
+      teamSlug: string;
+    };
+  }
+> {
+  await ensureLoggedIn(ctx, {
+    overrideAuthUrl: cmdOptions.overrideAuthUrl,
+    overrideAuthClient: cmdOptions.overrideAuthClient,
+    overrideAuthUsername: cmdOptions.overrideAuthUsername,
+    overrideAuthPassword: cmdOptions.overrideAuthPassword,
+  });
+  const project = await selectProject(ctx, chosenConfiguration, {
+    team: cmdOptions.team,
+    project: cmdOptions.project,
+    devDeployment: cmdOptions.devDeployment,
+    local: args.globallyForceCloud ? false : cmdOptions.local,
+    cloud: args.globallyForceCloud ? true : cmdOptions.cloud,
+    partitionId: args.partitionId,
+  });
+  // TODO complain about any non-default cmdOptions.localOptions here
+  // because we're ignoring them if this isn't a local development.
+
+  const deploymentOptions: DeploymentOptions =
+    cmdOptions.selectionWithinProject.kind === "prod"
+      ? { kind: "prod" }
+      : project.devDeployment === "local"
+        ? { kind: "local", ...cmdOptions.localOptions }
+        : { kind: "dev" };
+  const {
+    deploymentName,
+    deploymentUrl: url,
+    adminKey,
+  } = await ensureDeploymentProvisioned(ctx, {
+    teamSlug: project.teamSlug,
+    projectSlug: project.projectSlug,
+    deploymentOptions,
+    partitionId: args.partitionId,
+  });
+  return {
+    url,
+    adminKey,
+    deploymentFields: {
+      deploymentName,
+      deploymentType: deploymentOptions.kind,
+      projectSlug: project.projectSlug,
+      teamSlug: project.teamSlug,
+    },
+  };
+}
+
+export async function handleManuallySetUrlAndAdminKey(
+  ctx: Context,
+  cmdOptions: { url: string; adminKey: string },
+) {
+  const { url, adminKey } = cmdOptions;
+  const didErase = await eraseDeploymentEnvVar(ctx);
+  if (didErase) {
+    logMessage(
+      ctx,
+      chalk.yellowBright(
+        `Removed the CONVEX_DEPLOYMENT environment variable from .env.local`,
+      ),
+    );
+  }
+  const envVarWrite = await writeConvexUrlToEnvFile(ctx, url);
+  if (envVarWrite !== null) {
+    logMessage(
+      ctx,
+      chalk.green(
+        `Saved the given --url as ${envVarWrite.envVar} to ${envVarWrite.envFile}`,
+      ),
+    );
+  }
+  return { url, adminKey };
+}
+
+export async function selectProject(
+  ctx: Context,
+  chosenConfiguration: ChosenConfiguration,
+  cmdOptions: {
+    team?: string | undefined;
+    project?: string | undefined;
+    devDeployment?: "cloud" | "local" | undefined;
+    local?: boolean | undefined;
+    cloud?: boolean | undefined;
+    partitionId?: number;
+    defaultProjectName?: string | undefined;
+  },
+): Promise<{
+  teamSlug: string;
+  projectSlug: string;
+  devDeployment: "cloud" | "local";
+}> {
+  // Prompt the user to select a project.
+  const choice =
+    chosenConfiguration !== "ask" && chosenConfiguration !== null
+      ? chosenConfiguration
+      : await askToConfigure(ctx);
+  switch (choice) {
+    case "new":
+      return selectNewProject(ctx, chosenConfiguration, cmdOptions);
+    case "existing":
+      return selectExistingProject(ctx, chosenConfiguration, cmdOptions);
+    default:
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage: "No project selected.",
+      });
+  }
+}
+
+const cwd = path.basename(process.cwd());
+async function selectNewProject(
+  ctx: Context,
+  chosenConfiguration: ChosenConfiguration,
+  config: {
+    team?: string | undefined;
+    project?: string | undefined;
+    devDeployment?: "cloud" | "local" | undefined;
+    cloud?: boolean | undefined;
+    local?: boolean | undefined;
+    partitionId?: number | undefined;
+    defaultProjectName?: string | undefined;
+  },
+) {
+  const { teamSlug: selectedTeam, chosen: didChooseBetweenTeams } =
+    await validateOrSelectTeam(ctx, config.team, "Team:");
+  let projectName: string = config.project || cwd;
+  let choseProjectInteractively = false;
+  if (!config.project) {
+    projectName = await promptString(ctx, {
+      message: "Project name:",
+      default: config.defaultProjectName || cwd,
+    });
+    choseProjectInteractively = true;
+  }
+
+  const { devDeployment } = await selectDevDeploymentType(ctx, {
+    chosenConfiguration,
+    newOrExisting: "new",
+    teamSlug: selectedTeam,
+    userHasChosenSomethingInteractively:
+      didChooseBetweenTeams || choseProjectInteractively,
+    projectSlug: undefined,
+    devDeploymentFromFlag: config.devDeployment,
+    forceDevDeployment: config.local
+      ? "local"
+      : config.cloud
+        ? "cloud"
+        : undefined,
+  });
+
+  showSpinner(ctx, "Creating new Convex project...");
+
+  let projectSlug, teamSlug, projectsRemaining;
+  try {
+    ({ projectSlug, teamSlug, projectsRemaining } = await createProject(ctx, {
+      teamSlug: selectedTeam,
+      projectName,
+      partitionId: config.partitionId,
+      // We have to create some deployment initially for a project.
+      deploymentTypeToProvision: devDeployment === "local" ? "prod" : "dev",
+    }));
+  } catch (err) {
+    logFailure(ctx, "Unable to create project.");
+    return await logAndHandleFetchError(ctx, err);
+  }
+  const teamMessage = didChooseBetweenTeams
+    ? " in team " + chalk.bold(teamSlug)
+    : "";
+  logFinishedStep(
+    ctx,
+    `Created project ${chalk.bold(
+      projectSlug,
+    )}${teamMessage}, manage it at ${chalk.bold(
+      projectDashboardUrl(teamSlug, projectSlug),
+    )}`,
+  );
+
+  if (projectsRemaining <= 2) {
+    logWarning(
+      ctx,
+      chalk.yellow.bold(
+        `Your account now has ${projectsRemaining} project${
+          projectsRemaining === 1 ? "" : "s"
+        } remaining.`,
+      ),
+    );
+  }
+
+  const { projectConfig: existingProjectConfig } = await readProjectConfig(ctx);
+  const configPath = await configFilepath(ctx);
+  const functionsPath = functionsDir(configPath, existingProjectConfig);
+  await doInitCodegen(ctx, functionsPath, true);
+  // Disable typechecking since there isn't any code yet.
+  await doCodegen(ctx, functionsPath, "disable");
+  return { teamSlug, projectSlug, devDeployment };
+}
+
+async function selectExistingProject(
+  ctx: Context,
+  chosenConfiguration: ChosenConfiguration,
+  config: {
+    team?: string | undefined;
+    project?: string | undefined;
+    devDeployment?: "cloud" | "local" | undefined;
+    local?: boolean | undefined;
+    cloud?: boolean | undefined;
+  },
+): Promise<{
+  teamSlug: string;
+  projectSlug: string;
+  devDeployment: "cloud" | "local";
+}> {
+  const { teamSlug, chosen } = await validateOrSelectTeam(
+    ctx,
+    config.team,
+    "Team:",
+  );
+
+  const projectSlug = await validateOrSelectProject(
+    ctx,
+    config.project,
+    teamSlug,
+    "Configure project",
+    "Project:",
+  );
+  if (projectSlug === null) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: "Run the command again to create a new project instead.",
+    });
+  }
+  const { devDeployment } = await selectDevDeploymentType(ctx, {
+    chosenConfiguration,
+    newOrExisting: "existing",
+    teamSlug,
+    projectSlug,
+    userHasChosenSomethingInteractively: chosen || !config.project,
+    devDeploymentFromFlag: config.devDeployment,
+    forceDevDeployment: config.local
+      ? "local"
+      : config.cloud
+        ? "cloud"
+        : undefined,
+  });
+
+  showSpinner(ctx, `Reinitializing project ${projectSlug}...\n`);
+
+  const { projectConfig: existingProjectConfig } = await readProjectConfig(ctx);
+
+  const functionsPath = functionsDir(configName(), existingProjectConfig);
+
+  await doCodegen(ctx, functionsPath, "disable");
+
+  logFinishedStep(ctx, `Reinitialized project ${chalk.bold(projectSlug)}`);
+  return { teamSlug, projectSlug, devDeployment };
+}
+
+async function askToConfigure(ctx: Context): Promise<"new" | "existing"> {
+  if (!(await hasProjects(ctx))) {
+    return "new";
+  }
+  return await promptOptions(ctx, {
+    message: "What would you like to configure?",
+    default: "new",
+    choices: [
+      { name: "create a new project", value: "new" },
+      { name: "choose an existing project", value: "existing" },
+    ],
+  });
+}
+
+type DeploymentOptions =
+  | {
+      kind: "prod";
+    }
+  | { kind: "dev" }
+  | {
+      kind: "local";
+      ports?: {
+        cloud: number;
+        site: number;
+      };
+      backendVersion?: string;
+      forceUpgrade: boolean;
+    };
+
+/**
+ * This method assumes that the member has access to the selected project.
+ */
+async function ensureDeploymentProvisioned(
+  ctx: Context,
+  options: {
+    teamSlug: string;
+    projectSlug: string;
+    deploymentOptions: DeploymentOptions;
+    partitionId: number | undefined;
+  },
+): Promise<DeploymentDetails> {
+  switch (options.deploymentOptions.kind) {
+    case "dev":
+    case "prod": {
+      const credentials =
+        await fetchDeploymentCredentialsProvisioningDevOrProdMaybeThrows(
+          ctx,
+          {
+            kind: "teamAndProjectSlugs",
+            teamSlug: options.teamSlug,
+            projectSlug: options.projectSlug,
+          },
+          options.deploymentOptions.kind,
+          options.partitionId,
+        );
+      return {
+        ...credentials,
+        onActivity: null,
+      };
+    }
+    case "local": {
+      const credentials = await handleLocalDeployment(ctx, {
+        teamSlug: options.teamSlug,
+        projectSlug: options.projectSlug,
+        ...options.deploymentOptions,
+      });
+      return credentials;
+    }
+    default:
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage: `Invalid deployment type: ${(options.deploymentOptions as any).kind}`,
+        errForSentry: `Invalid deployment type: ${(options.deploymentOptions as any).kind}`,
+      });
+  }
+}
+
+export async function updateEnvAndConfigForDeploymentSelection(
+  ctx: Context,
+  options: {
+    url: string;
+    deploymentName: string;
+    teamSlug: string | null;
+    projectSlug: string | null;
+    deploymentType: DeploymentType;
+  },
+  existingValue: string | null,
+) {
+  const { configPath, projectConfig: existingProjectConfig } =
+    await readProjectConfig(ctx);
+
+  const functionsPath = functionsDir(configName(), existingProjectConfig);
+
+  const { wroteToGitIgnore, changedDeploymentEnvVar } =
+    await writeDeploymentEnvVar(
+      ctx,
+      options.deploymentType,
+      {
+        team: options.teamSlug,
+        project: options.projectSlug,
+        deploymentName: options.deploymentName,
+      },
+      existingValue,
+    );
+  const projectConfig = await upgradeOldAuthInfoToAuthConfig(
+    ctx,
+    existingProjectConfig,
+    functionsPath,
+  );
+  await writeProjectConfig(ctx, projectConfig, {
+    deleteIfAllDefault: true,
+  });
+  await finalizeConfiguration(ctx, {
+    deploymentType: options.deploymentType,
+    deploymentName: options.deploymentName,
+    url: options.url,
+    wroteToGitIgnore,
+    changedDeploymentEnvVar,
+    functionsPath: functionsDir(configPath, projectConfig),
+  });
+}
diff --git a/synced/convex/libs/cli/convexExport.ts b/synced/convex/libs/cli/convexExport.ts
new file mode 100644
index 0000000..eb259f6
--- /dev/null
+++ b/synced/convex/libs/cli/convexExport.ts
@@ -0,0 +1,51 @@
+import { Command } from "@commander-js/extra-typings";
+import chalk from "chalk";
+import { ensureHasConvexDependency } from "./lib/utils/utils.js";
+import { oneoffContext } from "../bundler/context.js";
+import {
+  deploymentSelectionWithinProjectFromOptions,
+  loadSelectedDeploymentCredentials,
+} from "./lib/api.js";
+import { deploymentDashboardUrlPage } from "./lib/dashboard.js";
+import { actionDescription } from "./lib/command.js";
+import { exportFromDeployment } from "./lib/convexExport.js";
+import { getDeploymentSelection } from "./lib/deploymentSelection.js";
+export const convexExport = new Command("export")
+  .summary("Export data from your deployment to a ZIP file")
+  .description(
+    "Export data, and optionally file storage, from your Convex deployment to a ZIP file.\n" +
+      "By default, this exports from your dev deployment.",
+  )
+  .allowExcessArguments(false)
+  .addExportOptions()
+  .addDeploymentSelectionOptions(actionDescription("Export data from"))
+  .showHelpAfterError()
+  .action(async (options) => {
+    const ctx = await oneoffContext(options);
+    await ensureHasConvexDependency(ctx, "export");
+
+    const deploymentSelection = await getDeploymentSelection(ctx, options);
+
+    const selectionWithinProject =
+      await deploymentSelectionWithinProjectFromOptions(ctx, options);
+
+    const deployment = await loadSelectedDeploymentCredentials(
+      ctx,
+      deploymentSelection,
+      selectionWithinProject,
+    );
+
+    const deploymentNotice = options.prod
+      ? ` in your ${chalk.bold("prod")} deployment`
+      : "";
+    await exportFromDeployment(ctx, {
+      ...options,
+      deploymentUrl: deployment.url,
+      adminKey: deployment.adminKey,
+      deploymentNotice,
+      snapshotExportDashboardLink: deploymentDashboardUrlPage(
+        deployment.deploymentFields?.deploymentName ?? null,
+        "/settings/snapshot-export",
+      ),
+    });
+  });
diff --git a/synced/convex/libs/cli/convexImport.ts b/synced/convex/libs/cli/convexImport.ts
new file mode 100644
index 0000000..3caf619
--- /dev/null
+++ b/synced/convex/libs/cli/convexImport.ts
@@ -0,0 +1,60 @@
+import chalk from "chalk";
+import { ensureHasConvexDependency } from "./lib/utils/utils.js";
+import { oneoffContext } from "../bundler/context.js";
+import {
+  deploymentSelectionWithinProjectFromOptions,
+  loadSelectedDeploymentCredentials,
+} from "./lib/api.js";
+import { Command } from "@commander-js/extra-typings";
+import { actionDescription } from "./lib/command.js";
+import { deploymentDashboardUrlPage } from "./lib/dashboard.js";
+import { importIntoDeployment } from "./lib/convexImport.js";
+import { getDeploymentSelection } from "./lib/deploymentSelection.js";
+
+export const convexImport = new Command("import")
+  .summary("Import data from a file to your deployment")
+  .description(
+    "Import data from a file to your Convex deployment.\n\n" +
+      "  From a snapshot: `npx convex import snapshot.zip`\n" +
+      "  For a single table: `npx convex import --table tableName file.json`\n\n" +
+      "By default, this imports into your dev deployment.",
+  )
+  .allowExcessArguments(false)
+  .addImportOptions()
+  .addDeploymentSelectionOptions(actionDescription("Import data into"))
+  .showHelpAfterError()
+  .action(async (filePath, options) => {
+    const ctx = await oneoffContext(options);
+
+    await ensureHasConvexDependency(ctx, "import");
+
+    const selectionWithinProject =
+      await deploymentSelectionWithinProjectFromOptions(ctx, options);
+
+    const deploymentSelection = await getDeploymentSelection(ctx, options);
+    const deployment = await loadSelectedDeploymentCredentials(
+      ctx,
+      deploymentSelection,
+      selectionWithinProject,
+    );
+
+    const deploymentNotice = options.prod
+      ? ` in your ${chalk.bold("prod")} deployment`
+      : "";
+
+    await importIntoDeployment(ctx, filePath, {
+      ...options,
+      deploymentUrl: deployment.url,
+      adminKey: deployment.adminKey,
+      deploymentNotice,
+      snapshotImportDashboardLink: snapshotImportDashboardLink(
+        deployment.deploymentFields?.deploymentName ?? null,
+      ),
+    });
+  });
+
+function snapshotImportDashboardLink(deploymentName: string | null) {
+  return deploymentName === null
+    ? "https://dashboard.convex.dev/deployment/settings/snapshots"
+    : deploymentDashboardUrlPage(deploymentName, "/settings/snapshots");
+}
diff --git a/synced/convex/libs/cli/dashboard.ts b/synced/convex/libs/cli/dashboard.ts
new file mode 100644
index 0000000..49846d3
--- /dev/null
+++ b/synced/convex/libs/cli/dashboard.ts
@@ -0,0 +1,79 @@
+import { Command } from "@commander-js/extra-typings";
+import chalk from "chalk";
+import open from "open";
+import {
+  Context,
+  logMessage,
+  logOutput,
+  logWarning,
+  oneoffContext,
+} from "../bundler/context.js";
+import {
+  deploymentSelectionWithinProjectFromOptions,
+  loadSelectedDeploymentCredentials,
+} from "./lib/api.js";
+import { actionDescription } from "./lib/command.js";
+import { getDeploymentSelection } from "./lib/deploymentSelection.js";
+import { checkIfDashboardIsRunning } from "./lib/localDeployment/dashboard.js";
+import { getDashboardUrl } from "./lib/dashboard.js";
+import { isAnonymousDeployment } from "./lib/deployment.js";
+
+export const DASHBOARD_HOST = process.env.CONVEX_PROVISION_HOST
+  ? "http://localhost:6789"
+  : "https://dashboard.convex.dev";
+
+export const dashboard = new Command("dashboard")
+  .alias("dash")
+  .description("Open the dashboard in the browser")
+  .allowExcessArguments(false)
+  .option(
+    "--no-open",
+    "Don't automatically open the dashboard in the default browser",
+  )
+  .addDeploymentSelectionOptions(actionDescription("Open the dashboard for"))
+  .showHelpAfterError()
+  .action(async (options) => {
+    const ctx = await oneoffContext(options);
+
+    const selectionWithinProject =
+      await deploymentSelectionWithinProjectFromOptions(ctx, options);
+    const deploymentSelection = await getDeploymentSelection(ctx, options);
+    const deployment = await loadSelectedDeploymentCredentials(
+      ctx,
+      deploymentSelection,
+      selectionWithinProject,
+      { ensureLocalRunning: false },
+    );
+
+    if (deployment.deploymentFields === null) {
+      const msg = `Self-hosted deployment configured.\n\`${chalk.bold("npx convex dashboard")}\` is not supported for self-hosted deployments.\nSee self-hosting instructions for how to self-host the dashboard.`;
+      logMessage(ctx, chalk.yellow(msg));
+      return;
+    }
+    const dashboardUrl = getDashboardUrl(ctx, deployment.deploymentFields);
+    if (isAnonymousDeployment(deployment.deploymentFields.deploymentName)) {
+      const warningMessage = `You are not currently running the dashboard locally. Make sure \`npx convex dev\` is running and try again.`;
+      if (dashboardUrl === null) {
+        logWarning(ctx, warningMessage);
+        return;
+      }
+      const isLocalDashboardRunning = await checkIfDashboardIsRunning(ctx);
+      if (!isLocalDashboardRunning) {
+        logWarning(ctx, warningMessage);
+        return;
+      }
+      await logOrOpenUrl(ctx, dashboardUrl, options.open);
+      return;
+    }
+
+    await logOrOpenUrl(ctx, dashboardUrl ?? DASHBOARD_HOST, options.open);
+  });
+
+async function logOrOpenUrl(ctx: Context, url: string, shouldOpen: boolean) {
+  if (shouldOpen) {
+    logMessage(ctx, chalk.gray(`Opening ${url} in the default browser...`));
+    await open(url);
+  } else {
+    logOutput(ctx, url);
+  }
+}
diff --git a/synced/convex/libs/cli/data.ts b/synced/convex/libs/cli/data.ts
new file mode 100644
index 0000000..f4ba6b1
--- /dev/null
+++ b/synced/convex/libs/cli/data.ts
@@ -0,0 +1,47 @@
+import chalk from "chalk";
+import { oneoffContext } from "../bundler/context.js";
+import {
+  deploymentSelectionWithinProjectFromOptions,
+  loadSelectedDeploymentCredentials,
+} from "./lib/api.js";
+import { Command } from "@commander-js/extra-typings";
+import { actionDescription } from "./lib/command.js";
+import { dataInDeployment } from "./lib/data.js";
+import { getDeploymentSelection } from "./lib/deploymentSelection.js";
+
+export const data = new Command("data")
+  .summary("List tables and print data from your database")
+  .description(
+    "Inspect your Convex deployment's database.\n\n" +
+      "  List tables: `npx convex data`\n" +
+      "  List documents in a table: `npx convex data tableName`\n\n" +
+      "By default, this inspects your dev deployment.",
+  )
+  .allowExcessArguments(false)
+  .addDataOptions()
+  .addDeploymentSelectionOptions(actionDescription("Inspect the database in"))
+  .showHelpAfterError()
+  .action(async (tableName, options) => {
+    const ctx = await oneoffContext(options);
+    const selectionWithinProject =
+      await deploymentSelectionWithinProjectFromOptions(ctx, options);
+
+    const deploymentSelection = await getDeploymentSelection(ctx, options);
+    const deployment = await loadSelectedDeploymentCredentials(
+      ctx,
+      deploymentSelection,
+      selectionWithinProject,
+    );
+
+    const deploymentNotice = deployment.deploymentFields?.deploymentName
+      ? `${chalk.bold(deployment.deploymentFields.deploymentName)} deployment's `
+      : "";
+
+    await dataInDeployment(ctx, {
+      deploymentUrl: deployment.url,
+      adminKey: deployment.adminKey,
+      deploymentNotice,
+      tableName,
+      ...options,
+    });
+  });
diff --git a/synced/convex/libs/cli/deploy.ts b/synced/convex/libs/cli/deploy.ts
new file mode 100644
index 0000000..ecc4ff2
--- /dev/null
+++ b/synced/convex/libs/cli/deploy.ts
@@ -0,0 +1,377 @@
+import chalk from "chalk";
+import { Command, Option } from "@commander-js/extra-typings";
+import {
+  Context,
+  logFinishedStep,
+  logMessage,
+  oneoffContext,
+  showSpinner,
+} from "../bundler/context.js";
+import {
+  deploymentSelectionWithinProjectFromOptions,
+  loadSelectedDeploymentCredentials,
+} from "./lib/api.js";
+import {
+  gitBranchFromEnvironment,
+  isNonProdBuildEnvironment,
+  suggestedEnvVarName,
+} from "./lib/envvars.js";
+import { PushOptions } from "./lib/push.js";
+import {
+  CONVEX_DEPLOY_KEY_ENV_VAR_NAME,
+  CONVEX_SELF_HOSTED_URL_VAR_NAME,
+  CONVEX_DEPLOYMENT_ENV_VAR_NAME,
+  bigBrainAPI,
+} from "./lib/utils/utils.js";
+import { runFunctionAndLog } from "./lib/run.js";
+import { usageStateWarning } from "./lib/usage.js";
+import { getTeamAndProjectFromPreviewAdminKey } from "./lib/deployment.js";
+import { runPush } from "./lib/components.js";
+import { promptYesNo } from "./lib/utils/prompts.js";
+import { deployToDeployment, runCommand } from "./lib/deploy2.js";
+import { getDeploymentSelection } from "./lib/deploymentSelection.js";
+import { deploymentNameAndTypeFromSelection } from "./lib/deploymentSelection.js";
+export const deploy = new Command("deploy")
+  .summary("Deploy to your prod deployment")
+  .description(
+    "Deploy to your deployment. By default, this deploys to your prod deployment.\n\n" +
+      `Deploys to a preview deployment if the \`${CONVEX_DEPLOY_KEY_ENV_VAR_NAME}\` environment variable is set to a Preview Deploy Key.`,
+  )
+  .allowExcessArguments(false)
+  .addDeployOptions()
+  .addOption(
+    new Option(
+      "--preview-run <functionName>",
+      "Function to run if deploying to a preview deployment. This is ignored if deploying to a production deployment.",
+    ),
+  )
+  .addOption(
+    new Option(
+      "--preview-create <name>",
+      "The name to associate with this deployment if deploying to a newly created preview deployment. Defaults to the current Git branch name in Vercel, Netlify and GitHub CI. This is ignored if deploying to a production deployment.",
+    ).conflicts("preview-name"),
+  )
+  .addOption(
+    new Option(
+      "--check-build-environment <mode>",
+      "Whether to check for a non-production build environment before deploying to a production Convex deployment.",
+    )
+      .choices(["enable", "disable"] as const)
+      .default("enable" as const)
+      .hideHelp(),
+  )
+  // Hidden options to pass in admin key and url for tests and local development
+  .addOption(new Option("--admin-key <adminKey>").hideHelp())
+  .addOption(new Option("--url <url>").hideHelp())
+  .addOption(
+    new Option(
+      "--preview-name <name>",
+      "[deprecated] Use `--preview-create` instead. The name to associate with this deployment if deploying to a preview deployment.",
+    )
+      .hideHelp()
+      .conflicts("preview-create"),
+  )
+  .addOption(
+    new Option(
+      "--env-file <envFile>",
+      `Path to a custom file of environment variables, for choosing the \
+deployment, e.g. ${CONVEX_DEPLOYMENT_ENV_VAR_NAME} or ${CONVEX_SELF_HOSTED_URL_VAR_NAME}. \
+Same format as .env.local or .env files, and overrides them.`,
+    ),
+  )
+  .addOption(new Option("--partition-id <id>").hideHelp())
+  .showHelpAfterError()
+  .action(async (cmdOptions) => {
+    const ctx = await oneoffContext(cmdOptions);
+
+    const deploymentSelection = await getDeploymentSelection(ctx, cmdOptions);
+    if (
+      cmdOptions.checkBuildEnvironment === "enable" &&
+      isNonProdBuildEnvironment() &&
+      deploymentSelection.kind === "existingDeployment" &&
+      deploymentSelection.deploymentToActOn.source === "deployKey" &&
+      deploymentSelection.deploymentToActOn.deploymentFields?.deploymentType ===
+        "prod"
+    ) {
+      await ctx.crash({
+        exitCode: 1,
+        errorType: "invalid filesystem data",
+        printedMessage: `Detected a non-production build environment and "${CONVEX_DEPLOY_KEY_ENV_VAR_NAME}" for a production Convex deployment.\n
+          This is probably unintentional.
+          `,
+      });
+    }
+
+    if (deploymentSelection.kind === "anonymous") {
+      logMessage(
+        ctx,
+        "You are currently developing anonymously with a locally running project.\n" +
+          "To deploy your Convex app to the cloud, log in by running `npx convex login`.\n" +
+          "See https://docs.convex.dev/production for more information on how Convex cloud works and instructions on how to set up hosting.",
+      );
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage: null,
+      });
+    }
+
+    if (deploymentSelection.kind === "preview") {
+      // TODO -- add usage state warnings here too once we can do it without a deployment name
+      // await usageStateWarning(ctx);
+      if (cmdOptions.previewName !== undefined) {
+        await ctx.crash({
+          exitCode: 1,
+          errorType: "fatal",
+          printedMessage:
+            "The `--preview-name` flag has been deprecated in favor of `--preview-create`. Please re-run the command using `--preview-create` instead.",
+        });
+      }
+
+      const teamAndProjectSlugs = await getTeamAndProjectFromPreviewAdminKey(
+        ctx,
+        deploymentSelection.previewDeployKey,
+      );
+      await deployToNewPreviewDeployment(
+        ctx,
+        {
+          previewDeployKey: deploymentSelection.previewDeployKey,
+          projectSelection: {
+            kind: "teamAndProjectSlugs",
+            teamSlug: teamAndProjectSlugs.teamSlug,
+            projectSlug: teamAndProjectSlugs.projectSlug,
+          },
+        },
+        {
+          ...cmdOptions,
+        },
+      );
+    } else {
+      await deployToExistingDeployment(ctx, cmdOptions);
+    }
+  });
+
+async function deployToNewPreviewDeployment(
+  ctx: Context,
+  deploymentSelection: {
+    previewDeployKey: string;
+    projectSelection: {
+      kind: "teamAndProjectSlugs";
+      teamSlug: string;
+      projectSlug: string;
+    };
+  },
+  options: {
+    dryRun?: boolean | undefined;
+    previewCreate?: string | undefined;
+    previewRun?: string | undefined;
+    cmdUrlEnvVarName?: string | undefined;
+    cmd?: string | undefined;
+    verbose?: boolean | undefined;
+    typecheck: "enable" | "try" | "disable";
+    typecheckComponents: boolean;
+    codegen: "enable" | "disable";
+
+    debug?: boolean | undefined;
+    debugBundlePath?: string | undefined;
+    partitionId?: string | undefined;
+  },
+) {
+  const previewName = options.previewCreate ?? gitBranchFromEnvironment();
+  if (previewName === null) {
+    await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage:
+        "`npx convex deploy` to a preview deployment could not determine the preview name. Provide one using `--preview-create`",
+    });
+  }
+
+  if (options.dryRun) {
+    logFinishedStep(
+      ctx,
+      `Would have claimed preview deployment for "${previewName}"`,
+    );
+    await runCommand(ctx, {
+      cmdUrlEnvVarName: options.cmdUrlEnvVarName,
+      cmd: options.cmd,
+      dryRun: !!options.dryRun,
+      url: "https://<PREVIEW DEPLOYMENT>.convex.cloud",
+      adminKey: "preview-deployment-admin-key",
+    });
+    logFinishedStep(
+      ctx,
+      `Would have deployed Convex functions to preview deployment for "${previewName}"`,
+    );
+    if (options.previewRun !== undefined) {
+      logMessage(ctx, `Would have run function "${options.previewRun}"`);
+    }
+    return;
+  }
+  const data = await bigBrainAPI({
+    ctx,
+    method: "POST",
+    url: "claim_preview_deployment",
+    data: {
+      projectSelection: deploymentSelection.projectSelection,
+      identifier: previewName,
+      partitionId: options.partitionId
+        ? parseInt(options.partitionId)
+        : undefined,
+    },
+  });
+
+  const previewAdminKey = data.adminKey;
+  const previewUrl = data.instanceUrl;
+
+  await runCommand(ctx, {
+    ...options,
+    url: previewUrl,
+    adminKey: previewAdminKey,
+  });
+
+  const pushOptions: PushOptions = {
+    deploymentName: data.deploymentName,
+    adminKey: previewAdminKey,
+    verbose: !!options.verbose,
+    dryRun: false,
+    typecheck: options.typecheck,
+    typecheckComponents: options.typecheckComponents,
+    debug: !!options.debug,
+    debugBundlePath: options.debugBundlePath,
+    codegen: options.codegen === "enable",
+    url: previewUrl,
+    liveComponentSources: false,
+  };
+  showSpinner(ctx, `Deploying to ${previewUrl}...`);
+  await runPush(ctx, pushOptions);
+  logFinishedStep(ctx, `Deployed Convex functions to ${previewUrl}`);
+
+  if (options.previewRun !== undefined) {
+    await runFunctionAndLog(ctx, {
+      deploymentUrl: previewUrl,
+      adminKey: previewAdminKey,
+      functionName: options.previewRun,
+      argsString: "{}",
+      componentPath: undefined,
+      callbacks: {
+        onSuccess: () => {
+          logFinishedStep(
+            ctx,
+            `Finished running function "${options.previewRun}"`,
+          );
+        },
+      },
+    });
+  }
+}
+
+async function deployToExistingDeployment(
+  ctx: Context,
+  options: {
+    verbose?: boolean | undefined;
+    dryRun?: boolean | undefined;
+    yes?: boolean | undefined;
+    typecheck: "enable" | "try" | "disable";
+    typecheckComponents: boolean;
+    codegen: "enable" | "disable";
+    cmd?: string | undefined;
+    cmdUrlEnvVarName?: string | undefined;
+
+    debugBundlePath?: string | undefined;
+    debug?: boolean | undefined;
+    adminKey?: string | undefined;
+    url?: string | undefined;
+    writePushRequest?: string | undefined;
+    liveComponentSources?: boolean | undefined;
+    partitionId?: string | undefined;
+    envFile?: string | undefined;
+  },
+) {
+  const selectionWithinProject =
+    await deploymentSelectionWithinProjectFromOptions(ctx, {
+      ...options,
+      implicitProd: true,
+    });
+  const deploymentSelection = await getDeploymentSelection(ctx, options);
+  const deploymentToActOn = await loadSelectedDeploymentCredentials(
+    ctx,
+    deploymentSelection,
+    selectionWithinProject,
+  );
+  if (deploymentToActOn.deploymentFields !== null) {
+    await usageStateWarning(
+      ctx,
+      deploymentToActOn.deploymentFields.deploymentName,
+    );
+  }
+  const configuredDeployment =
+    deploymentNameAndTypeFromSelection(deploymentSelection);
+  if (configuredDeployment !== null && configuredDeployment.name !== null) {
+    const shouldPushToProd =
+      configuredDeployment.name ===
+        deploymentToActOn.deploymentFields?.deploymentName ||
+      (options.yes ??
+        (await askToConfirmPush(
+          ctx,
+          {
+            configuredName: configuredDeployment.name,
+            configuredType: configuredDeployment.type,
+            requestedName: deploymentToActOn.deploymentFields?.deploymentName!,
+            requestedType: deploymentToActOn.deploymentFields?.deploymentType!,
+          },
+          deploymentToActOn.url,
+        )));
+    if (!shouldPushToProd) {
+      await ctx.crash({
+        exitCode: 1,
+        printedMessage: null,
+        errorType: "fatal",
+      });
+    }
+  }
+
+  await deployToDeployment(
+    ctx,
+    {
+      url: deploymentToActOn.url,
+      adminKey: deploymentToActOn.adminKey,
+      deploymentName:
+        deploymentToActOn.deploymentFields?.deploymentName ?? null,
+    },
+    options,
+  );
+}
+
+async function askToConfirmPush(
+  ctx: Context,
+  deployment: {
+    configuredName: string;
+    configuredType: string | null;
+    requestedName: string;
+    requestedType: string;
+  },
+  prodUrl: string,
+) {
+  logMessage(
+    ctx,
+    `\
+You're currently developing against your ${chalk.bold(
+      deployment.configuredType ?? "dev",
+    )} deployment
+
+  ${deployment.configuredName} (set in CONVEX_DEPLOYMENT)
+
+Your ${chalk.bold(deployment.requestedType)} deployment ${chalk.bold(
+      deployment.requestedName,
+    )} serves traffic at:
+
+  ${(await suggestedEnvVarName(ctx)).envVar}=${chalk.bold(prodUrl)}
+
+Make sure that your published client is configured with this URL (for instructions see https://docs.convex.dev/hosting)\n`,
+  );
+  return promptYesNo(ctx, {
+    message: `Do you want to push your code to your ${deployment.requestedType} deployment ${deployment.requestedName} now?`,
+    default: true,
+  });
+}
diff --git a/synced/convex/libs/cli/deployments.ts b/synced/convex/libs/cli/deployments.ts
new file mode 100644
index 0000000..f368226
--- /dev/null
+++ b/synced/convex/libs/cli/deployments.ts
@@ -0,0 +1,42 @@
+import { Command } from "@commander-js/extra-typings";
+import { readProjectConfig } from "./lib/config.js";
+import chalk from "chalk";
+import { bigBrainAPI } from "./lib/utils/utils.js";
+import {
+  logError,
+  logMessage,
+  logOutput,
+  oneoffContext,
+} from "../bundler/context.js";
+
+type Deployment = {
+  id: number;
+  name: string;
+  create_time: number;
+  deployment_type: "dev" | "prod";
+};
+
+export const deployments = new Command("deployments")
+  .description("List deployments associated with a project")
+  .allowExcessArguments(false)
+  .action(async () => {
+    const ctx = await oneoffContext({
+      url: undefined,
+      adminKey: undefined,
+      envFile: undefined,
+    });
+    const { projectConfig: config } = await readProjectConfig(ctx);
+
+    const url = `teams/${config.team}/projects/${config.project}/deployments`;
+
+    logMessage(ctx, `Deployments for project ${config.team}/${config.project}`);
+    const deployments = (await bigBrainAPI({
+      ctx,
+      method: "GET",
+      url,
+    })) as Deployment[];
+    logOutput(ctx, deployments);
+    if (deployments.length === 0) {
+      logError(ctx, chalk.yellow(`No deployments exist for project`));
+    }
+  });
diff --git a/synced/convex/libs/cli/dev.ts b/synced/convex/libs/cli/dev.ts
new file mode 100644
index 0000000..4595991
--- /dev/null
+++ b/synced/convex/libs/cli/dev.ts
@@ -0,0 +1,255 @@
+import { Command, Option } from "@commander-js/extra-typings";
+import { logVerbose, oneoffContext } from "../bundler/context.js";
+import { deploymentCredentialsOrConfigure } from "./configure.js";
+import { usageStateWarning } from "./lib/usage.js";
+import { normalizeDevOptions } from "./lib/command.js";
+import { devAgainstDeployment } from "./lib/dev.js";
+import { deploymentSelectionWithinProjectFromOptions } from "./lib/api.js";
+import {
+  CONVEX_DEPLOYMENT_ENV_VAR_NAME,
+  CONVEX_SELF_HOSTED_URL_VAR_NAME,
+} from "./lib/utils/utils.js";
+import { getDeploymentSelection } from "./lib/deploymentSelection.js";
+
+export const dev = new Command("dev")
+  .summary("Develop against a dev deployment, watching for changes")
+  .description(
+    "Develop against a dev deployment, watching for changes\n\n" +
+      "  1. Configures a new or existing project (if needed)\n" +
+      "  2. Updates generated types and pushes code to the configured dev deployment\n" +
+      "  3. Runs the provided command (if `--run` or `--run-sh` is used)\n" +
+      "  4. Watches for file changes, and repeats step 2\n",
+  )
+  .allowExcessArguments(false)
+  .option("-v, --verbose", "Show full listing of changes")
+  .addOption(
+    new Option(
+      "--typecheck <mode>",
+      `Check TypeScript files with \`tsc --noEmit\`.`,
+    )
+      .choices(["enable", "try", "disable"] as const)
+      .default("try" as const),
+  )
+  .option(
+    "--typecheck-components",
+    "Check TypeScript files within component implementations with `tsc --noEmit`.",
+    false,
+  )
+  .addOption(
+    new Option("--codegen <mode>", "Regenerate code in `convex/_generated/`")
+      .choices(["enable", "disable"] as const)
+      .default("enable" as const),
+  )
+  .option(
+    "--once",
+    "Execute only the first 3 steps, stop on any failure",
+    false,
+  )
+  .option(
+    "--until-success",
+    "Execute only the first 3 steps, on failure watch for local and remote changes and retry steps 2 and 3",
+    false,
+  )
+  .addOption(
+    new Option(
+      "--run <functionName>",
+      "The identifier of the function to run in step 3, " +
+        "like `api.init.createData` or `myDir/myFile:myFunction`",
+    ).conflicts(["--run-sh"]),
+  )
+  .option(
+    "--run-component <functionName>",
+    "If --run is used and the function is in a component, the path the component tree defined in convex.config.ts. " +
+      "Components are a beta feature. This flag is unstable and may change in subsequent releases.",
+  )
+  .addOption(
+    new Option(
+      "--run-sh <command>",
+      "A shell command to run in step 3, like `node myScript.js`. " +
+        "If you just want to run a Convex function, use `--run` instead.",
+    ).conflicts(["--run"]),
+  )
+  .addOption(
+    new Option(
+      "--tail-logs [mode]",
+      "Choose whether to tail Convex function logs in this terminal",
+    )
+      .choices(["always", "pause-on-deploy", "disable"] as const)
+      .default("pause-on-deploy"),
+  )
+  .addOption(new Option("--trace-events").default(false).hideHelp())
+  .addOption(new Option("--debug-bundle-path <path>").hideHelp())
+  .addOption(new Option("--live-component-sources").hideHelp())
+  .addOption(
+    new Option(
+      "--configure [choice]",
+      "Ignore existing configuration and configure new or existing project, interactively or set by --team <team_slug>, --project <project_slug>, and --dev-deployment local|cloud",
+    )
+      .choices(["new", "existing"] as const)
+      .conflicts(["--local", "--cloud"]),
+  )
+  .addOption(
+    new Option(
+      "--team <team_slug>",
+      "The team you'd like to use for this project",
+    ).hideHelp(),
+  )
+  .addOption(
+    new Option(
+      "--project <project_slug>",
+      "The name of the project you'd like to configure",
+    ).hideHelp(),
+  )
+  .addOption(
+    new Option(
+      "--dev-deployment <mode>",
+      "Use a local or cloud deployment for dev for this project",
+    )
+      .choices(["cloud", "local"] as const)
+      .conflicts(["--prod"])
+      .hideHelp(),
+  )
+  .addOption(
+    new Option(
+      "--prod",
+      "Develop live against this project's production deployment.",
+    )
+      .default(false)
+      .hideHelp(),
+  )
+  .addOption(
+    new Option(
+      "--env-file <envFile>",
+      `Path to a custom file of environment variables, for choosing the \
+deployment, e.g. ${CONVEX_DEPLOYMENT_ENV_VAR_NAME} or ${CONVEX_SELF_HOSTED_URL_VAR_NAME}. \
+Same format as .env.local or .env files, and overrides them.`,
+    ),
+  )
+  .addOption(new Option("--skip-push").default(false).hideHelp())
+  .addOption(new Option("--admin-key <adminKey>").hideHelp())
+  .addOption(new Option("--url <url>").hideHelp())
+  // Options for testing
+  .addOption(new Option("--override-auth-url <url>").hideHelp())
+  .addOption(new Option("--override-auth-client <id>").hideHelp())
+  .addOption(new Option("--override-auth-username <username>").hideHelp())
+  .addOption(new Option("--override-auth-password <password>").hideHelp())
+  .addOption(new Option("--local-cloud-port <port>").hideHelp())
+  .addOption(new Option("--local-site-port <port>").hideHelp())
+  .addOption(new Option("--local-backend-version <version>").hideHelp())
+  .addOption(new Option("--local-force-upgrade").default(false).hideHelp())
+  .addOption(new Option("--partition-id <id>").hideHelp())
+  .addOption(
+    new Option(
+      "--local",
+      "Use local deployment regardless of last used backend. DB data will not be downloaded from any cloud deployment.",
+    )
+      .default(false)
+      .conflicts(["--prod", "--url", "--admin-key", "--cloud"])
+      .hideHelp(),
+  )
+  .addOption(
+    new Option(
+      "--cloud",
+      "Use cloud deployment regardles of last used backend. DB data will not be uploaded from local.",
+    )
+      .default(false)
+      .conflicts(["--prod", "--url", "--admin-key", "--local"])
+      .hideHelp(),
+  )
+  .showHelpAfterError()
+  .action(async (cmdOptions) => {
+    const ctx = await oneoffContext(cmdOptions);
+    process.on("SIGINT", async () => {
+      logVerbose(ctx, "Received SIGINT, cleaning up...");
+      await ctx.flushAndExit(-2);
+    });
+
+    const devOptions = await normalizeDevOptions(ctx, cmdOptions);
+
+    const selectionWithinProject =
+      await deploymentSelectionWithinProjectFromOptions(ctx, cmdOptions);
+
+    if (cmdOptions.configure === undefined) {
+      if (cmdOptions.team || cmdOptions.project || cmdOptions.devDeployment)
+        return await ctx.crash({
+          exitCode: 1,
+          errorType: "fatal",
+          printedMessage:
+            "`--team, --project, and --dev-deployment can can only be used with `--configure`.",
+        });
+    }
+
+    const localOptions: {
+      ports?: { cloud: number; site: number };
+      backendVersion?: string | undefined;
+      forceUpgrade: boolean;
+    } = { forceUpgrade: false };
+    if (!cmdOptions.local && cmdOptions.devDeployment !== "local") {
+      if (
+        cmdOptions.localCloudPort !== undefined ||
+        cmdOptions.localSitePort !== undefined ||
+        cmdOptions.localBackendVersion !== undefined ||
+        cmdOptions.localForceUpgrade === true
+      ) {
+        return await ctx.crash({
+          exitCode: 1,
+          errorType: "fatal",
+          printedMessage:
+            "`--local-*` options can only be used with `--configure --dev-deployment local` or `--local`.",
+        });
+      }
+    } else {
+      if (cmdOptions.localCloudPort !== undefined) {
+        if (cmdOptions.localSitePort === undefined) {
+          return await ctx.crash({
+            exitCode: 1,
+            errorType: "fatal",
+            printedMessage:
+              "`--local-cloud-port` requires `--local-site-port` to be set.",
+          });
+        }
+        localOptions["ports"] = {
+          cloud: parseInt(cmdOptions.localCloudPort),
+          site: parseInt(cmdOptions.localSitePort),
+        };
+      }
+      localOptions["backendVersion"] = cmdOptions.localBackendVersion;
+      localOptions["forceUpgrade"] = cmdOptions.localForceUpgrade;
+    }
+
+    const partitionId = cmdOptions.partitionId
+      ? parseInt(cmdOptions.partitionId)
+      : undefined;
+    const configure =
+      cmdOptions.configure === true ? "ask" : (cmdOptions.configure ?? null);
+    const deploymentSelection = await getDeploymentSelection(ctx, cmdOptions);
+    const credentials = await deploymentCredentialsOrConfigure(
+      ctx,
+      deploymentSelection,
+      configure,
+      {
+        ...cmdOptions,
+        localOptions,
+        selectionWithinProject,
+      },
+      partitionId,
+    );
+
+    if (credentials.deploymentFields !== null) {
+      await usageStateWarning(ctx, credentials.deploymentFields.deploymentName);
+    }
+
+    if (cmdOptions.skipPush) {
+      return;
+    }
+
+    await devAgainstDeployment(
+      ctx,
+      {
+        url: credentials.url,
+        adminKey: credentials.adminKey,
+        deploymentName: credentials.deploymentFields?.deploymentName ?? null,
+      },
+      devOptions,
+    );
+  });
diff --git a/synced/convex/libs/cli/disableLocalDev.ts b/synced/convex/libs/cli/disableLocalDev.ts
new file mode 100644
index 0000000..edacd1d
--- /dev/null
+++ b/synced/convex/libs/cli/disableLocalDev.ts
@@ -0,0 +1,139 @@
+import { Command } from "@commander-js/extra-typings";
+import { logFinishedStep, oneoffContext } from "../bundler/context.js";
+import { deploymentCredentialsOrConfigure } from "./configure.js";
+import {
+  modifyGlobalConfig,
+  readGlobalConfig,
+} from "./lib/utils/globalConfig.js";
+import {
+  deploymentNameAndTypeFromSelection,
+  getDeploymentSelection,
+} from "./lib/deploymentSelection.js";
+
+export const disableLocalDeployments = new Command("disable-local-deployments")
+  .description(
+    "Stop using a local deployment for the current project, or globally disable local depoyments with --global",
+  )
+  .option(
+    "--global",
+    "Disable local deployments on this machine until a future release when this feature is more stable.",
+  )
+  .option("--undo-global", "Re-enable local deployments on this machine.")
+  .allowExcessArguments(false)
+  .action(async (cmdOptions) => {
+    const ctx = await oneoffContext({
+      url: undefined,
+      adminKey: undefined,
+      envFile: undefined,
+    });
+
+    if (cmdOptions.undoGlobal) {
+      return disableLocalDeploymentsGloballyUntilBetaOver(true);
+    }
+    if (cmdOptions.global) {
+      return disableLocalDeploymentsGloballyUntilBetaOver(
+        !!cmdOptions.undoGlobal,
+      );
+    }
+
+    const deploymentSelection = await getDeploymentSelection(ctx, {
+      url: undefined,
+      adminKey: undefined,
+      envFile: undefined,
+    });
+    const configuredDeployment =
+      deploymentNameAndTypeFromSelection(deploymentSelection);
+    if (
+      configuredDeployment?.type !== null &&
+      configuredDeployment?.type !== "local"
+    ) {
+      logFinishedStep(ctx, "Local development is already not being used.");
+      return;
+    }
+
+    await deploymentCredentialsOrConfigure(ctx, deploymentSelection, "ask", {
+      selectionWithinProject: { kind: "ownDev" },
+      prod: false,
+      localOptions: {
+        forceUpgrade: false,
+      },
+      cloud: true,
+    });
+
+    logFinishedStep(
+      ctx,
+      "You are no longer using a local deployment for development.",
+    );
+  });
+
+async function disableLocalDeploymentsGloballyUntilBetaOver(
+  reenable: boolean,
+): Promise<void> {
+  const ctx = await oneoffContext({
+    url: undefined,
+    adminKey: undefined,
+    envFile: undefined,
+  });
+
+  // Ensure this is not used in CI or scripts, since it has global effects and will be deprecated
+  // in the future.
+  if (!process.stdin.isTTY) {
+    return ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage:
+        "`disable-local-deployments --global` is not for scripting, it is temporary and only for interactive use.",
+    });
+  }
+  const config = readGlobalConfig(ctx);
+  if (config === null) {
+    return ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: "Log in first with `npx convex login",
+    });
+  }
+
+  if (reenable) {
+    if (
+      !("optOutOfLocalDevDeploymentsUntilBetaOver" in config) ||
+      !config.optOutOfLocalDevDeploymentsUntilBetaOver
+    ) {
+      logFinishedStep(
+        ctx,
+        "You are already opted into allowing local deployents on this machine.",
+      );
+      return;
+    }
+    await modifyGlobalConfig(ctx, {
+      ...config,
+      optOutOfLocalDevDeploymentsUntilBetaOver: false,
+    });
+
+    logFinishedStep(
+      ctx,
+      "You have been opted back into allowing local deployents on this machine.",
+    );
+    return;
+  }
+
+  if (
+    "optOutOfLocalDevDeploymentsUntilBetaOver" in config &&
+    config.optOutOfLocalDevDeploymentsUntilBetaOver
+  ) {
+    logFinishedStep(
+      ctx,
+      "You are already opted out of local deployents on this machine.",
+    );
+    return;
+  }
+  await modifyGlobalConfig(ctx, {
+    ...config,
+    optOutOfLocalDevDeploymentsUntilBetaOver: true,
+  });
+
+  logFinishedStep(
+    ctx,
+    "You have been opted out of local deployents on this machine until the beta is over. Run `npx convex disable-local-deployments --undo-global` to opt back in.",
+  );
+}
diff --git a/synced/convex/libs/cli/docs.ts b/synced/convex/libs/cli/docs.ts
new file mode 100644
index 0000000..8a6b160
--- /dev/null
+++ b/synced/convex/libs/cli/docs.ts
@@ -0,0 +1,55 @@
+import { Command } from "@commander-js/extra-typings";
+import chalk from "chalk";
+import open from "open";
+import { Context, logMessage, oneoffContext } from "../bundler/context.js";
+import { bigBrainFetch, deprecationCheckWarning } from "./lib/utils/utils.js";
+import {
+  getDeploymentSelection,
+  deploymentNameFromSelection,
+} from "./lib/deploymentSelection.js";
+
+export const docs = new Command("docs")
+  .description("Open the docs in the browser")
+  .allowExcessArguments(false)
+  .option("--no-open", "Print docs URL instead of opening it in your browser")
+  .action(async (options) => {
+    const ctx = await oneoffContext({
+      url: undefined,
+      adminKey: undefined,
+      envFile: undefined,
+    });
+    const deploymentSelection = await getDeploymentSelection(ctx, {
+      url: undefined,
+      adminKey: undefined,
+      envFile: undefined,
+    });
+    const configuredDeployment =
+      deploymentNameFromSelection(deploymentSelection);
+    if (configuredDeployment === null) {
+      await openDocs(ctx, options.open);
+      return;
+    }
+    const getCookieUrl = `get_cookie/${configuredDeployment}`;
+    const fetch = await bigBrainFetch(ctx);
+    try {
+      const res = await fetch(getCookieUrl);
+      deprecationCheckWarning(ctx, res);
+      const { cookie } = await res.json();
+      await openDocs(ctx, options.open, cookie);
+    } catch {
+      await openDocs(ctx, options.open);
+    }
+  });
+
+async function openDocs(ctx: Context, toOpen: boolean, cookie?: string) {
+  let docsUrl = "https://docs.convex.dev";
+  if (cookie !== undefined) {
+    docsUrl += "/?t=" + cookie;
+  }
+  if (toOpen) {
+    await open(docsUrl);
+    logMessage(ctx, chalk.green("Docs have launched! Check your browser."));
+  } else {
+    logMessage(ctx, chalk.green(`Find Convex docs here: ${docsUrl}`));
+  }
+}
diff --git a/synced/convex/libs/cli/env.ts b/synced/convex/libs/cli/env.ts
new file mode 100644
index 0000000..305ce64
--- /dev/null
+++ b/synced/convex/libs/cli/env.ts
@@ -0,0 +1,135 @@
+import { Command } from "@commander-js/extra-typings";
+import chalk from "chalk";
+import { Context, oneoffContext } from "../bundler/context.js";
+import {
+  DeploymentSelectionOptions,
+  deploymentSelectionWithinProjectFromOptions,
+  loadSelectedDeploymentCredentials,
+} from "./lib/api.js";
+import { actionDescription } from "./lib/command.js";
+import { ensureHasConvexDependency } from "./lib/utils/utils.js";
+import {
+  envGetInDeployment,
+  envListInDeployment,
+  envRemoveInDeployment,
+  envSetInDeployment,
+} from "./lib/env.js";
+import { getDeploymentSelection } from "./lib/deploymentSelection.js";
+
+const envSet = new Command("set")
+  // Pretend value is required
+  .usage("[options] <name> <value>")
+  .arguments("<name> [value]")
+  .summary("Set a variable")
+  .description(
+    "Set a variable: `npx convex env set NAME value`\n" +
+      "If the variable already exists, its value is updated.\n\n" +
+      "A single `NAME=value` argument is also supported.",
+  )
+  .configureHelp({ showGlobalOptions: true })
+  .allowExcessArguments(false)
+  .action(async (originalName, originalValue, _options, cmd) => {
+    const options = cmd.optsWithGlobals();
+    const { ctx, deployment } = await selectEnvDeployment(options);
+    await ensureHasConvexDependency(ctx, "env set");
+    await envSetInDeployment(ctx, deployment, originalName, originalValue);
+  });
+
+async function selectEnvDeployment(
+  options: DeploymentSelectionOptions,
+): Promise<{
+  ctx: Context;
+  deployment: {
+    deploymentUrl: string;
+    adminKey: string;
+    deploymentNotice: string;
+  };
+}> {
+  const ctx = await oneoffContext(options);
+  const deploymentSelection = await getDeploymentSelection(ctx, options);
+  const selectionWithinProject =
+    await deploymentSelectionWithinProjectFromOptions(ctx, options);
+  const {
+    adminKey,
+    url: deploymentUrl,
+    deploymentFields,
+  } = await loadSelectedDeploymentCredentials(
+    ctx,
+    deploymentSelection,
+    selectionWithinProject,
+  );
+  const deploymentNotice =
+    deploymentFields !== null
+      ? ` (on ${chalk.bold(deploymentFields.deploymentType)} deployment ${chalk.bold(deploymentFields.deploymentName)})`
+      : "";
+  return {
+    ctx,
+    deployment: {
+      deploymentUrl,
+      adminKey,
+      deploymentNotice,
+    },
+  };
+}
+
+const envGet = new Command("get")
+  .arguments("<name>")
+  .summary("Print a variable's value")
+  .description("Print a variable's value: `npx convex env get NAME`")
+  .configureHelp({ showGlobalOptions: true })
+  .allowExcessArguments(false)
+  .action(async (envVarName, _options, cmd) => {
+    const options = cmd.optsWithGlobals();
+    const { ctx, deployment } = await selectEnvDeployment(options);
+    await ensureHasConvexDependency(ctx, "env get");
+    await envGetInDeployment(ctx, deployment, envVarName);
+  });
+
+const envRemove = new Command("remove")
+  .alias("rm")
+  .alias("unset")
+  .arguments("<name>")
+  .summary("Unset a variable")
+  .description(
+    "Unset a variable: `npx convex env remove NAME`\n" +
+      "If the variable doesn't exist, the command doesn't do anything and succeeds.",
+  )
+  .configureHelp({ showGlobalOptions: true })
+  .allowExcessArguments(false)
+  .action(async (name, _options, cmd) => {
+    const options = cmd.optsWithGlobals();
+    const { ctx, deployment } = await selectEnvDeployment(options);
+    await ensureHasConvexDependency(ctx, "env remove");
+    await envRemoveInDeployment(ctx, deployment, name);
+  });
+
+const envList = new Command("list")
+  .summary("List all variables")
+  .description("List all variables: `npx convex env list`")
+  .configureHelp({ showGlobalOptions: true })
+  .allowExcessArguments(false)
+  .action(async (_options, cmd) => {
+    const options = cmd.optsWithGlobals();
+    const { ctx, deployment } = await selectEnvDeployment(options);
+    await ensureHasConvexDependency(ctx, "env list");
+    await envListInDeployment(ctx, deployment);
+  });
+
+export const env = new Command("env")
+  .summary("Set and view environment variables")
+  .description(
+    "Set and view environment variables on your deployment\n\n" +
+      "  Set a variable: `npx convex env set NAME value`\n" +
+      "  Unset a variable: `npx convex env remove NAME`\n" +
+      "  List all variables: `npx convex env list`\n" +
+      "  Print a variable's value: `npx convex env get NAME`\n\n" +
+      "By default, this sets and views variables on your dev deployment.",
+  )
+  .addCommand(envSet)
+  .addCommand(envGet)
+  .addCommand(envRemove)
+  .addCommand(envList)
+  .addHelpCommand(false)
+  .addDeploymentSelectionOptions(
+    actionDescription("Set and view environment variables on"),
+  );
diff --git a/synced/convex/libs/cli/functionSpec.ts b/synced/convex/libs/cli/functionSpec.ts
new file mode 100644
index 0000000..fe97c49
--- /dev/null
+++ b/synced/convex/libs/cli/functionSpec.ts
@@ -0,0 +1,39 @@
+import { oneoffContext } from "../bundler/context.js";
+import {
+  deploymentSelectionWithinProjectFromOptions,
+  loadSelectedDeploymentCredentials,
+} from "./lib/api.js";
+import { Command, Option } from "@commander-js/extra-typings";
+import { actionDescription } from "./lib/command.js";
+import { functionSpecForDeployment } from "./lib/functionSpec.js";
+import { getDeploymentSelection } from "./lib/deploymentSelection.js";
+export const functionSpec = new Command("function-spec")
+  .summary("List function metadata from your deployment")
+  .description(
+    "List argument and return values to your Convex functions.\n\n" +
+      "By default, this inspects your dev deployment.",
+  )
+  .allowExcessArguments(false)
+  .addOption(new Option("--file", "Output as JSON to a file."))
+  .addDeploymentSelectionOptions(
+    actionDescription("Read function metadata from"),
+  )
+  .showHelpAfterError()
+  .action(async (options) => {
+    const ctx = await oneoffContext(options);
+    const deploymentSelection = await getDeploymentSelection(ctx, options);
+    const selectionWithinProject =
+      await deploymentSelectionWithinProjectFromOptions(ctx, options);
+    const { adminKey, url: deploymentUrl } =
+      await loadSelectedDeploymentCredentials(
+        ctx,
+        deploymentSelection,
+        selectionWithinProject,
+      );
+
+    await functionSpecForDeployment(ctx, {
+      deploymentUrl,
+      adminKey,
+      file: !!options.file,
+    });
+  });
diff --git a/synced/convex/libs/cli/index.ts b/synced/convex/libs/cli/index.ts
new file mode 100644
index 0000000..fb9497a
--- /dev/null
+++ b/synced/convex/libs/cli/index.ts
@@ -0,0 +1,133 @@
+import { Command } from "@commander-js/extra-typings";
+import { init } from "./init.js";
+import { dashboard } from "./dashboard.js";
+import { deployments } from "./deployments.js";
+import { docs } from "./docs.js";
+import { run } from "./run.js";
+import { version } from "./version.js";
+import { auth } from "./auth.js";
+import { codegen } from "./codegen.js";
+import { reinit } from "./reinit.js";
+import { update } from "./update.js";
+import { typecheck } from "./typecheck.js";
+import { login } from "./login.js";
+import { logout } from "./logout.js";
+import chalk from "chalk";
+import * as Sentry from "@sentry/node";
+import { initSentry } from "./lib/utils/sentry.js";
+import { dev } from "./dev.js";
+import { deploy } from "./deploy.js";
+import { logs } from "./logs.js";
+import { networkTest } from "./network_test.js";
+import { convexExport } from "./convexExport.js";
+import { convexImport } from "./convexImport.js";
+import { env } from "./env.js";
+import { data } from "./data.js";
+import inquirer from "inquirer";
+import inquirerSearchList from "inquirer-search-list";
+import { format } from "util";
+import { functionSpec } from "./functionSpec.js";
+import { disableLocalDeployments } from "./disableLocalDev.js";
+import { mcp } from "./mcp.js";
+import dns from "node:dns";
+
+const MINIMUM_MAJOR_VERSION = 16;
+const MINIMUM_MINOR_VERSION = 15;
+
+// console.error before it started being red by default in Node.js v20
+function logToStderr(...args: unknown[]) {
+  process.stderr.write(`${format(...args)}\n`);
+}
+
+async function main() {
+  // Use ipv4 first for 127.0.0.1 in tests
+  dns.setDefaultResultOrder("ipv4first");
+
+  initSentry();
+  inquirer.registerPrompt("search-list", inquirerSearchList);
+
+  const nodeVersion = process.versions.node;
+  const majorVersion = parseInt(nodeVersion.split(".")[0], 10);
+  const minorVersion = parseInt(nodeVersion.split(".")[1], 10);
+  if (
+    majorVersion < MINIMUM_MAJOR_VERSION ||
+    (majorVersion === MINIMUM_MAJOR_VERSION &&
+      minorVersion < MINIMUM_MINOR_VERSION)
+  ) {
+    logToStderr(
+      chalk.red(
+        `Your Node version ${nodeVersion} is too old. Convex requires at least Node v${MINIMUM_MAJOR_VERSION}.${MINIMUM_MINOR_VERSION}`,
+      ),
+    );
+    logToStderr(
+      chalk.gray(
+        `You can use ${chalk.bold(
+          "nvm",
+        )} (https://github.com/nvm-sh/nvm#installing-and-updating) to manage different versions of Node.`,
+      ),
+    );
+    logToStderr(
+      chalk.gray(
+        "After installing `nvm`, install the latest version of Node with " +
+          chalk.bold("`nvm install node`."),
+      ),
+    );
+    logToStderr(
+      chalk.gray(
+        "Then, activate the installed version in your terminal with " +
+          chalk.bold("`nvm use`."),
+      ),
+    );
+    process.exit(1);
+  }
+
+  const program = new Command();
+  program
+    .name("convex")
+    .usage("<command> [options]")
+    .description("Start developing with Convex by running `npx convex dev`.")
+    .addCommand(login, { hidden: true })
+    .addCommand(init, { hidden: true })
+    .addCommand(reinit, { hidden: true })
+    .addCommand(dev)
+    .addCommand(deploy)
+    .addCommand(deployments, { hidden: true })
+    .addCommand(run)
+    .addCommand(convexImport)
+    .addCommand(dashboard)
+    .addCommand(docs)
+    .addCommand(logs)
+    .addCommand(typecheck, { hidden: true })
+    .addCommand(auth, { hidden: true })
+    .addCommand(convexExport)
+    .addCommand(env)
+    .addCommand(data)
+    .addCommand(codegen)
+    .addCommand(update)
+    .addCommand(logout)
+    .addCommand(networkTest, { hidden: true })
+    .addCommand(functionSpec)
+    .addCommand(disableLocalDeployments)
+    .addCommand(mcp)
+    .addHelpCommand("help <command>", "Show help for given <command>")
+    .version(version)
+    // Hide version and help so they don't clutter
+    // the list of commands.
+    .configureHelp({ visibleOptions: () => [] })
+    .showHelpAfterError();
+
+  // Run the command and be sure to flush Sentry before exiting.
+  try {
+    await program.parseAsync(process.argv);
+  } catch (e) {
+    Sentry.captureException(e);
+    process.exitCode = 1;
+    // This is too early to use `logError`, so just log directly.
+    // eslint-disable-next-line no-console
+    console.error(chalk.red("Unexpected Error: " + e));
+  } finally {
+    await Sentry.close();
+  }
+  process.exit();
+}
+void main();
diff --git a/synced/convex/libs/cli/init.ts b/synced/convex/libs/cli/init.ts
new file mode 100644
index 0000000..2ebe534
--- /dev/null
+++ b/synced/convex/libs/cli/init.ts
@@ -0,0 +1,40 @@
+import { Command, Option } from "@commander-js/extra-typings";
+import path from "path";
+import { oneoffContext } from "../bundler/context.js";
+
+const cwd = path.basename(process.cwd());
+
+// Initialize a new Convex project.
+// This command is deprecated and hidden from the command help.
+// `npx convex dev --once --configure=new` replaces it.
+export const init = new Command("init")
+  .description("Initialize a new Convex project in the current directory")
+  .allowExcessArguments(false)
+  .addOption(
+    new Option(
+      "--project <name>",
+      `Name of the project to create. Defaults to \`${cwd}\` (the current directory)`,
+    ),
+  )
+  .addOption(
+    new Option(
+      "--team <slug>",
+      "Slug identifier for the team this project will belong to.",
+    ),
+  )
+  .action(async (_options) => {
+    return (
+      await oneoffContext({
+        url: undefined,
+        adminKey: undefined,
+        envFile: undefined,
+      })
+    ).crash({
+      exitCode: 1,
+      errorType: "fatal",
+      errForSentry:
+        "The `init` command is deprecated. Use `npx convex dev --once --configure=new` instead.",
+      printedMessage:
+        "The `init` command is deprecated. Use `npx convex dev --once --configure=new` instead.",
+    });
+  });
diff --git a/synced/convex/libs/cli/lib/api.ts b/synced/convex/libs/cli/lib/api.ts
new file mode 100644
index 0000000..107be0a
--- /dev/null
+++ b/synced/convex/libs/cli/lib/api.ts
@@ -0,0 +1,829 @@
+import { Context, logVerbose, logWarning } from "../../bundler/context.js";
+import { getTeamAndProjectFromPreviewAdminKey } from "./deployment.js";
+import {
+  assertLocalBackendRunning,
+  localDeploymentUrl,
+} from "./localDeployment/run.js";
+import {
+  ThrowingFetchError,
+  bigBrainAPI,
+  bigBrainAPIMaybeThrows,
+  logAndHandleFetchError,
+} from "./utils/utils.js";
+import { z } from "zod";
+import {
+  DeploymentSelection,
+  ProjectSelection,
+} from "./deploymentSelection.js";
+import { loadLocalDeploymentCredentials } from "./localDeployment/localDeployment.js";
+import { loadAnonymousDeployment } from "./localDeployment/anonymous.js";
+export type DeploymentName = string;
+export type CloudDeploymentType = "prod" | "dev" | "preview";
+export type AccountRequiredDeploymentType = CloudDeploymentType | "local";
+export type DeploymentType = AccountRequiredDeploymentType | "anonymous";
+
+export type Project = {
+  id: string;
+  name: string;
+  slug: string;
+  isDemo: boolean;
+};
+
+type AdminKey = string;
+
+// Provision a new project, creating a deployment of type `deploymentTypeToProvision`
+export async function createProject(
+  ctx: Context,
+  {
+    teamSlug: selectedTeamSlug,
+    projectName,
+    partitionId,
+    deploymentTypeToProvision,
+  }: {
+    teamSlug: string;
+    projectName: string;
+    partitionId?: number;
+    deploymentTypeToProvision: "prod" | "dev";
+  },
+): Promise<{
+  projectSlug: string;
+  teamSlug: string;
+  projectsRemaining: number;
+}> {
+  const provisioningArgs = {
+    team: selectedTeamSlug,
+    projectName,
+    // TODO: Consider allowing projects with no deployments, or consider switching
+    // to provisioning prod on creation.
+    deploymentType: deploymentTypeToProvision,
+    partitionId,
+  };
+  const data = await bigBrainAPI({
+    ctx,
+    method: "POST",
+    url: "create_project",
+    data: provisioningArgs,
+  });
+  const { projectSlug, teamSlug, projectsRemaining } = data;
+  if (
+    projectSlug === undefined ||
+    teamSlug === undefined ||
+    projectsRemaining === undefined
+  ) {
+    const error =
+      "Unexpected response during provisioning: " + JSON.stringify(data);
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "transient",
+      errForSentry: error,
+      printedMessage: error,
+    });
+  }
+  return {
+    projectSlug,
+    teamSlug,
+    projectsRemaining,
+  };
+}
+
+// ----------------------------------------------------------------------
+// Helpers for `deploymentSelectionFromOptions`
+// ----------------------------------------------------------------------
+
+export const deploymentSelectionWithinProjectSchema = z.discriminatedUnion(
+  "kind",
+  [
+    z.object({ kind: z.literal("previewName"), previewName: z.string() }),
+    z.object({ kind: z.literal("deploymentName"), deploymentName: z.string() }),
+    z.object({ kind: z.literal("prod"), partitionId: z.number().optional() }),
+    z.object({
+      kind: z.literal("implicitProd"),
+      partitionId: z.number().optional(),
+    }),
+    z.object({ kind: z.literal("ownDev"), partitionId: z.number().optional() }),
+  ],
+);
+
+export type DeploymentSelectionWithinProject = z.infer<
+  typeof deploymentSelectionWithinProjectSchema
+>;
+
+type DeploymentSelectionOptionsWithinProject = {
+  prod?: boolean | undefined;
+  // Whether this command defaults to prod when no other flags are provided. If
+  // this is not set, the default will be "ownDev"
+  implicitProd?: boolean;
+
+  previewName?: string | undefined;
+  deploymentName?: string | undefined;
+  partitionId?: string | undefined;
+};
+
+export type DeploymentSelectionOptions =
+  DeploymentSelectionOptionsWithinProject & {
+    url?: string | undefined;
+    adminKey?: string | undefined;
+    envFile?: string | undefined;
+  };
+
+export async function deploymentSelectionWithinProjectFromOptions(
+  ctx: Context,
+  options: DeploymentSelectionOptions,
+): Promise<DeploymentSelectionWithinProject> {
+  if (options.previewName !== undefined) {
+    return { kind: "previewName", previewName: options.previewName };
+  }
+  if (options.deploymentName !== undefined) {
+    return { kind: "deploymentName", deploymentName: options.deploymentName };
+  }
+  const partitionId = options.partitionId
+    ? parseInt(options.partitionId)
+    : undefined;
+  if (options.prod) {
+    return { kind: "prod", partitionId };
+  }
+  if (options.implicitProd) {
+    return { kind: "implicitProd", partitionId };
+  }
+  return { kind: "ownDev", partitionId };
+}
+
+export async function validateDeploymentSelectionForExistingDeployment(
+  ctx: Context,
+  deploymentSelection: DeploymentSelectionWithinProject,
+  source: "selfHosted" | "deployKey" | "cliArgs",
+) {
+  if (
+    deploymentSelection.kind === "ownDev" ||
+    deploymentSelection.kind === "implicitProd"
+  ) {
+    // These are both considered the "default" selection depending on the command, so this is always fine
+    return;
+  }
+  switch (source) {
+    case "selfHosted":
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage:
+          "The `--prod`, `--preview-name`, and `--deployment-name` flags cannot be used with a self-hosted deployment.",
+      });
+    case "deployKey":
+      logWarning(
+        ctx,
+        "Ignoring `--prod`, `--preview-name`, or `--deployment-name` flags and using deployment from CONVEX_DEPLOY_KEY",
+      );
+      break;
+    case "cliArgs":
+      logWarning(
+        ctx,
+        "Ignoring `--prod`, `--preview-name`, or `--deployment-name` flags since this command was run with --url and --admin-key",
+      );
+      break;
+  }
+}
+
+// ----------------------------------------------------------------------
+// Helpers for `checkAccessToSelectedProject`
+// ----------------------------------------------------------------------
+
+async function hasAccessToProject(
+  ctx: Context,
+  selector: { projectSlug: string; teamSlug: string },
+): Promise<boolean> {
+  try {
+    await bigBrainAPIMaybeThrows({
+      ctx,
+      url: `/api/teams/${selector.teamSlug}/projects/${selector.projectSlug}/deployments`,
+      method: "GET",
+    });
+    return true;
+  } catch (err) {
+    if (
+      err instanceof ThrowingFetchError &&
+      (err.serverErrorData?.code === "TeamNotFound" ||
+        err.serverErrorData?.code === "ProjectNotFound")
+    ) {
+      return false;
+    }
+    return logAndHandleFetchError(ctx, err);
+  }
+}
+
+export async function checkAccessToSelectedProject(
+  ctx: Context,
+  projectSelection: ProjectSelection,
+): Promise<
+  | { kind: "hasAccess"; teamSlug: string; projectSlug: string }
+  | { kind: "noAccess" }
+  | { kind: "unknown" }
+> {
+  switch (projectSelection.kind) {
+    case "deploymentName": {
+      const result = await getTeamAndProjectSlugForDeployment(ctx, {
+        deploymentName: projectSelection.deploymentName,
+      });
+      if (result === null) {
+        return { kind: "noAccess" };
+      }
+      return {
+        kind: "hasAccess",
+        teamSlug: result.teamSlug,
+        projectSlug: result.projectSlug,
+      };
+    }
+    case "teamAndProjectSlugs": {
+      const hasAccess = await hasAccessToProject(ctx, {
+        teamSlug: projectSelection.teamSlug,
+        projectSlug: projectSelection.projectSlug,
+      });
+      if (!hasAccess) {
+        return { kind: "noAccess" };
+      }
+      return {
+        kind: "hasAccess",
+        teamSlug: projectSelection.teamSlug,
+        projectSlug: projectSelection.projectSlug,
+      };
+    }
+    case "projectDeployKey":
+      // Ideally we would be able to do an explicit check here, but if the key is invalid,
+      // it will instead fail as soon as we try to use the key.
+      return { kind: "unknown" };
+    default: {
+      const _exhaustivenessCheck: never = projectSelection;
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage: `Invalid project selection: ${(projectSelection as any).kind}`,
+      });
+    }
+  }
+}
+
+async function getTeamAndProjectSlugForDeployment(
+  ctx: Context,
+  selector: { deploymentName: string },
+): Promise<{ teamSlug: string; projectSlug: string } | null> {
+  try {
+    const body = await bigBrainAPIMaybeThrows({
+      ctx,
+      url: `/api/deployment/${selector.deploymentName}/team_and_project`,
+      method: "GET",
+    });
+    return { teamSlug: body.team, projectSlug: body.project };
+  } catch (err) {
+    if (
+      err instanceof ThrowingFetchError &&
+      (err.serverErrorData?.code === "DeploymentNotFound" ||
+        err.serverErrorData?.code === "ProjectNotFound")
+    ) {
+      return null;
+    }
+    return logAndHandleFetchError(ctx, err);
+  }
+}
+
+// ----------------------------------------------------------------------
+// Helpers for fetching deployment credentials
+// ----------------------------------------------------------------------
+
+// Used by dev for upgrade from team and project in convex.json to CONVEX_DEPLOYMENT
+export async function fetchDeploymentCredentialsProvisioningDevOrProdMaybeThrows(
+  ctx: Context,
+  projectSelection:
+    | { kind: "teamAndProjectSlugs"; teamSlug: string; projectSlug: string }
+    | { kind: "projectDeployKey"; projectDeployKey: string },
+  deploymentType: "prod" | "dev",
+  partitionId: number | undefined,
+): Promise<{
+  deploymentName: string;
+  deploymentUrl: string;
+  adminKey: AdminKey;
+}> {
+  if (projectSelection.kind === "projectDeployKey") {
+    const auth = ctx.bigBrainAuth();
+    const doesAuthMatch =
+      auth !== null &&
+      auth.kind === "projectKey" &&
+      auth.projectKey === projectSelection.projectDeployKey;
+    if (!doesAuthMatch) {
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        errForSentry: new Error(
+          "Expected project deploy key to match the big brain auth header",
+        ),
+        printedMessage: "Unexpected error when loading the Convex deployment",
+      });
+    }
+  }
+  let data;
+  try {
+    data = await bigBrainAPIMaybeThrows({
+      ctx,
+      method: "POST",
+      url: "deployment/provision_and_authorize",
+      data: {
+        teamSlug:
+          projectSelection.kind === "teamAndProjectSlugs"
+            ? projectSelection.teamSlug
+            : null,
+        projectSlug:
+          projectSelection.kind === "teamAndProjectSlugs"
+            ? projectSelection.projectSlug
+            : null,
+        deploymentType: deploymentType === "prod" ? "prod" : "dev",
+        partitionId,
+      },
+    });
+  } catch (error) {
+    const msg = "Unknown error during authorization: " + error;
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "transient",
+      errForSentry: new Error(msg),
+      printedMessage: msg,
+    });
+  }
+  const adminKey = data.adminKey;
+  const url = data.url;
+  const deploymentName = data.deploymentName;
+  if (adminKey === undefined || url === undefined) {
+    const msg = "Unknown error during authorization: " + JSON.stringify(data);
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "transient",
+      errForSentry: new Error(msg),
+      printedMessage: msg,
+    });
+  }
+  return { adminKey, deploymentUrl: url, deploymentName };
+}
+
+async function fetchExistingDevDeploymentCredentialsOrCrash(
+  ctx: Context,
+  deploymentName: DeploymentName,
+): Promise<{
+  deploymentName: string;
+  adminKey: string;
+  url: string;
+  deploymentType: DeploymentType;
+}> {
+  const slugs = await fetchTeamAndProject(ctx, deploymentName);
+  const credentials =
+    await fetchDeploymentCredentialsProvisioningDevOrProdMaybeThrows(
+      ctx,
+      {
+        kind: "teamAndProjectSlugs",
+        teamSlug: slugs.team,
+        projectSlug: slugs.project,
+      },
+      "dev",
+      undefined,
+    );
+  return {
+    deploymentName: credentials.deploymentName,
+    adminKey: credentials.adminKey,
+    url: credentials.deploymentUrl,
+    deploymentType: "dev",
+  };
+}
+
+// ----------------------------------------------------------------------
+// Helpers for `loadSelectedDeploymentCredentials`
+// ----------------------------------------------------------------------
+
+async function handleOwnDev(
+  ctx: Context,
+  projectSelection: ProjectSelection,
+  partitionId: number | undefined,
+): Promise<{
+  deploymentName: string;
+  adminKey: string;
+  url: string;
+  deploymentType: DeploymentType;
+}> {
+  switch (projectSelection.kind) {
+    case "deploymentName": {
+      if (projectSelection.deploymentType === "local") {
+        const credentials = await loadLocalDeploymentCredentials(
+          ctx,
+          projectSelection.deploymentName,
+        );
+        return {
+          deploymentName: projectSelection.deploymentName,
+          adminKey: credentials.adminKey,
+          url: credentials.deploymentUrl,
+          deploymentType: "local",
+        };
+      }
+      return await fetchExistingDevDeploymentCredentialsOrCrash(
+        ctx,
+        projectSelection.deploymentName,
+      );
+    }
+    case "teamAndProjectSlugs":
+    case "projectDeployKey": {
+      // Note -- this provisions a dev deployment if one doesn't exist
+      const credentials =
+        await fetchDeploymentCredentialsProvisioningDevOrProdMaybeThrows(
+          ctx,
+          projectSelection,
+          "dev",
+          partitionId,
+        );
+      return {
+        url: credentials.deploymentUrl,
+        adminKey: credentials.adminKey,
+        deploymentName: credentials.deploymentName,
+        deploymentType: "dev",
+      };
+    }
+  }
+}
+
+async function handleProd(
+  ctx: Context,
+  projectSelection: ProjectSelection,
+  partitionId: number | undefined,
+): Promise<{
+  deploymentName: string;
+  adminKey: string;
+  url: string;
+  deploymentType: "prod";
+}> {
+  switch (projectSelection.kind) {
+    case "deploymentName": {
+      const credentials = await bigBrainAPI({
+        ctx,
+        method: "POST",
+        url: "deployment/authorize_prod",
+        data: {
+          deploymentName: projectSelection.deploymentName,
+          partitionId: partitionId,
+        },
+      });
+      return credentials;
+    }
+    case "teamAndProjectSlugs":
+    case "projectDeployKey": {
+      const credentials =
+        await fetchDeploymentCredentialsProvisioningDevOrProdMaybeThrows(
+          ctx,
+          projectSelection,
+          "prod",
+          partitionId,
+        );
+      return {
+        url: credentials.deploymentUrl,
+        adminKey: credentials.adminKey,
+        deploymentName: credentials.deploymentName,
+        deploymentType: "prod",
+      };
+    }
+  }
+}
+
+async function handlePreview(
+  ctx: Context,
+  previewName: string,
+  projectSelection: ProjectSelection,
+): Promise<{
+  deploymentName: string;
+  adminKey: string;
+  url: string;
+  deploymentType: "preview";
+}> {
+  switch (projectSelection.kind) {
+    case "deploymentName":
+    case "teamAndProjectSlugs":
+      return await bigBrainAPI({
+        ctx,
+        method: "POST",
+        url: "deployment/authorize_preview",
+        data: {
+          previewName: previewName,
+          projectSelection: projectSelection,
+        },
+      });
+
+    case "projectDeployKey":
+      // TODO -- this should be supported
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage:
+          "Project deploy keys are not supported for preview deployments",
+      });
+  }
+}
+
+async function handleDeploymentName(
+  ctx: Context,
+  deploymentName: string,
+  projectSelection: ProjectSelection,
+): Promise<{
+  deploymentName: string;
+  adminKey: string;
+  url: string;
+  deploymentType: DeploymentType;
+}> {
+  switch (projectSelection.kind) {
+    case "deploymentName":
+    case "teamAndProjectSlugs":
+      return await bigBrainAPI({
+        ctx,
+        method: "POST",
+        url: "deployment/authorize_within_current_project",
+        data: {
+          selectedDeploymentName: deploymentName,
+          projectSelection: projectSelection,
+        },
+      });
+    case "projectDeployKey":
+      // TODO -- this should be supported
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage:
+          "Project deploy keys are not supported with the --deployment-name flag",
+      });
+  }
+}
+
+async function fetchDeploymentCredentialsWithinCurrentProject(
+  ctx: Context,
+  projectSelection: ProjectSelection,
+  deploymentSelection: DeploymentSelectionWithinProject,
+): Promise<{
+  deploymentName: string;
+  adminKey: string;
+  url: string;
+  deploymentType: DeploymentType;
+}> {
+  switch (deploymentSelection.kind) {
+    case "ownDev": {
+      return await handleOwnDev(
+        ctx,
+        projectSelection,
+        deploymentSelection.partitionId,
+      );
+    }
+    case "implicitProd":
+    case "prod": {
+      return await handleProd(
+        ctx,
+        projectSelection,
+        deploymentSelection.partitionId,
+      );
+    }
+    case "previewName":
+      return await handlePreview(
+        ctx,
+        deploymentSelection.previewName,
+        projectSelection,
+      );
+    case "deploymentName":
+      return await handleDeploymentName(
+        ctx,
+        deploymentSelection.deploymentName,
+        projectSelection,
+      );
+    default: {
+      const _exhaustivenessCheck: never = deploymentSelection;
+      return ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        // This should be unreachable, so don't bother with a printed message.
+        printedMessage: null,
+        errForSentry: `Unexpected deployment selection: ${deploymentSelection as any}`,
+      });
+    }
+  }
+}
+
+async function _loadExistingDeploymentCredentialsForProject(
+  ctx: Context,
+  targetProject: ProjectSelection,
+  deploymentSelection: DeploymentSelectionWithinProject,
+  { ensureLocalRunning } = { ensureLocalRunning: true },
+): Promise<{
+  adminKey: string;
+  url: string;
+  deploymentFields: {
+    deploymentName: string;
+    deploymentType: DeploymentType;
+    projectSlug: string | null;
+    teamSlug: string | null;
+  } | null;
+}> {
+  const accessResult = await checkAccessToSelectedProject(ctx, targetProject);
+  if (accessResult.kind === "noAccess") {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage:
+        "You don't have access to the selected project. Run `npx convex dev` to select a different project.",
+    });
+  }
+  const result = await fetchDeploymentCredentialsWithinCurrentProject(
+    ctx,
+    targetProject,
+    deploymentSelection,
+  );
+  logVerbose(
+    ctx,
+    `Deployment URL: ${result.url}, Deployment Name: ${result.deploymentName}, Deployment Type: ${result.deploymentType}`,
+  );
+  if (ensureLocalRunning && result.deploymentType === "local") {
+    await assertLocalBackendRunning(ctx, {
+      url: result.url,
+      deploymentName: result.deploymentName,
+    });
+  }
+  return {
+    ...result,
+    deploymentFields: {
+      deploymentName: result.deploymentName,
+      deploymentType: result.deploymentType,
+
+      projectSlug:
+        accessResult.kind === "hasAccess" ? accessResult.projectSlug : null,
+      teamSlug:
+        accessResult.kind === "hasAccess" ? accessResult.teamSlug : null,
+    },
+  };
+}
+// This is used by most commands (notably not `dev` and `deploy`) to determine
+// which deployment to act on, taking into account the deployment selection flags.
+//
+export async function loadSelectedDeploymentCredentials(
+  ctx: Context,
+  deploymentSelection: DeploymentSelection,
+  selectionWithinProject: DeploymentSelectionWithinProject,
+  { ensureLocalRunning } = { ensureLocalRunning: true },
+): Promise<{
+  adminKey: string;
+  url: string;
+  deploymentFields: {
+    deploymentName: string;
+    deploymentType: DeploymentType;
+    projectSlug: string | null;
+    teamSlug: string | null;
+  } | null;
+}> {
+  switch (deploymentSelection.kind) {
+    case "existingDeployment":
+      await validateDeploymentSelectionForExistingDeployment(
+        ctx,
+        selectionWithinProject,
+        deploymentSelection.deploymentToActOn.source,
+      );
+      // We're already set up.
+      logVerbose(
+        ctx,
+        `Deployment URL: ${deploymentSelection.deploymentToActOn.url}, Deployment Name: ${deploymentSelection.deploymentToActOn.deploymentFields?.deploymentName ?? "unknown"}, Deployment Type: ${deploymentSelection.deploymentToActOn.deploymentFields?.deploymentType ?? "unknown"}`,
+      );
+      return {
+        adminKey: deploymentSelection.deploymentToActOn.adminKey,
+        url: deploymentSelection.deploymentToActOn.url,
+        deploymentFields:
+          deploymentSelection.deploymentToActOn.deploymentFields,
+      };
+    case "chooseProject":
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage:
+          "No CONVEX_DEPLOYMENT set, run `npx convex dev` to configure a Convex project",
+      });
+    case "preview": {
+      const slugs = await getTeamAndProjectFromPreviewAdminKey(
+        ctx,
+        deploymentSelection.previewDeployKey,
+      );
+      return await _loadExistingDeploymentCredentialsForProject(
+        ctx,
+        {
+          kind: "teamAndProjectSlugs",
+          teamSlug: slugs.teamSlug,
+          projectSlug: slugs.projectSlug,
+        },
+        selectionWithinProject,
+        { ensureLocalRunning },
+      );
+    }
+    case "deploymentWithinProject": {
+      return await _loadExistingDeploymentCredentialsForProject(
+        ctx,
+        deploymentSelection.targetProject,
+        selectionWithinProject,
+        { ensureLocalRunning },
+      );
+    }
+    case "anonymous": {
+      if (deploymentSelection.deploymentName === null) {
+        return await ctx.crash({
+          exitCode: 1,
+          errorType: "fatal",
+          printedMessage:
+            "No CONVEX_DEPLOYMENT set, run `npx convex dev` to configure a Convex project",
+        });
+      }
+      const config = await loadAnonymousDeployment(
+        ctx,
+        deploymentSelection.deploymentName,
+      );
+      const url = localDeploymentUrl(config.ports.cloud);
+      if (ensureLocalRunning) {
+        await assertLocalBackendRunning(ctx, {
+          url,
+          deploymentName: deploymentSelection.deploymentName,
+        });
+      }
+      return {
+        adminKey: config.adminKey,
+        url,
+        deploymentFields: {
+          deploymentName: deploymentSelection.deploymentName,
+          deploymentType: "anonymous",
+          projectSlug: null,
+          teamSlug: null,
+        },
+      };
+    }
+    default: {
+      const _exhaustivenessCheck: never = deploymentSelection;
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage: "Unknown deployment type",
+      });
+    }
+  }
+}
+
+export async function fetchTeamAndProject(
+  ctx: Context,
+  deploymentName: string,
+) {
+  const data = (await bigBrainAPI({
+    ctx,
+    method: "GET",
+    url: `deployment/${deploymentName}/team_and_project`,
+  })) as {
+    team: string; // slug
+    project: string; // slug
+    teamId: number;
+    projectId: number;
+  };
+
+  const { team, project } = data;
+  if (team === undefined || project === undefined) {
+    const msg =
+      "Unknown error when fetching team and project: " + JSON.stringify(data);
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "transient",
+      errForSentry: new Error(msg),
+      printedMessage: msg,
+    });
+  }
+
+  return data;
+}
+
+export async function fetchTeamAndProjectForKey(
+  ctx: Context,
+  // Deployment deploy key, like `prod:happy-animal-123|<stuff>`
+  deployKey: string,
+) {
+  const data = (await bigBrainAPI({
+    ctx,
+    method: "POST",
+    url: `deployment/team_and_project_for_key`,
+    data: {
+      deployKey: deployKey,
+    },
+  })) as {
+    team: string; // slug
+    project: string; // slug
+    teamId: number;
+    projectId: number;
+  };
+
+  const { team, project } = data;
+  if (team === undefined || project === undefined) {
+    const msg =
+      "Unknown error when fetching team and project: " + JSON.stringify(data);
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "transient",
+      errForSentry: new Error(msg),
+      printedMessage: msg,
+    });
+  }
+
+  return data;
+}
diff --git a/synced/convex/libs/cli/lib/codegen.ts b/synced/convex/libs/cli/lib/codegen.ts
new file mode 100644
index 0000000..472ff96
--- /dev/null
+++ b/synced/convex/libs/cli/lib/codegen.ts
@@ -0,0 +1,648 @@
+import path from "path";
+import prettier from "prettier";
+import { withTmpDir, TempDir } from "../../bundler/fs.js";
+import { entryPoints } from "../../bundler/index.js";
+import { apiCodegen } from "../codegen_templates/api.js";
+import { apiCjsCodegen } from "../codegen_templates/api_cjs.js";
+import {
+  dynamicDataModelDTS,
+  noSchemaDataModelDTS,
+  staticDataModelDTS,
+} from "../codegen_templates/dataModel.js";
+import { readmeCodegen } from "../codegen_templates/readme.js";
+import { serverCodegen } from "../codegen_templates/server.js";
+import { tsconfigCodegen } from "../codegen_templates/tsconfig.js";
+import {
+  Context,
+  logError,
+  logMessage,
+  logOutput,
+  logVerbose,
+} from "../../bundler/context.js";
+import { typeCheckFunctionsInMode, TypeCheckMode } from "./typecheck.js";
+import { readProjectConfig } from "./config.js";
+import { recursivelyDelete } from "./fsUtils.js";
+import {
+  componentServerDTS,
+  componentServerJS,
+  componentServerStubDTS,
+} from "../codegen_templates/component_server.js";
+import { ComponentDirectory } from "./components/definition/directoryStructure.js";
+import { StartPushResponse } from "./deployApi/startPush.js";
+import {
+  componentApiDTS,
+  componentApiJs,
+  componentApiStubDTS,
+  rootComponentApiCJS,
+} from "../codegen_templates/component_api.js";
+
+export type CodegenOptions = {
+  url?: string;
+  adminKey?: string;
+  dryRun: boolean;
+  debug: boolean;
+  typecheck: TypeCheckMode;
+  init: boolean;
+  commonjs: boolean;
+  liveComponentSources: boolean;
+};
+
+export async function doInitCodegen(
+  ctx: Context,
+  functionsDir: string,
+  skipIfExists: boolean,
+  opts?: { dryRun?: boolean; debug?: boolean },
+): Promise<void> {
+  await prepareForCodegen(ctx, functionsDir, opts);
+  await withTmpDir(async (tmpDir) => {
+    await doReadmeCodegen(ctx, tmpDir, functionsDir, skipIfExists, opts);
+    await doTsconfigCodegen(ctx, tmpDir, functionsDir, skipIfExists, opts);
+  });
+}
+
+async function prepareForCodegen(
+  ctx: Context,
+  functionsDir: string,
+  opts?: { dryRun?: boolean },
+) {
+  // Delete the old _generated.ts because v0.1.2 used to put the react generated
+  // code there
+  const legacyCodegenPath = path.join(functionsDir, "_generated.ts");
+  if (ctx.fs.exists(legacyCodegenPath)) {
+    if (opts?.dryRun) {
+      logError(
+        ctx,
+        `Command would delete legacy codegen file: ${legacyCodegenPath}}`,
+      );
+    } else {
+      logError(ctx, `Deleting legacy codegen file: ${legacyCodegenPath}}`);
+      ctx.fs.unlink(legacyCodegenPath);
+    }
+  }
+
+  // Create the codegen dir if it doesn't already exist.
+  const codegenDir = path.join(functionsDir, "_generated");
+  ctx.fs.mkdir(codegenDir, { allowExisting: true, recursive: true });
+  return codegenDir;
+}
+
+export async function doCodegen(
+  ctx: Context,
+  functionsDir: string,
+  typeCheckMode: TypeCheckMode,
+  opts?: { dryRun?: boolean; generateCommonJSApi?: boolean; debug?: boolean },
+) {
+  const { projectConfig } = await readProjectConfig(ctx);
+  const codegenDir = await prepareForCodegen(ctx, functionsDir, opts);
+
+  await withTmpDir(async (tmpDir) => {
+    // Write files in dependency order so a watching dev server doesn't
+    // see inconsistent results where a file we write imports from a
+    // file that doesn't exist yet. We'll collect all the paths we write
+    // and then delete any remaining paths at the end.
+    const writtenFiles = [];
+
+    // First, `dataModel.d.ts` imports from the developer's `schema.js` file.
+    const schemaFiles = await doDataModelCodegen(
+      ctx,
+      tmpDir,
+      functionsDir,
+      codegenDir,
+      opts,
+    );
+    writtenFiles.push(...schemaFiles);
+
+    // Next, the `server.d.ts` file imports from `dataModel.d.ts`.
+    const serverFiles = await doServerCodegen(ctx, tmpDir, codegenDir, opts);
+    writtenFiles.push(...serverFiles);
+
+    // The `api.d.ts` file imports from the developer's modules, which then
+    // import from `server.d.ts`. Note that there's a cycle here, since the
+    // developer's modules could also import from the `api.{js,d.ts}` files.
+    const apiFiles = await doApiCodegen(
+      ctx,
+      tmpDir,
+      functionsDir,
+      codegenDir,
+      opts?.generateCommonJSApi || projectConfig.generateCommonJSApi,
+      opts,
+    );
+    writtenFiles.push(...apiFiles);
+
+    // Cleanup any files that weren't written in this run.
+    for (const file of ctx.fs.listDir(codegenDir)) {
+      if (!writtenFiles.includes(file.name)) {
+        recursivelyDelete(ctx, path.join(codegenDir, file.name), opts);
+      }
+    }
+
+    // Generated code is updated, typecheck the query and mutation functions.
+    await typeCheckFunctionsInMode(ctx, typeCheckMode, functionsDir);
+  });
+}
+
+export async function doInitialComponentCodegen(
+  ctx: Context,
+  tmpDir: TempDir,
+  componentDirectory: ComponentDirectory,
+  opts?: {
+    dryRun?: boolean;
+    generateCommonJSApi?: boolean;
+    debug?: boolean;
+    verbose?: boolean;
+  },
+) {
+  const { projectConfig } = await readProjectConfig(ctx);
+
+  // This component defined in a dist directory; it is probably in a node_module
+  // directory, installed from a package. It is stuck with the files it has.
+  // Heuristics for this:
+  // - component definition has a dist/ directory as an ancestor
+  // - component definition is a .js file
+  // - presence of .js.map files
+  // We may improve this heuristic.
+  const isPublishedPackage =
+    componentDirectory.definitionPath.endsWith(".js") &&
+    !componentDirectory.isRoot;
+  if (isPublishedPackage) {
+    if (opts?.verbose) {
+      logMessage(
+        ctx,
+        `skipping initial codegen for installed package ${componentDirectory.path}`,
+      );
+    }
+    return;
+  }
+
+  const codegenDir = await prepareForCodegen(
+    ctx,
+    componentDirectory.path,
+    opts,
+  );
+
+  // Write files in dependency order so a watching dev server doesn't
+  // see inconsistent results where a file we write imports from a
+  // file that doesn't exist yet. We'll collect all the paths we write
+  // and then delete any remaining paths at the end.
+  const writtenFiles = [];
+
+  // First, `dataModel.d.ts` imports from the developer's `schema.js` file.
+  const dataModelFiles = await doInitialComponentDataModelCodegen(
+    ctx,
+    tmpDir,
+    componentDirectory,
+    codegenDir,
+    opts,
+  );
+  writtenFiles.push(...dataModelFiles);
+
+  // Next, the `server.d.ts` file imports from `dataModel.d.ts`.
+  const serverFiles = await doInitialComponentServerCodegen(
+    ctx,
+    componentDirectory.isRoot,
+    tmpDir,
+    codegenDir,
+    opts,
+  );
+  writtenFiles.push(...serverFiles);
+
+  // The `api.d.ts` file imports from the developer's modules, which then
+  // import from `server.d.ts`. Note that there's a cycle here, since the
+  // developer's modules could also import from the `api.{js,d.ts}` files.
+  const apiFiles = await doInitialComponentApiCodegen(
+    ctx,
+    componentDirectory.isRoot,
+    tmpDir,
+    codegenDir,
+    opts?.generateCommonJSApi || projectConfig.generateCommonJSApi,
+    opts,
+  );
+  writtenFiles.push(...apiFiles);
+
+  // Cleanup any files that weren't written in this run.
+  for (const file of ctx.fs.listDir(codegenDir)) {
+    if (!writtenFiles.includes(file.name)) {
+      recursivelyDelete(ctx, path.join(codegenDir, file.name), opts);
+    }
+  }
+}
+
+export async function doFinalComponentCodegen(
+  ctx: Context,
+  tmpDir: TempDir,
+  rootComponent: ComponentDirectory,
+  componentDirectory: ComponentDirectory,
+  startPushResponse: StartPushResponse,
+  opts?: {
+    dryRun?: boolean;
+    debug?: boolean;
+    generateCommonJSApi?: boolean;
+  },
+) {
+  const { projectConfig } = await readProjectConfig(ctx);
+
+  const isPublishedPackage =
+    componentDirectory.definitionPath.endsWith(".js") &&
+    !componentDirectory.isRoot;
+  if (isPublishedPackage) {
+    return;
+  }
+
+  const codegenDir = path.join(componentDirectory.path, "_generated");
+  ctx.fs.mkdir(codegenDir, { allowExisting: true, recursive: true });
+
+  // `dataModel.d.ts`, `server.d.ts` and `api.d.ts` depend on analyze results, where we
+  // replace the stub generated during initial codegen with a more precise type.
+  const hasSchemaFile = schemaFileExists(ctx, componentDirectory.path);
+  let dataModelContents: string;
+  if (hasSchemaFile) {
+    if (projectConfig.codegen.staticDataModel) {
+      dataModelContents = await staticDataModelDTS(
+        ctx,
+        startPushResponse,
+        rootComponent,
+        componentDirectory,
+      );
+    } else {
+      dataModelContents = dynamicDataModelDTS();
+    }
+  } else {
+    dataModelContents = noSchemaDataModelDTS();
+  }
+  const dataModelDTSPath = path.join(codegenDir, "dataModel.d.ts");
+  await writeFormattedFile(
+    ctx,
+    tmpDir,
+    dataModelContents,
+    "typescript",
+    dataModelDTSPath,
+    opts,
+  );
+
+  const serverDTSPath = path.join(codegenDir, "server.d.ts");
+  const serverContents = await componentServerDTS(componentDirectory);
+  await writeFormattedFile(
+    ctx,
+    tmpDir,
+    serverContents,
+    "typescript",
+    serverDTSPath,
+    opts,
+  );
+
+  const apiDTSPath = path.join(codegenDir, "api.d.ts");
+  const apiContents = await componentApiDTS(
+    ctx,
+    startPushResponse,
+    rootComponent,
+    componentDirectory,
+    { staticApi: projectConfig.codegen.staticApi },
+  );
+  await writeFormattedFile(
+    ctx,
+    tmpDir,
+    apiContents,
+    "typescript",
+    apiDTSPath,
+    opts,
+  );
+
+  if (opts?.generateCommonJSApi || projectConfig.generateCommonJSApi) {
+    const apiCjsDTSPath = path.join(codegenDir, "api_cjs.d.ts");
+    await writeFormattedFile(
+      ctx,
+      tmpDir,
+      apiContents,
+      "typescript",
+      apiCjsDTSPath,
+      opts,
+    );
+  }
+}
+
+async function doReadmeCodegen(
+  ctx: Context,
+  tmpDir: TempDir,
+  functionsDir: string,
+  skipIfExists: boolean,
+  opts?: { dryRun?: boolean; debug?: boolean },
+) {
+  const readmePath = path.join(functionsDir, "README.md");
+  if (skipIfExists && ctx.fs.exists(readmePath)) {
+    logVerbose(ctx, `Not overwriting README.md.`);
+    return;
+  }
+  await writeFormattedFile(
+    ctx,
+    tmpDir,
+    readmeCodegen(),
+    "markdown",
+    readmePath,
+    opts,
+  );
+}
+
+async function doTsconfigCodegen(
+  ctx: Context,
+  tmpDir: TempDir,
+  functionsDir: string,
+  skipIfExists: boolean,
+  opts?: { dryRun?: boolean; debug?: boolean },
+) {
+  const tsconfigPath = path.join(functionsDir, "tsconfig.json");
+  if (skipIfExists && ctx.fs.exists(tsconfigPath)) {
+    logVerbose(ctx, `Not overwriting tsconfig.json.`);
+    return;
+  }
+  await writeFormattedFile(
+    ctx,
+    tmpDir,
+    tsconfigCodegen(),
+    "json",
+    tsconfigPath,
+    opts,
+  );
+}
+
+function schemaFileExists(ctx: Context, functionsDir: string) {
+  let schemaPath = path.join(functionsDir, "schema.ts");
+  let hasSchemaFile = ctx.fs.exists(schemaPath);
+  if (!hasSchemaFile) {
+    schemaPath = path.join(functionsDir, "schema.js");
+    hasSchemaFile = ctx.fs.exists(schemaPath);
+  }
+  return hasSchemaFile;
+}
+
+async function doDataModelCodegen(
+  ctx: Context,
+  tmpDir: TempDir,
+  functionsDir: string,
+  codegenDir: string,
+  opts?: { dryRun?: boolean; debug?: boolean },
+) {
+  const hasSchemaFile = schemaFileExists(ctx, functionsDir);
+  const schemaContent = hasSchemaFile
+    ? dynamicDataModelDTS()
+    : noSchemaDataModelDTS();
+
+  await writeFormattedFile(
+    ctx,
+    tmpDir,
+    schemaContent,
+    "typescript",
+    path.join(codegenDir, "dataModel.d.ts"),
+    opts,
+  );
+  return ["dataModel.d.ts"];
+}
+
+async function doServerCodegen(
+  ctx: Context,
+  tmpDir: TempDir,
+  codegenDir: string,
+  opts?: { dryRun?: boolean; debug?: boolean },
+) {
+  const serverContent = serverCodegen();
+  await writeFormattedFile(
+    ctx,
+    tmpDir,
+    serverContent.JS,
+    "typescript",
+    path.join(codegenDir, "server.js"),
+    opts,
+  );
+
+  await writeFormattedFile(
+    ctx,
+    tmpDir,
+    serverContent.DTS,
+    "typescript",
+    path.join(codegenDir, "server.d.ts"),
+    opts,
+  );
+
+  return ["server.js", "server.d.ts"];
+}
+
+async function doInitialComponentServerCodegen(
+  ctx: Context,
+  isRoot: boolean,
+  tmpDir: TempDir,
+  codegenDir: string,
+  opts?: { dryRun?: boolean; debug?: boolean },
+) {
+  await writeFormattedFile(
+    ctx,
+    tmpDir,
+    componentServerJS(),
+    "typescript",
+    path.join(codegenDir, "server.js"),
+    opts,
+  );
+
+  // Don't write our stub if the file already exists: It probably
+  // has better type information than this stub.
+  const serverDTSPath = path.join(codegenDir, "server.d.ts");
+  if (!ctx.fs.exists(serverDTSPath)) {
+    await writeFormattedFile(
+      ctx,
+      tmpDir,
+      componentServerStubDTS(isRoot),
+      "typescript",
+      path.join(codegenDir, "server.d.ts"),
+      opts,
+    );
+  }
+
+  return ["server.js", "server.d.ts"];
+}
+
+async function doInitialComponentDataModelCodegen(
+  ctx: Context,
+  tmpDir: TempDir,
+  componentDirectory: ComponentDirectory,
+  codegenDir: string,
+  opts?: { dryRun?: boolean; debug?: boolean },
+) {
+  const hasSchemaFile = schemaFileExists(ctx, componentDirectory.path);
+  const dataModelContext = hasSchemaFile
+    ? dynamicDataModelDTS()
+    : noSchemaDataModelDTS();
+  const dataModelPath = path.join(codegenDir, "dataModel.d.ts");
+
+  // Don't write our stub if the file already exists, since it may have
+  // better type information from `doFinalComponentDataModelCodegen`.
+  if (!ctx.fs.exists(dataModelPath)) {
+    await writeFormattedFile(
+      ctx,
+      tmpDir,
+      dataModelContext,
+      "typescript",
+      dataModelPath,
+      opts,
+    );
+  }
+  return ["dataModel.d.ts"];
+}
+
+async function doInitialComponentApiCodegen(
+  ctx: Context,
+  isRoot: boolean,
+  tmpDir: TempDir,
+  codegenDir: string,
+  generateCommonJSApi: boolean,
+  opts?: { dryRun?: boolean; debug?: boolean },
+) {
+  const apiJS = componentApiJs();
+  await writeFormattedFile(
+    ctx,
+    tmpDir,
+    apiJS,
+    "typescript",
+    path.join(codegenDir, "api.js"),
+    opts,
+  );
+
+  // Don't write the `.d.ts` stub if it already exists.
+  const apiDTSPath = path.join(codegenDir, "api.d.ts");
+  const apiStubDTS = componentApiStubDTS();
+  if (!ctx.fs.exists(apiDTSPath)) {
+    await writeFormattedFile(
+      ctx,
+      tmpDir,
+      apiStubDTS,
+      "typescript",
+      apiDTSPath,
+      opts,
+    );
+  }
+
+  const writtenFiles = ["api.js", "api.d.ts"];
+
+  if (generateCommonJSApi && isRoot) {
+    const apiCjsJS = rootComponentApiCJS();
+    await writeFormattedFile(
+      ctx,
+      tmpDir,
+      apiCjsJS,
+      "typescript",
+      path.join(codegenDir, "api_cjs.cjs"),
+      opts,
+    );
+
+    const cjsStubPath = path.join(codegenDir, "api_cjs.d.cts");
+    if (!ctx.fs.exists(cjsStubPath)) {
+      await writeFormattedFile(
+        ctx,
+        tmpDir,
+        apiStubDTS,
+        "typescript",
+        cjsStubPath,
+        opts,
+      );
+    }
+    writtenFiles.push("api_cjs.cjs", "api_cjs.d.cts");
+  }
+
+  return writtenFiles;
+}
+
+async function doApiCodegen(
+  ctx: Context,
+  tmpDir: TempDir,
+  functionsDir: string,
+  codegenDir: string,
+  generateCommonJSApi: boolean,
+  opts?: { dryRun?: boolean; debug?: boolean },
+) {
+  const absModulePaths = await entryPoints(ctx, functionsDir);
+  const modulePaths = absModulePaths.map((p) => path.relative(functionsDir, p));
+
+  const apiContent = apiCodegen(modulePaths);
+  await writeFormattedFile(
+    ctx,
+    tmpDir,
+    apiContent.JS,
+    "typescript",
+    path.join(codegenDir, "api.js"),
+    opts,
+  );
+  await writeFormattedFile(
+    ctx,
+    tmpDir,
+    apiContent.DTS,
+    "typescript",
+    path.join(codegenDir, "api.d.ts"),
+    opts,
+  );
+  const writtenFiles = ["api.js", "api.d.ts"];
+
+  if (generateCommonJSApi) {
+    const apiCjsContent = apiCjsCodegen(modulePaths);
+    await writeFormattedFile(
+      ctx,
+      tmpDir,
+      apiCjsContent.JS,
+      "typescript",
+      path.join(codegenDir, "api_cjs.cjs"),
+      opts,
+    );
+    await writeFormattedFile(
+      ctx,
+      tmpDir,
+      apiCjsContent.DTS,
+      "typescript",
+      path.join(codegenDir, "api_cjs.d.cts"),
+      opts,
+    );
+    writtenFiles.push("api_cjs.cjs", "api_cjs.d.cts");
+  }
+
+  return writtenFiles;
+}
+
+async function writeFormattedFile(
+  ctx: Context,
+  tmpDir: TempDir,
+  contents: string,
+  filetype: string,
+  destination: string,
+  options?: {
+    dryRun?: boolean;
+    debug?: boolean;
+  },
+) {
+  // Run prettier so we don't have to think about formatting!
+  //
+  // This is a little sketchy because we are using the default prettier config
+  // (not our user's one) but it's better than nothing.
+  const formattedContents = await prettier.format(contents, {
+    parser: filetype,
+    pluginSearchDirs: false,
+  });
+  if (options?.debug) {
+    // NB: The `test_codegen_projects_are_up_to_date` smoke test depends
+    // on this output format.
+    logOutput(ctx, `# ${path.resolve(destination)}`);
+    logOutput(ctx, formattedContents);
+    return;
+  }
+  try {
+    const existing = ctx.fs.readUtf8File(destination);
+    if (existing === formattedContents) {
+      return;
+    }
+  } catch (err: any) {
+    if (err.code !== "ENOENT") {
+      // eslint-disable-next-line no-restricted-syntax
+      throw err;
+    }
+  }
+  if (options?.dryRun) {
+    logOutput(ctx, `Command would write file: ${destination}`);
+    return;
+  }
+  const tmpPath = tmpDir.writeUtf8File(formattedContents);
+  ctx.fs.swapTmpFile(tmpPath, destination);
+}
diff --git a/synced/convex/libs/cli/lib/command.ts b/synced/convex/libs/cli/lib/command.ts
new file mode 100644
index 0000000..ef46589
--- /dev/null
+++ b/synced/convex/libs/cli/lib/command.ts
@@ -0,0 +1,517 @@
+import { Command, Option } from "@commander-js/extra-typings";
+import { OneoffCtx } from "../../bundler/context.js";
+import { LogMode } from "./logs.js";
+import {
+  CONVEX_DEPLOYMENT_ENV_VAR_NAME,
+  CONVEX_SELF_HOSTED_ADMIN_KEY_VAR_NAME,
+  CONVEX_SELF_HOSTED_URL_VAR_NAME,
+  parseInteger,
+  parsePositiveInteger,
+} from "./utils/utils.js";
+
+declare module "@commander-js/extra-typings" {
+  interface Command<Args extends any[] = [], Opts extends OptionValues = {}> {
+    /**
+     * For a command that talks to the configured dev deployment by default,
+     * add flags for talking to prod, preview, or other deployment in the same
+     * project.
+     *
+     * These flags are added to the end of `command` (ordering matters for `--help`
+     * output). `action` should look like "Import data into" because it is prefixed
+     * onto help strings.
+     *
+     * The options can be passed to `deploymentSelectionFromOptions`.
+     *
+     * NOTE: This method only exists at runtime if this file is imported.
+     * To help avoid this bug, this method takes in an `ActionDescription` which
+     * can only be constructed via `actionDescription` from this file.
+     */
+    addDeploymentSelectionOptions(action: ActionDescription): Command<
+      Args,
+      Opts & {
+        envFile?: string;
+        url?: string;
+        adminKey?: string;
+        prod?: boolean;
+        previewName?: string;
+        deploymentName?: string;
+      }
+    >;
+
+    /**
+     * Adds options for the `deploy` command.
+     */
+    addDeployOptions(): Command<
+      Args,
+      Opts & {
+        verbose?: boolean;
+        dryRun?: boolean;
+        yes?: boolean;
+        typecheck: "enable" | "try" | "disable";
+        typecheckComponents: boolean;
+        codegen: "enable" | "disable";
+        cmd?: string;
+        cmdUrlEnvVarName?: string;
+        debugBundlePath?: string;
+        debug?: boolean;
+        writePushRequest?: string;
+        liveComponentSources?: boolean;
+      }
+    >;
+
+    /**
+     * Adds options for `self-host` subcommands.
+     */
+    addSelfHostOptions(): Command<
+      Args,
+      Opts & {
+        url?: string;
+        adminKey?: string;
+        env?: string;
+      }
+    >;
+
+    /**
+     * Adds options and arguments for the `run` command.
+     */
+    addRunOptions(): Command<
+      [...Args, string, string | undefined],
+      Opts & {
+        watch?: boolean;
+        push?: boolean;
+        identity?: string;
+        typecheck: "enable" | "try" | "disable";
+        typecheckComponents: boolean;
+        codegen: "enable" | "disable";
+        component?: string;
+        liveComponentSources?: boolean;
+      }
+    >;
+
+    /**
+     * Adds options for the `import` command.
+     */
+    addImportOptions(): Command<
+      [...Args, string],
+      Opts & {
+        table?: string;
+        format?: "csv" | "jsonLines" | "jsonArray" | "zip";
+        replace?: boolean;
+        append?: boolean;
+        replaceAll?: boolean;
+        yes?: boolean;
+        component?: string;
+      }
+    >;
+
+    /**
+     * Adds options for the `export` command.
+     */
+    addExportOptions(): Command<
+      Args,
+      Opts & {
+        path: string;
+        includeFileStorage?: boolean;
+      }
+    >;
+
+    /**
+     * Adds options for the `data` command.
+     */
+    addDataOptions(): Command<
+      [...Args, string | undefined],
+      Opts & {
+        limit: number;
+        order: "asc" | "desc";
+        component?: string;
+      }
+    >;
+
+    /**
+     * Adds options for the `logs` command.
+     */
+    addLogsOptions(): Command<
+      Args,
+      Opts & {
+        history: number;
+        success: boolean;
+      }
+    >;
+
+    /**
+     * Adds options for the `network-test` command.
+     */
+    addNetworkTestOptions(): Command<
+      Args,
+      Opts & {
+        timeout?: string;
+        ipFamily?: string;
+        speedTest?: boolean;
+      }
+    >;
+  }
+}
+
+Command.prototype.addDeploymentSelectionOptions = function (
+  action: ActionDescription,
+) {
+  return this.addOption(
+    new Option("--url <url>")
+      .conflicts(["--prod", "--preview-name", "--deployment-name"])
+      .hideHelp(),
+  )
+    .addOption(new Option("--admin-key <adminKey>").hideHelp())
+    .addOption(
+      new Option(
+        "--env-file <envFile>",
+        `Path to a custom file of environment variables, for choosing the \
+deployment, e.g. ${CONVEX_DEPLOYMENT_ENV_VAR_NAME} or ${CONVEX_SELF_HOSTED_URL_VAR_NAME}. \
+Same format as .env.local or .env files, and overrides them.`,
+      ),
+    )
+    .addOption(
+      new Option(
+        "--prod",
+        action + " this project's production deployment.",
+      ).conflicts(["--preview-name", "--deployment-name", "--url"]),
+    )
+    .addOption(
+      new Option(
+        "--preview-name <previewName>",
+        action + " the preview deployment with the given name.",
+      ).conflicts(["--prod", "--deployment-name", "--url"]),
+    )
+    .addOption(
+      new Option(
+        "--deployment-name <deploymentName>",
+        action + " the specified deployment.",
+      ).conflicts(["--prod", "--preview-name", "--url"]),
+    ) as any;
+};
+
+declare const tag: unique symbol;
+type ActionDescription = string & { readonly [tag]: "noop" };
+export function actionDescription(action: string): ActionDescription {
+  return action as any;
+}
+
+export async function normalizeDevOptions(
+  ctx: OneoffCtx,
+  cmdOptions: {
+    verbose?: boolean;
+    typecheck: "enable" | "try" | "disable";
+    typecheckComponents?: boolean;
+    codegen: "enable" | "disable";
+    once?: boolean;
+    untilSuccess: boolean;
+    run?: string;
+    runSh?: string;
+    runComponent?: string;
+    tailLogs?: string | true;
+    traceEvents: boolean;
+    debugBundlePath?: string;
+    liveComponentSources?: boolean;
+    while?: string;
+  },
+): Promise<{
+  verbose: boolean;
+  typecheck: "enable" | "try" | "disable";
+  typecheckComponents: boolean;
+  codegen: boolean;
+  once: boolean;
+  untilSuccess: boolean;
+  run?:
+    | { kind: "function"; name: string; component?: string }
+    | { kind: "shell"; command: string };
+  tailLogs: LogMode;
+  traceEvents: boolean;
+  debugBundlePath?: string;
+  liveComponentSources: boolean;
+}> {
+  if (cmdOptions.runComponent && !cmdOptions.run) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: "Can't specify `--run-component` option without `--run`",
+    });
+  }
+
+  if (cmdOptions.debugBundlePath !== undefined && !cmdOptions.once) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: "`--debug-bundle-path` can only be used with `--once`.",
+    });
+  }
+
+  return {
+    verbose: !!cmdOptions.verbose,
+    typecheck: cmdOptions.typecheck,
+    typecheckComponents: !!cmdOptions.typecheckComponents,
+    codegen: cmdOptions.codegen === "enable",
+    once: !!cmdOptions.once,
+    untilSuccess: cmdOptions.untilSuccess,
+    run:
+      cmdOptions.run !== undefined
+        ? {
+            kind: "function",
+            name: cmdOptions.run,
+            component: cmdOptions.runComponent,
+          }
+        : cmdOptions.runSh !== undefined
+          ? {
+              kind: "shell",
+              command: cmdOptions.runSh,
+            }
+          : undefined,
+    tailLogs:
+      typeof cmdOptions.tailLogs === "string"
+        ? (cmdOptions.tailLogs as LogMode)
+        : "pause-on-deploy",
+    traceEvents: cmdOptions.traceEvents,
+    debugBundlePath: cmdOptions.debugBundlePath,
+    liveComponentSources: !!cmdOptions.liveComponentSources,
+  };
+}
+
+Command.prototype.addDeployOptions = function () {
+  return this.option("-v, --verbose", "Show full listing of changes")
+    .option(
+      "--dry-run",
+      "Print out the generated configuration without deploying to your Convex deployment",
+    )
+    .option("-y, --yes", "Skip confirmation prompt when running locally")
+    .addOption(
+      new Option(
+        "--typecheck <mode>",
+        `Whether to check TypeScript files with \`tsc --noEmit\` before deploying.`,
+      )
+        .choices(["enable", "try", "disable"] as const)
+        .default("try" as const),
+    )
+    .option(
+      "--typecheck-components",
+      "Check TypeScript files within component implementations with `tsc --noEmit`.",
+      false,
+    )
+    .addOption(
+      new Option(
+        "--codegen <mode>",
+        "Whether to regenerate code in `convex/_generated/` before pushing.",
+      )
+        .choices(["enable", "disable"] as const)
+        .default("enable" as const),
+    )
+    .addOption(
+      new Option(
+        "--cmd <command>",
+        "Command to run as part of deploying your app (e.g. `vite build`). This command can depend on the environment variables specified in `--cmd-url-env-var-name` being set.",
+      ),
+    )
+    .addOption(
+      new Option(
+        "--cmd-url-env-var-name <name>",
+        "Environment variable name to set Convex deployment URL (e.g. `VITE_CONVEX_URL`) when using `--cmd`",
+      ),
+    )
+    .addOption(new Option("--debug-bundle-path <path>").hideHelp())
+    .addOption(new Option("--debug").hideHelp())
+    .addOption(new Option("--write-push-request <writePushRequest>").hideHelp())
+    .addOption(new Option("--live-component-sources").hideHelp());
+};
+
+Command.prototype.addSelfHostOptions = function () {
+  return this.option(
+    "--admin-key <adminKey>",
+    `An admin key for the deployment. Can alternatively be set as \`${CONVEX_SELF_HOSTED_ADMIN_KEY_VAR_NAME}\` environment variable.`,
+  )
+    .option(
+      "--url <url>",
+      `The url of the deployment. Can alternatively be set as \`${CONVEX_SELF_HOSTED_URL_VAR_NAME}\` environment variable.`,
+    )
+    .option(
+      "--env <env>",
+      `Path to a custom file of environment variables, containing \`${CONVEX_SELF_HOSTED_URL_VAR_NAME}\` and \`${CONVEX_SELF_HOSTED_ADMIN_KEY_VAR_NAME}\`.`,
+    );
+};
+
+Command.prototype.addRunOptions = function () {
+  return (
+    this.argument(
+      "functionName",
+      "identifier of the function to run, like `listMessages` or `dir/file:myFunction`",
+    )
+      .argument(
+        "[args]",
+        "JSON-formatted arguments object to pass to the function.",
+      )
+      .option(
+        "-w, --watch",
+        "Watch a query, printing its result if the underlying data changes. Given function must be a query.",
+      )
+      .option("--push", "Push code to deployment before running the function.")
+      .addOption(
+        new Option(
+          "--identity <identity>",
+          'JSON-formatted UserIdentity object, e.g. \'{ name: "John", address: "0x123" }\'',
+        ),
+      )
+      // For backwards compatibility we still support --no-push which is a noop
+      .addOption(new Option("--no-push").hideHelp())
+      // Options for the deploy that --push does
+      .addOption(
+        new Option(
+          "--typecheck <mode>",
+          `Whether to check TypeScript files with \`tsc --noEmit\`.`,
+        )
+          .choices(["enable", "try", "disable"] as const)
+          .default("try" as const),
+      )
+      .option(
+        "--typecheck-components",
+        "Check TypeScript files within component implementations with `tsc --noEmit`.",
+        false,
+      )
+      .addOption(
+        new Option(
+          "--codegen <mode>",
+          "Regenerate code in `convex/_generated/`",
+        )
+          .choices(["enable", "disable"] as const)
+          .default("enable" as const),
+      )
+      .addOption(
+        new Option(
+          "--component <path>",
+          "Path to the component in the component tree defined in convex.config.ts. " +
+            "Components are a beta feature. This flag is unstable and may change in subsequent releases.",
+        ),
+      )
+      .addOption(new Option("--live-component-sources").hideHelp())
+  );
+};
+
+Command.prototype.addImportOptions = function () {
+  return this.argument("<path>", "Path to the input file")
+    .addOption(
+      new Option(
+        "--table <table>",
+        "Destination table name. Required if format is csv, jsonLines, or jsonArray. Not supported if format is zip.",
+      ),
+    )
+    .addOption(
+      new Option(
+        "--replace",
+        "Replace all existing data in any of the imported tables",
+      )
+        .conflicts("--append")
+        .conflicts("--replace-all"),
+    )
+    .addOption(
+      new Option("--append", "Append imported data to any existing tables")
+        .conflicts("--replace-all")
+        .conflicts("--replace"),
+    )
+    .addOption(
+      new Option(
+        "--replace-all",
+        "Replace all existing data in the deployment with the imported tables,\n" +
+          "  deleting tables that don't appear in the import file or the schema,\n" +
+          "  and clearing tables that appear in the schema but not in the import file",
+      )
+        .conflicts("--append")
+        .conflicts("--replace"),
+    )
+    .option(
+      "-y, --yes",
+      "Skip confirmation prompt when import leads to deleting existing documents",
+    )
+    .addOption(
+      new Option(
+        "--format <format>",
+        "Input file format. This flag is only required if the filename is missing an extension.\n" +
+          "- CSV files must have a header, and each row's entries are interpreted either as a (floating point) number or a string.\n" +
+          "- JSON files must be an array of JSON objects.\n" +
+          "- JSONLines files must have a JSON object per line.\n" +
+          "- ZIP files must have one directory per table, containing <table>/documents.jsonl. Snapshot exports from the Convex dashboard have this format.",
+      ).choices(["csv", "jsonLines", "jsonArray", "zip"]),
+    )
+    .addOption(
+      new Option(
+        "--component <path>",
+        "Path to the component in the component tree defined in convex.config.ts",
+      ),
+    );
+};
+
+Command.prototype.addExportOptions = function () {
+  return this.requiredOption(
+    "--path <zipFilePath>",
+    "Exports data into a ZIP file at this path, which may be a directory or unoccupied .zip path",
+  ).addOption(
+    new Option(
+      "--include-file-storage",
+      "Includes stored files (https://dashboard.convex.dev/deployment/files) in a _storage folder within the ZIP file",
+    ),
+  );
+};
+
+Command.prototype.addDataOptions = function () {
+  return this.addOption(
+    new Option(
+      "--limit <n>",
+      "List only the `n` the most recently created documents.",
+    )
+      .default(100)
+      .argParser(parsePositiveInteger),
+  )
+    .addOption(
+      new Option(
+        "--order <choice>",
+        "Order the documents by their `_creationTime`.",
+      )
+        .choices(["asc", "desc"])
+        .default("desc"),
+    )
+    .addOption(
+      new Option(
+        "--component <path>",
+        "Path to the component in the component tree defined in convex.config.ts.\n" +
+          "  By default, inspects data in the root component",
+      ).hideHelp(),
+    )
+    .argument("[table]", "If specified, list documents in this table.");
+};
+
+Command.prototype.addLogsOptions = function () {
+  return this.option(
+    "--history [n]",
+    "Show `n` most recent logs. Defaults to showing all available logs.",
+    parseInteger,
+  ).option(
+    "--success",
+    "Print a log line for every successful function execution",
+    false,
+  );
+};
+
+Command.prototype.addNetworkTestOptions = function () {
+  return this.addOption(
+    new Option(
+      "--timeout <timeout>",
+      "Timeout in seconds for the network test (default: 30).",
+    ),
+  )
+    .addOption(
+      new Option(
+        "--ip-family <ipFamily>",
+        "IP family to use (ipv4, ipv6, or auto)",
+      ),
+    )
+    .addOption(
+      new Option(
+        "--speed-test",
+        "Perform a large echo test to measure network speed.",
+      ),
+    );
+};
diff --git a/synced/convex/libs/cli/lib/components.ts b/synced/convex/libs/cli/lib/components.ts
new file mode 100644
index 0000000..aaefd37
--- /dev/null
+++ b/synced/convex/libs/cli/lib/components.ts
@@ -0,0 +1,479 @@
+import path from "path";
+import {
+  Context,
+  changeSpinner,
+  logFinishedStep,
+  logMessage,
+} from "../../bundler/context.js";
+import {
+  ProjectConfig,
+  configFromProjectConfig,
+  getFunctionsDirectoryPath,
+  readProjectConfig,
+} from "./config.js";
+import {
+  finishPush,
+  reportPushCompleted,
+  startPush,
+  waitForSchema,
+} from "./deploy2.js";
+import { version } from "../version.js";
+import { PushOptions, runNonComponentsPush } from "./push.js";
+import { ensureHasConvexDependency, functionsDir } from "./utils/utils.js";
+import {
+  bundleDefinitions,
+  bundleImplementations,
+  componentGraph,
+} from "./components/definition/bundle.js";
+import { isComponentDirectory } from "./components/definition/directoryStructure.js";
+import {
+  doFinalComponentCodegen,
+  doInitialComponentCodegen,
+  CodegenOptions,
+  doInitCodegen,
+  doCodegen,
+} from "./codegen.js";
+import {
+  AppDefinitionConfig,
+  ComponentDefinitionConfig,
+} from "./deployApi/definitionConfig.js";
+import { typeCheckFunctionsInMode, TypeCheckMode } from "./typecheck.js";
+import { withTmpDir } from "../../bundler/fs.js";
+import { handleDebugBundlePath } from "./debugBundlePath.js";
+import chalk from "chalk";
+import { StartPushRequest, StartPushResponse } from "./deployApi/startPush.js";
+import {
+  deploymentSelectionWithinProjectFromOptions,
+  loadSelectedDeploymentCredentials,
+} from "./api.js";
+import {
+  FinishPushDiff,
+  DeveloperIndexConfig,
+} from "./deployApi/finishPush.js";
+import { Reporter, Span } from "./tracing.js";
+import {
+  DEFINITION_FILENAME_JS,
+  DEFINITION_FILENAME_TS,
+} from "./components/constants.js";
+import { DeploymentSelection } from "./deploymentSelection.js";
+async function findComponentRootPath(ctx: Context, functionsDir: string) {
+  // Default to `.ts` but fallback to `.js` if not present.
+  let componentRootPath = path.resolve(
+    path.join(functionsDir, DEFINITION_FILENAME_TS),
+  );
+  if (!ctx.fs.exists(componentRootPath)) {
+    componentRootPath = path.resolve(
+      path.join(functionsDir, DEFINITION_FILENAME_JS),
+    );
+  }
+  return componentRootPath;
+}
+
+export async function runCodegen(
+  ctx: Context,
+  deploymentSelection: DeploymentSelection,
+  options: CodegenOptions,
+) {
+  // This also ensures the current directory is the project root.
+  await ensureHasConvexDependency(ctx, "codegen");
+
+  const { configPath, projectConfig } = await readProjectConfig(ctx);
+  const functionsDirectoryPath = functionsDir(configPath, projectConfig);
+
+  const componentRootPath = await findComponentRootPath(
+    ctx,
+    functionsDirectoryPath,
+  );
+
+  if (ctx.fs.exists(componentRootPath)) {
+    const selectionWithinProject =
+      await deploymentSelectionWithinProjectFromOptions(ctx, options);
+    const credentials = await loadSelectedDeploymentCredentials(
+      ctx,
+      deploymentSelection,
+      selectionWithinProject,
+    );
+
+    await startComponentsPushAndCodegen(
+      ctx,
+      Span.noop(),
+      projectConfig,
+      configPath,
+      {
+        ...options,
+        deploymentName: credentials.deploymentFields?.deploymentName ?? null,
+        url: credentials.url,
+        adminKey: credentials.adminKey,
+        generateCommonJSApi: options.commonjs,
+        verbose: options.dryRun,
+        codegen: true,
+        liveComponentSources: options.liveComponentSources,
+        typecheckComponents: false,
+      },
+    );
+  } else {
+    if (options.init) {
+      await doInitCodegen(ctx, functionsDirectoryPath, false, {
+        dryRun: options.dryRun,
+        debug: options.debug,
+      });
+    }
+
+    if (options.typecheck !== "disable") {
+      logMessage(ctx, chalk.gray("Running TypeScript typecheck"));
+    }
+
+    await doCodegen(ctx, functionsDirectoryPath, options.typecheck, {
+      dryRun: options.dryRun,
+      debug: options.debug,
+      generateCommonJSApi: options.commonjs,
+    });
+  }
+}
+
+export async function runPush(ctx: Context, options: PushOptions) {
+  const { configPath, projectConfig } = await readProjectConfig(ctx);
+  const convexDir = functionsDir(configPath, projectConfig);
+  const componentRootPath = await findComponentRootPath(ctx, convexDir);
+  if (ctx.fs.exists(componentRootPath)) {
+    await runComponentsPush(ctx, options, configPath, projectConfig);
+  } else {
+    await runNonComponentsPush(ctx, options, configPath, projectConfig);
+  }
+}
+
+async function startComponentsPushAndCodegen(
+  ctx: Context,
+  parentSpan: Span,
+  projectConfig: ProjectConfig,
+  configPath: string,
+  options: {
+    typecheck: TypeCheckMode;
+    typecheckComponents: boolean;
+    adminKey: string;
+    url: string;
+    deploymentName: string | null;
+    verbose: boolean;
+    debugBundlePath?: string;
+    dryRun: boolean;
+    generateCommonJSApi?: boolean;
+    debug: boolean;
+    writePushRequest?: string;
+    codegen: boolean;
+    liveComponentSources?: boolean;
+  },
+): Promise<StartPushResponse | null> {
+  const convexDir = await getFunctionsDirectoryPath(ctx);
+
+  // '.' means use the process current working directory, it's the default behavior.
+  // Spelling it out here to be explicit for a future where this code can run
+  // from other directories.
+  // In esbuild the working directory is used to print error messages and resolving
+  // relatives paths passed to it. It generally doesn't matter for resolving imports,
+  // imports are resolved from the file where they are written.
+  const absWorkingDir = path.resolve(".");
+  const isComponent = isComponentDirectory(ctx, convexDir, true);
+  if (isComponent.kind === "err") {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "invalid filesystem data",
+      printedMessage: `Invalid component root directory (${isComponent.why}): ${convexDir}`,
+    });
+  }
+  const rootComponent = isComponent.component;
+
+  changeSpinner(ctx, "Finding component definitions...");
+  // Create a list of relevant component directories. These are just for knowing
+  // while directories to bundle in bundleDefinitions and bundleImplementations.
+  // This produces a bundle in memory as a side effect but it's thrown away.
+  const { components, dependencyGraph } = await parentSpan.enterAsync(
+    "componentGraph",
+    () =>
+      componentGraph(
+        ctx,
+        absWorkingDir,
+        rootComponent,
+        !!options.liveComponentSources,
+        options.verbose,
+      ),
+  );
+
+  if (options.codegen) {
+    changeSpinner(ctx, "Generating server code...");
+    await parentSpan.enterAsync("doInitialComponentCodegen", () =>
+      withTmpDir(async (tmpDir) => {
+        await doInitialComponentCodegen(ctx, tmpDir, rootComponent, options);
+        for (const directory of components.values()) {
+          await doInitialComponentCodegen(ctx, tmpDir, directory, options);
+        }
+      }),
+    );
+  }
+
+  changeSpinner(ctx, "Bundling component definitions...");
+  // This bundles everything but the actual function definitions
+  const {
+    appDefinitionSpecWithoutImpls,
+    componentDefinitionSpecsWithoutImpls,
+  } = await parentSpan.enterAsync("bundleDefinitions", () =>
+    bundleDefinitions(
+      ctx,
+      absWorkingDir,
+      dependencyGraph,
+      rootComponent,
+      // Note that this *includes* the root component.
+      [...components.values()],
+      !!options.liveComponentSources,
+    ),
+  );
+
+  changeSpinner(ctx, "Bundling component schemas and implementations...");
+  const { appImplementation, componentImplementations } =
+    await parentSpan.enterAsync("bundleImplementations", () =>
+      bundleImplementations(
+        ctx,
+        rootComponent,
+        [...components.values()],
+        projectConfig.node.externalPackages,
+        options.liveComponentSources ? ["@convex-dev/component-source"] : [],
+        options.verbose,
+      ),
+    );
+  if (options.debugBundlePath) {
+    const { config: localConfig } = await configFromProjectConfig(
+      ctx,
+      projectConfig,
+      configPath,
+      options.verbose,
+    );
+    // TODO(ENG-6972): Actually write the bundles for components.
+    await handleDebugBundlePath(ctx, options.debugBundlePath, localConfig);
+    logMessage(
+      ctx,
+      `Wrote bundle and metadata for modules in the root to ${options.debugBundlePath}. Skipping rest of push.`,
+    );
+    return null;
+  }
+
+  // We're just using the version this CLI is running with for now.
+  // This could be different than the version of `convex` the app runs with
+  // if the CLI is installed globally.
+  // TODO: This should be the version of the `convex` package used by each
+  // component, and may be different for each component.
+  const udfServerVersion = version;
+
+  const appDefinition: AppDefinitionConfig = {
+    ...appDefinitionSpecWithoutImpls,
+    ...appImplementation,
+    udfServerVersion,
+  };
+
+  const componentDefinitions: ComponentDefinitionConfig[] = [];
+  for (const componentDefinition of componentDefinitionSpecsWithoutImpls) {
+    const impl = componentImplementations.filter(
+      (impl) => impl.definitionPath === componentDefinition.definitionPath,
+    )[0];
+    if (!impl) {
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage: `missing! couldn't find ${componentDefinition.definitionPath} in ${componentImplementations.map((impl) => impl.definitionPath).toString()}`,
+      });
+    }
+    componentDefinitions.push({
+      ...componentDefinition,
+      ...impl,
+      udfServerVersion,
+    });
+  }
+  const startPushRequest = {
+    adminKey: options.adminKey,
+    dryRun: options.dryRun,
+    functions: projectConfig.functions,
+    appDefinition,
+    componentDefinitions,
+    nodeDependencies: appImplementation.externalNodeDependencies,
+  };
+  if (options.writePushRequest) {
+    const pushRequestPath = path.resolve(options.writePushRequest);
+    ctx.fs.writeUtf8File(
+      `${pushRequestPath}.json`,
+      JSON.stringify(startPushRequest),
+    );
+    return null;
+  }
+  logStartPushSizes(parentSpan, startPushRequest);
+
+  changeSpinner(ctx, "Uploading functions to Convex...");
+  const startPushResponse = await parentSpan.enterAsync("startPush", (span) =>
+    startPush(ctx, span, startPushRequest, options),
+  );
+
+  if (options.verbose) {
+    logMessage(ctx, "startPush: " + JSON.stringify(startPushResponse, null, 2));
+  }
+
+  if (options.codegen) {
+    changeSpinner(ctx, "Generating TypeScript bindings...");
+    await parentSpan.enterAsync("doFinalComponentCodegen", () =>
+      withTmpDir(async (tmpDir) => {
+        await doFinalComponentCodegen(
+          ctx,
+          tmpDir,
+          rootComponent,
+          rootComponent,
+          startPushResponse,
+          options,
+        );
+        for (const directory of components.values()) {
+          await doFinalComponentCodegen(
+            ctx,
+            tmpDir,
+            rootComponent,
+            directory,
+            startPushResponse,
+            options,
+          );
+        }
+      }),
+    );
+  }
+
+  changeSpinner(ctx, "Running TypeScript...");
+  await parentSpan.enterAsync("typeCheckFunctionsInMode", async () => {
+    await typeCheckFunctionsInMode(ctx, options.typecheck, rootComponent.path);
+    if (options.typecheckComponents) {
+      for (const directory of components.values()) {
+        await typeCheckFunctionsInMode(ctx, options.typecheck, directory.path);
+      }
+    }
+  });
+
+  return startPushResponse;
+}
+
+function logStartPushSizes(span: Span, startPushRequest: StartPushRequest) {
+  let v8Size = 0;
+  let v8Count = 0;
+  let nodeSize = 0;
+  let nodeCount = 0;
+
+  for (const componentDefinition of startPushRequest.componentDefinitions) {
+    for (const module of componentDefinition.functions) {
+      if (module.environment === "isolate") {
+        v8Size += module.source.length + (module.sourceMap ?? "").length;
+        v8Count += 1;
+      } else if (module.environment === "node") {
+        nodeSize += module.source.length + (module.sourceMap ?? "").length;
+        nodeCount += 1;
+      }
+    }
+  }
+  span.setProperty("v8_size", v8Size.toString());
+  span.setProperty("v8_count", v8Count.toString());
+  span.setProperty("node_size", nodeSize.toString());
+  span.setProperty("node_count", nodeCount.toString());
+}
+
+export async function runComponentsPush(
+  ctx: Context,
+  options: PushOptions,
+  configPath: string,
+  projectConfig: ProjectConfig,
+) {
+  const reporter = new Reporter();
+  const pushSpan = Span.root(reporter, "runComponentsPush");
+  pushSpan.setProperty("cli_version", version);
+
+  await ensureHasConvexDependency(ctx, "push");
+
+  const startPushResponse = await pushSpan.enterAsync(
+    "startComponentsPushAndCodegen",
+    (span) =>
+      startComponentsPushAndCodegen(
+        ctx,
+        span,
+        projectConfig,
+        configPath,
+        options,
+      ),
+  );
+  if (!startPushResponse) {
+    return;
+  }
+
+  await pushSpan.enterAsync("waitForSchema", (span) =>
+    waitForSchema(ctx, span, startPushResponse, options),
+  );
+
+  const finishPushResponse = await pushSpan.enterAsync("finishPush", (span) =>
+    finishPush(ctx, span, startPushResponse, options),
+  );
+  printDiff(ctx, finishPushResponse, options);
+  pushSpan.end();
+
+  // Asynchronously report that the push completed.
+  if (!options.dryRun) {
+    void reportPushCompleted(ctx, options.adminKey, options.url, reporter);
+  }
+}
+
+function printDiff(
+  ctx: Context,
+  finishPushResponse: FinishPushDiff,
+  opts: { verbose: boolean; dryRun: boolean },
+) {
+  if (opts.verbose) {
+    const diffString = JSON.stringify(finishPushResponse, null, 2);
+    logMessage(ctx, diffString);
+    return;
+  }
+  const { componentDiffs } = finishPushResponse;
+
+  // Print out index diffs for the root component.
+  let rootDiff = componentDiffs[""];
+  if (rootDiff && rootDiff.indexDiff) {
+    if (rootDiff.indexDiff.removed_indexes.length > 0) {
+      let msg = `${opts.dryRun ? "Would delete" : "Deleted"} table indexes:\n`;
+      for (let i = 0; i < rootDiff.indexDiff.removed_indexes.length; i++) {
+        const index = rootDiff.indexDiff.removed_indexes[i];
+        if (i > 0) {
+          msg += "\n";
+        }
+        msg += `  [-] ${formatIndex(index)}`;
+      }
+      logFinishedStep(ctx, msg);
+    }
+    if (rootDiff.indexDiff.added_indexes.length > 0) {
+      let msg = `${opts.dryRun ? "Would add" : "Added"} table indexes:\n`;
+      for (let i = 0; i < rootDiff.indexDiff.added_indexes.length; i++) {
+        const index = rootDiff.indexDiff.added_indexes[i];
+        if (i > 0) {
+          msg += "\n";
+        }
+        msg += `  [+] ${formatIndex(index)}`;
+      }
+      logFinishedStep(ctx, msg);
+    }
+  }
+
+  // Only show component level diffs for other components.
+  for (const [componentPath, componentDiff] of Object.entries(componentDiffs)) {
+    if (componentPath === "") {
+      continue;
+    }
+    if (componentDiff.diffType.type === "create") {
+      logFinishedStep(ctx, `Installed component ${componentPath}.`);
+    }
+    if (componentDiff.diffType.type === "unmount") {
+      logFinishedStep(ctx, `Unmounted component ${componentPath}.`);
+    }
+    if (componentDiff.diffType.type === "remount") {
+      logFinishedStep(ctx, `Remounted component ${componentPath}.`);
+    }
+  }
+}
+
+function formatIndex(index: DeveloperIndexConfig) {
+  return `${index.name}`;
+}
diff --git a/synced/convex/libs/cli/lib/components/constants.ts b/synced/convex/libs/cli/lib/components/constants.ts
new file mode 100644
index 0000000..48e0d0d
--- /dev/null
+++ b/synced/convex/libs/cli/lib/components/constants.ts
@@ -0,0 +1,2 @@
+export const DEFINITION_FILENAME_TS = "convex.config.ts";
+export const DEFINITION_FILENAME_JS = "convex.config.js";
diff --git a/synced/convex/libs/cli/lib/components/definition/bundle.ts b/synced/convex/libs/cli/lib/components/definition/bundle.ts
new file mode 100644
index 0000000..96f5dfa
--- /dev/null
+++ b/synced/convex/libs/cli/lib/components/definition/bundle.ts
@@ -0,0 +1,651 @@
+import path from "path";
+import {
+  ComponentDirectory,
+  ComponentDefinitionPath,
+  buildComponentDirectory,
+  isComponentDirectory,
+  qualifiedDefinitionPath,
+  toComponentDefinitionPath,
+} from "./directoryStructure.js";
+import {
+  Context,
+  logMessage,
+  logWarning,
+  showSpinner,
+} from "../../../../bundler/context.js";
+import esbuild, { BuildOptions, Metafile, OutputFile, Plugin } from "esbuild";
+import chalk from "chalk";
+import {
+  AppDefinitionSpecWithoutImpls,
+  ComponentDefinitionSpecWithoutImpls,
+} from "../../config.js";
+import {
+  Bundle,
+  bundle,
+  bundleAuthConfig,
+  bundleSchema,
+  entryPointsByEnvironment,
+} from "../../../../bundler/index.js";
+import { NodeDependency } from "../../deployApi/modules.js";
+
+/**
+ * An esbuild plugin to mark component definitions external or return a list of
+ * all component definitions.
+ *
+ * By default this plugin runs in "bundle" mode and marks all imported component
+ * definition files as external, not traversing further.
+ *
+ * If "discover" mode is specified it traverses the entire tree.
+ */
+function componentPlugin({
+  mode = "bundle",
+  rootComponentDirectory,
+  verbose,
+  ctx,
+}: {
+  mode: "discover" | "bundle";
+  rootComponentDirectory: ComponentDirectory;
+  verbose?: boolean;
+  ctx: Context;
+}): Plugin {
+  const components = new Map<string, ComponentDirectory>();
+  return {
+    name: `convex-${mode === "discover" ? "discover-components" : "bundle-components"}`,
+    async setup(build) {
+      // This regex can't be really precise since developers could import
+      // "convex.config", "convex.config.js", "convex.config.ts", etc.
+      build.onResolve({ filter: /.*convex.config.*/ }, async (args) => {
+        verbose && logMessage(ctx, "esbuild resolving import:", args);
+        if (args.namespace !== "file") {
+          verbose && logMessage(ctx, "  Not a file.");
+          return;
+        }
+        if (args.kind === "entry-point") {
+          verbose && logMessage(ctx, "  -> Top-level entry-point.");
+          const componentDirectory = await buildComponentDirectory(
+            ctx,
+            path.resolve(args.path),
+          );
+
+          // No attempt to resolve args.path is made for entry points so they
+          // must be relative or absolute file paths, not npm packages.
+          // Whether we're bundling or discovering, we're done.
+          if (components.get(args.path)) {
+            // We always invoke esbuild in a try/catch.
+            // eslint-disable-next-line no-restricted-syntax
+            throw new Error(
+              `Entry point component "${args.path}" already registered.`,
+            );
+          }
+          components.set(args.path, componentDirectory);
+          return;
+        }
+
+        const candidates = [args.path];
+        const ext = path.extname(args.path);
+        if (ext === ".js") {
+          candidates.push(args.path.slice(0, -".js".length) + ".ts");
+        }
+        if (ext !== ".js" && ext !== ".ts") {
+          candidates.push(args.path + ".js");
+          candidates.push(args.path + ".ts");
+        }
+        let resolvedPath = undefined;
+        for (const candidate of candidates) {
+          const result = await build.resolve(candidate, {
+            // We expect this to be "import-statement" but pass 'kind' through
+            // to say honest to normal esbuild behavior.
+            kind: args.kind,
+            resolveDir: args.resolveDir,
+          });
+          if (result.path) {
+            resolvedPath = result.path;
+            break;
+          }
+        }
+        if (resolvedPath === undefined) {
+          verbose && logMessage(ctx, `  -> ${args.path} not found.`);
+          return;
+        }
+
+        const parentDir = path.dirname(resolvedPath);
+        let imported = components.get(resolvedPath);
+        if (!imported) {
+          const isComponent = isComponentDirectory(ctx, parentDir, false);
+          if (isComponent.kind !== "ok") {
+            verbose && logMessage(ctx, "  -> Not a component:", isComponent);
+            return;
+          }
+          imported = isComponent.component;
+          components.set(resolvedPath, imported);
+        }
+
+        verbose &&
+          logMessage(
+            ctx,
+            "  -> Component import! Recording it.",
+            args.path,
+            resolvedPath,
+          );
+
+        if (mode === "discover") {
+          return {
+            path: resolvedPath,
+          };
+        } else {
+          // In bundle mode, transform external imports to use componentPaths:
+          // import rateLimiter from "convex_ratelimiter";
+          // => import rateLimiter from `_componentDeps/${base64('../node_modules/convex_ratelimiter')}`;
+
+          // A componentPath is path from the root component to the directory
+          // of the this component's definition file.
+          const componentPath = toComponentDefinitionPath(
+            rootComponentDirectory,
+            imported,
+          );
+          const importPath = definitionImportPath(componentPath);
+          return {
+            path: importPath,
+            external: true,
+          };
+        }
+      });
+    },
+  };
+}
+
+/** The path on the deployment that identifier a component definition. */
+function definitionImportPath(componentPath: ComponentDefinitionPath): string {
+  return `./_componentDeps/${Buffer.from(componentPath).toString("base64url")}`;
+}
+
+// Share configuration between the component definition discovery and bundling passes.
+function sharedEsbuildOptions({
+  liveComponentSources = false,
+}: {
+  liveComponentSources?: boolean;
+}) {
+  const options = {
+    bundle: true,
+    platform: "browser",
+    format: "esm",
+    target: "esnext",
+
+    conditions: ["convex", "module"] as string[],
+
+    // `false` is the default for splitting. It's simpler to evaluate these on
+    // the server as a single file.
+    // Splitting could be enabled for speed once the server supports it.
+    splitting: false,
+
+    // place output files in memory at their source locations
+    write: false,
+    outdir: path.parse(process.cwd()).root,
+    outbase: path.parse(process.cwd()).root,
+
+    minify: true, // Note that this implies NODE_ENV="production".
+    keepNames: true,
+
+    metafile: true,
+  } as const satisfies BuildOptions;
+
+  // Link directly to component sources (usually .ts) in order to
+  // skip the build step. This also causes codegen to run for components
+  // loaded from npm packages.
+  if (liveComponentSources) {
+    options.conditions.push("@convex-dev/component-source");
+  }
+  return options;
+}
+
+// Use the esbuild metafile to discover the dependency graph in which component
+// definitions are nodes.
+export async function componentGraph(
+  ctx: Context,
+  absWorkingDir: string,
+  rootComponentDirectory: ComponentDirectory,
+  liveComponentSources: boolean,
+  verbose: boolean = true,
+): Promise<{
+  components: Map<string, ComponentDirectory>;
+  dependencyGraph: [ComponentDirectory, ComponentDirectory][];
+}> {
+  let result;
+  try {
+    result = await esbuild.build({
+      absWorkingDir, // This is mostly useful for formatting error messages.
+      entryPoints: [qualifiedDefinitionPath(rootComponentDirectory)],
+      plugins: [
+        componentPlugin({
+          ctx,
+          mode: "discover",
+          verbose,
+          rootComponentDirectory,
+        }),
+      ],
+      sourcemap: "external",
+      sourcesContent: false,
+
+      ...sharedEsbuildOptions({ liveComponentSources }),
+    });
+    await registerEsbuildReads(ctx, absWorkingDir, result.metafile);
+  } catch (err: any) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "invalid filesystem data",
+      printedMessage: `esbuild failed: ${err}`,
+    });
+  }
+
+  if (result.errors.length) {
+    const message = result.errors.map((error) => error.text).join("\n");
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "invalid filesystem data",
+      printedMessage: message,
+    });
+  }
+  for (const warning of result.warnings) {
+    // eslint-disable-next-line no-console
+    console.log(chalk.yellow(`esbuild warning: ${warning.text}`));
+  }
+  return await findComponentDependencies(ctx, result.metafile);
+}
+
+/**
+ * Get dependencies of a ComponenDirectory as ComponentPaths.
+ *
+ * Component paths are paths relative to the root component.
+ */
+export function getDeps(
+  rootComponent: ComponentDirectory,
+  dependencyGraph: [ComponentDirectory, ComponentDirectory][],
+  definitionPath: string,
+): ComponentDefinitionPath[] {
+  return dependencyGraph
+    .filter(
+      ([importer, _imported]) => importer.definitionPath === definitionPath,
+    )
+    .map(([_importer, imported]) =>
+      toComponentDefinitionPath(rootComponent, imported),
+    );
+}
+
+/**
+ * The returned dependency graph is an array of tuples of [importer, imported]
+ *
+ * This doesn't work on just any esbuild metafile because it assumes input
+ * imports have not been transformed. We run it on the metafile produced by
+ * the esbuild invocation that uses the component plugin in "discover" mode.
+ */
+async function findComponentDependencies(
+  ctx: Context,
+  metafile: Metafile,
+): Promise<{
+  components: Map<string, ComponentDirectory>;
+  dependencyGraph: [ComponentDirectory, ComponentDirectory][];
+}> {
+  const { inputs } = metafile;
+  // This filter means we only supports *direct imports* of component definitions
+  // from other component definitions.
+  const componentInputs = Object.keys(inputs).filter((path) =>
+    path.includes(".config."),
+  );
+
+  // Absolute path doesn't appear to be necessary here since only inputs marked
+  // external get transformed to an absolute path but it's not clear what's an
+  // esbuild implementation detail in the metafile or which settings change this.
+  const componentsByAbsPath = new Map<string, ComponentDirectory>();
+  for (const inputPath of componentInputs) {
+    const importer = await buildComponentDirectory(ctx, inputPath);
+    componentsByAbsPath.set(path.resolve(inputPath), importer);
+  }
+  const dependencyGraph: [ComponentDirectory, ComponentDirectory][] = [];
+  for (const inputPath of componentInputs) {
+    const importer = componentsByAbsPath.get(path.resolve(inputPath))!;
+    const { imports } = inputs[inputPath];
+    const componentImports = imports.filter((imp) =>
+      imp.path.includes(".config."),
+    );
+    for (const importPath of componentImports.map((dep) => dep.path)) {
+      const imported = componentsByAbsPath.get(path.resolve(importPath));
+      if (!imported) {
+        return await ctx.crash({
+          exitCode: 1,
+          errorType: "invalid filesystem data",
+          printedMessage: `Didn't find ${path.resolve(importPath)} in ${[...componentsByAbsPath.keys()].toString()}`,
+        });
+      }
+      dependencyGraph.push([importer, imported]);
+    }
+  }
+
+  const components = new Map<string, ComponentDirectory>();
+  for (const directory of componentsByAbsPath.values()) {
+    components.set(directory.path, directory);
+  }
+  return { components, dependencyGraph };
+}
+
+// NB: If a directory linked to is not a member of the passed
+// componentDirectories array then there will be external links
+// with no corresponding definition bundle.
+// That could be made to throw an error but maybe those are already available
+// on the Convex definition filesystem somehow, e.g. builtin components.
+/** Bundle the component definitions listed. */
+export async function bundleDefinitions(
+  ctx: Context,
+  absWorkingDir: string,
+  dependencyGraph: [ComponentDirectory, ComponentDirectory][],
+  rootComponentDirectory: ComponentDirectory,
+  componentDirectories: ComponentDirectory[],
+  liveComponentSources: boolean,
+  verbose: boolean = false,
+): Promise<{
+  appDefinitionSpecWithoutImpls: AppDefinitionSpecWithoutImpls;
+  componentDefinitionSpecsWithoutImpls: ComponentDefinitionSpecWithoutImpls[];
+}> {
+  let result;
+  try {
+    result = await esbuild.build({
+      absWorkingDir,
+      entryPoints: componentDirectories.map((dir) =>
+        qualifiedDefinitionPath(dir),
+      ),
+      plugins: [
+        componentPlugin({
+          ctx,
+          mode: "bundle",
+          verbose,
+          rootComponentDirectory,
+        }),
+      ],
+      sourcemap: true,
+      ...sharedEsbuildOptions({ liveComponentSources }),
+    });
+    await registerEsbuildReads(ctx, absWorkingDir, result.metafile);
+  } catch (err: any) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "invalid filesystem data",
+      printedMessage: `esbuild failed: ${err}`,
+    });
+  }
+
+  if (result.errors.length) {
+    const message = result.errors.map((error) => error.text).join("\n");
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "invalid filesystem data",
+      printedMessage: message,
+    });
+  }
+  for (const warning of result.warnings) {
+    // eslint-disable-next-line no-console
+    console.log(chalk.yellow(`esbuild warning: ${warning.text}`));
+  }
+
+  const outputs: {
+    outputJs: OutputFile;
+    outputJsMap?: OutputFile;
+    directory: ComponentDirectory;
+  }[] = [];
+  for (const directory of componentDirectories) {
+    const absInput = path.resolve(absWorkingDir, directory.definitionPath);
+    const expectedOutputJs =
+      absInput.slice(0, absInput.lastIndexOf(".")) + ".js";
+    const expectedOutputMap =
+      absInput.slice(0, absInput.lastIndexOf(".")) + ".js.map";
+    const outputJs = result.outputFiles.filter(
+      (outputFile) => outputFile.path === expectedOutputJs,
+    )[0];
+    if (!outputJs) {
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage: `no JS found matching ${expectedOutputJs} in ${result.outputFiles.map((x) => x.path).toString()}`,
+      });
+    }
+    const outputJsMap = result.outputFiles.filter(
+      (outputFile) => outputFile.path === expectedOutputMap,
+    )[0];
+    outputs.push({
+      outputJs,
+      outputJsMap,
+      directory,
+    });
+  }
+
+  const appBundles = outputs.filter(
+    (out) => out.directory.path === rootComponentDirectory.path,
+  );
+  if (appBundles.length !== 1) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: "found wrong number of app bundles",
+    });
+  }
+  const appBundle = appBundles[0];
+  const componentBundles = outputs.filter(
+    (out) => out.directory.path !== rootComponentDirectory.path,
+  );
+
+  const componentDefinitionSpecsWithoutImpls: ComponentDefinitionSpecWithoutImpls[] =
+    componentBundles.map(({ directory, outputJs, outputJsMap }) => ({
+      definitionPath: toComponentDefinitionPath(
+        rootComponentDirectory,
+        directory,
+      ),
+      definition: {
+        path: path.relative(directory.path, outputJs.path),
+        source: outputJs.text,
+        sourceMap: outputJsMap?.text,
+        environment: "isolate" as const,
+      },
+      dependencies: getDeps(
+        rootComponentDirectory,
+        dependencyGraph,
+        directory.definitionPath,
+      ),
+    }));
+  const appDeps = getDeps(
+    rootComponentDirectory,
+    dependencyGraph,
+    appBundle.directory.definitionPath,
+  );
+  const appDefinitionSpecWithoutImpls: AppDefinitionSpecWithoutImpls = {
+    definition: {
+      path: path.relative(rootComponentDirectory.path, appBundle.outputJs.path),
+      source: appBundle.outputJs.text,
+      sourceMap: appBundle.outputJsMap?.text,
+      environment: "isolate" as const,
+    },
+    dependencies: appDeps,
+  };
+  return {
+    appDefinitionSpecWithoutImpls,
+    componentDefinitionSpecsWithoutImpls,
+  };
+}
+
+export async function bundleImplementations(
+  ctx: Context,
+  rootComponentDirectory: ComponentDirectory,
+  componentDirectories: ComponentDirectory[],
+  nodeExternalPackages: string[],
+  extraConditions: string[],
+  verbose: boolean = false,
+): Promise<{
+  appImplementation: {
+    schema: Bundle | null;
+    functions: Bundle[];
+    externalNodeDependencies: NodeDependency[];
+  };
+  componentImplementations: {
+    schema: Bundle | null;
+    functions: Bundle[];
+    definitionPath: ComponentDefinitionPath;
+  }[];
+}> {
+  let appImplementation;
+  const componentImplementations = [];
+
+  let isRoot = true;
+  for (const directory of [rootComponentDirectory, ...componentDirectories]) {
+    const resolvedPath = path.resolve(
+      rootComponentDirectory.path,
+      directory.path,
+    );
+    let schema;
+    if (ctx.fs.exists(path.resolve(resolvedPath, "schema.ts"))) {
+      schema =
+        (await bundleSchema(ctx, resolvedPath, extraConditions))[0] || null;
+    } else if (ctx.fs.exists(path.resolve(resolvedPath, "schema.js"))) {
+      schema =
+        (await bundleSchema(ctx, resolvedPath, extraConditions))[0] || null;
+    } else {
+      schema = null;
+    }
+
+    const entryPoints = await entryPointsByEnvironment(ctx, resolvedPath);
+    const convexResult: {
+      modules: Bundle[];
+      externalDependencies: Map<string, string>;
+      bundledModuleNames: Set<string>;
+    } = await bundle(
+      ctx,
+      resolvedPath,
+      entryPoints.isolate,
+      true,
+      "browser",
+      undefined,
+      undefined,
+      extraConditions,
+    );
+
+    if (convexResult.externalDependencies.size !== 0) {
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage: "external dependencies not supported",
+      });
+    }
+    const functions = convexResult.modules;
+    if (isRoot) {
+      if (verbose) {
+        showSpinner(ctx, "Bundling modules for Node.js runtime...");
+      }
+      const nodeResult: {
+        modules: Bundle[];
+        externalDependencies: Map<string, string>;
+        bundledModuleNames: Set<string>;
+      } = await bundle(
+        ctx,
+        resolvedPath,
+        entryPoints.node,
+        true,
+        "node",
+        path.join("_deps", "node"),
+        nodeExternalPackages,
+        extraConditions,
+      );
+
+      const externalNodeDependencies: NodeDependency[] = [];
+      for (const [
+        moduleName,
+        moduleVersion,
+      ] of nodeResult.externalDependencies) {
+        externalNodeDependencies.push({
+          name: moduleName,
+          version: moduleVersion,
+        });
+      }
+      const authBundle = await bundleAuthConfig(ctx, resolvedPath);
+      appImplementation = {
+        schema,
+        functions: functions.concat(nodeResult.modules).concat(authBundle),
+        externalNodeDependencies,
+      };
+    } else {
+      // Reject push if components have node bundles in non-root directories.
+      if (directory.path !== rootComponentDirectory.path) {
+        const nodeResult: {
+          modules: Bundle[];
+          externalDependencies: Map<string, string>;
+          bundledModuleNames: Set<string>;
+        } = await bundle(
+          ctx,
+          resolvedPath,
+          entryPoints.node,
+          true,
+          "node",
+          path.join("_deps", "node"),
+          nodeExternalPackages,
+          extraConditions,
+        );
+        if (nodeResult.modules.length > 0) {
+          // TODO(ENG-7116) Remove error and bundle the component node actions when we are ready to support them.
+          await ctx.crash({
+            exitCode: 1,
+            errorType: "invalid filesystem data",
+            printedMessage: `"use node" directive is not supported in components. Remove it from the component at: ${resolvedPath}.`,
+          });
+        }
+      }
+      // definitionPath is the canonical form
+      const definitionPath = toComponentDefinitionPath(
+        rootComponentDirectory,
+        directory,
+      );
+      componentImplementations.push({ definitionPath, schema, functions });
+    }
+    isRoot = false;
+  }
+
+  if (!appImplementation) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: "No app implementation found",
+    });
+  }
+
+  return { appImplementation, componentImplementations };
+}
+
+async function registerEsbuildReads(
+  ctx: Context,
+  absWorkingDir: string,
+  metafile: Metafile,
+) {
+  for (const [relPath, input] of Object.entries(metafile.inputs)) {
+    if (
+      // We rewrite these files so this integrity check isn't useful.
+      path.basename(relPath).includes("convex.config") ||
+      // TODO: esbuild outputs paths prefixed with "(disabled)" when bundling our internal
+      // udf-system package. The files do actually exist locally, though.
+      relPath.indexOf("(disabled):") !== -1 ||
+      relPath.startsWith("wasm-binary:") ||
+      relPath.startsWith("wasm-stub:")
+    ) {
+      continue;
+    }
+    const absPath = path.resolve(absWorkingDir, relPath);
+    const st = ctx.fs.stat(absPath);
+    if (st.size !== input.bytes) {
+      // Consider this a transient error so we'll try again and hopefully
+      // no files change right after esbuild next time.
+      logWarning(
+        ctx,
+        `Bundled file ${absPath} changed right after esbuild invocation`,
+      );
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "transient",
+        printedMessage: null,
+      });
+    }
+    ctx.fs.registerPath(absPath, st);
+  }
+}
diff --git a/synced/convex/libs/cli/lib/components/definition/directoryStructure.ts b/synced/convex/libs/cli/lib/components/definition/directoryStructure.ts
new file mode 100644
index 0000000..89bbc9d
--- /dev/null
+++ b/synced/convex/libs/cli/lib/components/definition/directoryStructure.ts
@@ -0,0 +1,162 @@
+import path from "path";
+import { Context } from "../../../../bundler/context.js";
+import {
+  DEFINITION_FILENAME_JS,
+  DEFINITION_FILENAME_TS,
+} from "../constants.js";
+import { getFunctionsDirectoryPath } from "../../config.js";
+
+/**
+ * A component definition's location on the local filesystem using absolute paths.
+ *
+ * For module resolution it would be useful to avoid resolving any symlinks:
+ * node modules are often symlinked by e.g. pnpm but relative paths should generally be
+ * understood from their symlink location. We don't currently do this though, it made
+ * Windows harder to support.
+ *
+ * None of these properties are the import string, which might have been an unqualifed import
+ * (e.g. 'convex-waitlist' instead of '../node_modules/convex-waitlist/convex.config.ts')
+ */
+export type ComponentDirectory = {
+  /**
+   * Is this component directory for the root component?
+   */
+  isRoot: boolean;
+
+  /**
+   * Absolute local filesystem path to the component definition's directory.
+   */
+  path: string;
+
+  /**
+   * Absolute local filesystem path to the `convex.config.{ts,js}` file within the component definition.
+   */
+  definitionPath: string;
+};
+
+/**
+ * Qualify (ensure a leading dot) a path and make it relative to a working dir.
+ * Qualifying a path clarifies to esbuild that it represents a local file system
+ * path, not a remote path on the npm registry.
+ *
+ * If this path were made relative without resolving symlinks it would be a
+ * prettier identifier for the component directory, but instead symlinks are
+ * always resolved.
+ */
+export function qualifiedDefinitionPath(
+  directory: ComponentDirectory,
+  workingDir = ".",
+) {
+  const definitionPath = path.relative(workingDir, directory.definitionPath);
+  return `./${definitionPath}`;
+}
+
+// NB: The process cwd will be used to resolve the directory specified in the constructor.
+export function isComponentDirectory(
+  ctx: Context,
+  directory: string,
+  isRoot: boolean,
+):
+  | { kind: "ok"; component: ComponentDirectory }
+  | { kind: "err"; why: string } {
+  if (!ctx.fs.exists(directory)) {
+    return { kind: "err", why: `Directory doesn't exist` };
+  }
+  const dirStat = ctx.fs.stat(directory);
+  if (!dirStat.isDirectory()) {
+    return { kind: "err", why: `Not a directory` };
+  }
+
+  // Check that we have a definition file, defaulting to `.ts` but falling back to `.js`.
+  let filename = DEFINITION_FILENAME_TS;
+  let definitionPath = path.resolve(path.join(directory, filename));
+  if (!ctx.fs.exists(definitionPath)) {
+    filename = DEFINITION_FILENAME_JS;
+    definitionPath = path.resolve(path.join(directory, filename));
+  }
+  if (!ctx.fs.exists(definitionPath)) {
+    return {
+      kind: "err",
+      why: `Directory doesn't contain a ${filename} file`,
+    };
+  }
+  const definitionStat = ctx.fs.stat(definitionPath);
+  if (!definitionStat.isFile()) {
+    return {
+      kind: "err",
+      why: `Component definition ${filename} isn't a file`,
+    };
+  }
+  return {
+    kind: "ok",
+    component: {
+      isRoot,
+      path: path.resolve(directory),
+      definitionPath: definitionPath,
+    },
+  };
+}
+
+export async function buildComponentDirectory(
+  ctx: Context,
+  definitionPath: string,
+): Promise<ComponentDirectory> {
+  const convexDir = path.resolve(await getFunctionsDirectoryPath(ctx));
+  const isRoot = path.dirname(path.resolve(definitionPath)) === convexDir;
+  const isComponent = isComponentDirectory(
+    ctx,
+    path.dirname(definitionPath),
+    isRoot,
+  );
+  if (isComponent.kind === "err") {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "invalid filesystem data",
+      printedMessage: `Invalid component directory (${isComponent.why}): ${path.dirname(definitionPath)}`,
+    });
+  }
+  return isComponent.component;
+}
+
+/**
+ * ComponentPath is the local path identifying a
+ * component definition. It is the unqualified (it never starts with "./")
+ * relative path from the convex directory of the app (root component)
+ * to the directory where a component definition lives.
+ *
+ * Note the convex/ directory of the root component is not necessarily
+ * the working directory. It is currently never the same as the working
+ * directory since `npx convex` must be invoked from the package root instead.
+ */
+export type ComponentDefinitionPath = string & {
+  __brand: "ComponentDefinitionPath";
+};
+
+export function toComponentDefinitionPath(
+  rootComponent: ComponentDirectory,
+  component: ComponentDirectory,
+): ComponentDefinitionPath {
+  // First, compute a file system relative path.
+  const relativePath: string = path.relative(
+    rootComponent.path,
+    component.path,
+  );
+
+  // Then, convert it to a ComponentDefinitionPath, which always uses POSIX conventions.
+  const definitionPath = relativePath.split(path.sep).join(path.posix.sep);
+
+  return definitionPath as ComponentDefinitionPath;
+}
+
+export function toAbsolutePath(
+  rootComponent: ComponentDirectory,
+  componentDefinitionPath: ComponentDefinitionPath,
+) {
+  // Repeat the process from `toComponentDefinitionPath` in reverse: First
+  // convert to a relative local filesystem path, and then join it to
+  // the root component's absolute path.
+  const relativePath = componentDefinitionPath
+    .split(path.posix.sep)
+    .join(path.sep);
+  return path.normalize(path.join(rootComponent.path, relativePath));
+}
diff --git a/synced/convex/libs/cli/lib/config.test.ts b/synced/convex/libs/cli/lib/config.test.ts
new file mode 100644
index 0000000..09abd9b
--- /dev/null
+++ b/synced/convex/libs/cli/lib/config.test.ts
@@ -0,0 +1,73 @@
+import { vi, test, expect } from "vitest";
+import { parseProjectConfig } from "./config.js";
+import { logFailure, oneoffContext } from "../../bundler/context.js";
+import stripAnsi from "strip-ansi";
+
+test("parseProjectConfig", async () => {
+  // Make a context that throws on crashes so we can detect them.
+  const originalContext = await oneoffContext({
+    url: undefined,
+    adminKey: undefined,
+    envFile: undefined,
+  });
+  const ctx = {
+    ...originalContext,
+    crash: (args: { printedMessage: string | null }) => {
+      if (args.printedMessage !== null) {
+        logFailure(originalContext, args.printedMessage);
+      }
+      throw new Error();
+    },
+  };
+  const stderrSpy = vi.spyOn(process.stderr, "write").mockImplementation(() => {
+    // Do nothing
+    return true;
+  });
+  const assertParses = async (inp: any) => {
+    expect(await parseProjectConfig(ctx, inp)).toEqual(inp);
+  };
+  const assertParseError = async (inp: any, err: string) => {
+    await expect(parseProjectConfig(ctx, inp)).rejects.toThrow();
+    const calledWith = stderrSpy.mock.calls as string[][];
+    expect(stripAnsi(calledWith[0][0])).toEqual(err);
+  };
+
+  await assertParses({
+    team: "team",
+    project: "proj",
+    prodUrl: "prodUrl",
+    functions: "functions/",
+  });
+
+  await assertParses({
+    team: "team",
+    project: "proj",
+    prodUrl: "prodUrl",
+    functions: "functions/",
+    authInfos: [],
+  });
+
+  await assertParses({
+    team: "team",
+    project: "proj",
+    prodUrl: "prodUrl",
+    functions: "functions/",
+    authInfos: [
+      {
+        applicationID: "hello",
+        domain: "world",
+      },
+    ],
+  });
+
+  await assertParseError(
+    {
+      team: "team",
+      project: "proj",
+      prodUrl: "prodUrl",
+      functions: "functions/",
+      authInfo: [{}],
+    },
+    " Expected `authInfo` in `convex.json` to be type AuthInfo[]\n",
+  );
+});
diff --git a/synced/convex/libs/cli/lib/config.ts b/synced/convex/libs/cli/lib/config.ts
new file mode 100644
index 0000000..fd02425
--- /dev/null
+++ b/synced/convex/libs/cli/lib/config.ts
@@ -0,0 +1,1085 @@
+import chalk from "chalk";
+import equal from "deep-equal";
+import { EOL } from "os";
+import path from "path";
+import {
+  changeSpinner,
+  Context,
+  logError,
+  logFailure,
+  logFinishedStep,
+  logMessage,
+  showSpinner,
+} from "../../bundler/context.js";
+import {
+  Bundle,
+  BundleHash,
+  bundle,
+  bundleAuthConfig,
+  entryPointsByEnvironment,
+} from "../../bundler/index.js";
+import { version } from "../version.js";
+import { deploymentDashboardUrlPage } from "./dashboard.js";
+import {
+  formatSize,
+  functionsDir,
+  ErrorData,
+  loadPackageJson,
+  deploymentFetch,
+  deprecationCheckWarning,
+  logAndHandleFetchError,
+  ThrowingFetchError,
+} from "./utils/utils.js";
+import { createHash } from "crypto";
+import { promisify } from "util";
+import zlib from "zlib";
+import { recursivelyDelete } from "./fsUtils.js";
+import { NodeDependency } from "./deployApi/modules.js";
+import { ComponentDefinitionPath } from "./components/definition/directoryStructure.js";
+import {
+  LocalDeploymentError,
+  printLocalDeploymentOnError,
+} from "./localDeployment/errors.js";
+export { productionProvisionHost, provisionHost } from "./utils/utils.js";
+
+const brotli = promisify(zlib.brotliCompress);
+
+/** Type representing auth configuration. */
+export interface AuthInfo {
+  // Provider-specific application identifier. Corresponds to the `aud` field in an OIDC token.
+  applicationID: string;
+  // Domain used for authentication. Corresponds to the `iss` field in an OIDC token.
+  domain: string;
+}
+
+/** Type representing Convex project configuration. */
+export interface ProjectConfig {
+  functions: string;
+  node: {
+    externalPackages: string[];
+  };
+  generateCommonJSApi: boolean;
+  // deprecated
+  project?: string;
+  // deprecated
+  team?: string;
+  // deprecated
+  prodUrl?: string;
+  // deprecated
+  authInfo?: AuthInfo[];
+
+  // These are beta flags for using static codegen from the `api.d.ts` and `dataModel.d.ts` files.
+  codegen: {
+    staticApi: boolean;
+    staticDataModel: boolean;
+  };
+}
+
+export interface Config {
+  projectConfig: ProjectConfig;
+  modules: Bundle[];
+  nodeDependencies: NodeDependency[];
+  schemaId?: string;
+  udfServerVersion?: string;
+}
+
+export interface ConfigWithModuleHashes {
+  projectConfig: ProjectConfig;
+  moduleHashes: BundleHash[];
+  nodeDependencies: NodeDependency[];
+  schemaId?: string;
+  udfServerVersion?: string;
+}
+
+const DEFAULT_FUNCTIONS_PATH = "convex/";
+
+/** Check if object is of AuthInfo type. */
+function isAuthInfo(object: any): object is AuthInfo {
+  return (
+    "applicationID" in object &&
+    typeof object.applicationID === "string" &&
+    "domain" in object &&
+    typeof object.domain === "string"
+  );
+}
+
+function isAuthInfos(object: any): object is AuthInfo[] {
+  return Array.isArray(object) && object.every((item: any) => isAuthInfo(item));
+}
+
+/** Error parsing ProjectConfig representation. */
+class ParseError extends Error {}
+
+/** Parse object to ProjectConfig. */
+export async function parseProjectConfig(
+  ctx: Context,
+  obj: any,
+): Promise<ProjectConfig> {
+  if (typeof obj !== "object") {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "invalid filesystem data",
+      printedMessage: "Expected `convex.json` to contain an object",
+    });
+  }
+  if (typeof obj.node === "undefined") {
+    obj.node = {
+      externalPackages: [],
+    };
+  } else if (typeof obj.node.externalPackages === "undefined") {
+    obj.node.externalPackages = [];
+  } else if (
+    !Array.isArray(obj.node.externalPackages) ||
+    !obj.node.externalPackages.every((item: any) => typeof item === "string")
+  ) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "invalid filesystem data",
+      printedMessage:
+        "Expected `node.externalPackages` in `convex.json` to be an array of strings",
+    });
+  }
+  if (typeof obj.generateCommonJSApi === "undefined") {
+    obj.generateCommonJSApi = false;
+  } else if (typeof obj.generateCommonJSApi !== "boolean") {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "invalid filesystem data",
+      printedMessage:
+        "Expected `generateCommonJSApi` in `convex.json` to be true or false",
+    });
+  }
+
+  if (typeof obj.functions === "undefined") {
+    obj.functions = DEFAULT_FUNCTIONS_PATH;
+  } else if (typeof obj.functions !== "string") {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "invalid filesystem data",
+      printedMessage: "Expected `functions` in `convex.json` to be a string",
+    });
+  }
+
+  // Allow the `authInfo` key to be omitted, treating it as an empty list of providers.
+  if (obj.authInfo !== undefined) {
+    if (!isAuthInfos(obj.authInfo)) {
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "invalid filesystem data",
+        printedMessage:
+          "Expected `authInfo` in `convex.json` to be type AuthInfo[]",
+      });
+    }
+  }
+
+  if (typeof obj.codegen === "undefined") {
+    obj.codegen = {};
+  }
+  if (typeof obj.codegen !== "object") {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "invalid filesystem data",
+      printedMessage: "Expected `codegen` in `convex.json` to be an object",
+    });
+  }
+  if (typeof obj.codegen.staticApi === "undefined") {
+    obj.codegen.staticApi = false;
+  }
+  if (typeof obj.codegen.staticDataModel === "undefined") {
+    obj.codegen.staticDataModel = false;
+  }
+  if (
+    typeof obj.codegen.staticApi !== "boolean" ||
+    typeof obj.codegen.staticDataModel !== "boolean"
+  ) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "invalid filesystem data",
+      printedMessage:
+        "Expected `codegen.staticApi` and `codegen.staticDataModel` in `convex.json` to be booleans",
+    });
+  }
+
+  return obj;
+}
+
+// Parse a deployment config returned by the backend, picking out
+// the fields we care about.
+function parseBackendConfig(obj: any): {
+  functions: string;
+  authInfo?: AuthInfo[];
+} {
+  if (typeof obj !== "object") {
+    // Unexpected error
+    // eslint-disable-next-line no-restricted-syntax
+    throw new ParseError("Expected an object");
+  }
+  const { functions, authInfo } = obj;
+  if (typeof functions !== "string") {
+    // Unexpected error
+    // eslint-disable-next-line no-restricted-syntax
+    throw new ParseError("Expected functions to be a string");
+  }
+
+  // Allow the `authInfo` key to be omitted
+  if ((authInfo ?? null) !== null && !isAuthInfos(authInfo)) {
+    // Unexpected error
+    // eslint-disable-next-line no-restricted-syntax
+    throw new ParseError("Expected authInfo to be type AuthInfo[]");
+  }
+
+  return {
+    functions,
+    ...((authInfo ?? null) !== null ? { authInfo: authInfo } : {}),
+  };
+}
+
+export function configName(): string {
+  return "convex.json";
+}
+
+export async function configFilepath(ctx: Context): Promise<string> {
+  const configFn = configName();
+  // We used to allow src/convex.json, but no longer (as of 10/7/2022).
+  // Leave an error message around to help people out. We can remove this
+  // error message after a couple months.
+  const preferredLocation = configFn;
+  const wrongLocation = path.join("src", configFn);
+
+  // Allow either location, but not both.
+  const preferredLocationExists = ctx.fs.exists(preferredLocation);
+  const wrongLocationExists = ctx.fs.exists(wrongLocation);
+  if (preferredLocationExists && wrongLocationExists) {
+    const message = `${chalk.red(`Error: both ${preferredLocation} and ${wrongLocation} files exist!`)}\nConsolidate these and remove ${wrongLocation}.`;
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "invalid filesystem data",
+      printedMessage: message,
+    });
+  }
+  if (!preferredLocationExists && wrongLocationExists) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "invalid filesystem data",
+      printedMessage: `Error: Please move ${wrongLocation} to the root of your project`,
+    });
+  }
+
+  return preferredLocation;
+}
+
+export async function getFunctionsDirectoryPath(ctx: Context): Promise<string> {
+  const { projectConfig, configPath } = await readProjectConfig(ctx);
+  return functionsDir(configPath, projectConfig);
+}
+
+/** Read configuration from a local `convex.json` file. */
+export async function readProjectConfig(ctx: Context): Promise<{
+  projectConfig: ProjectConfig;
+  configPath: string;
+}> {
+  if (!ctx.fs.exists("convex.json")) {
+    // create-react-app bans imports from outside of src, so we can just
+    // put the functions directory inside of src/ to work around this issue.
+    const packages = await loadPackageJson(ctx);
+    const isCreateReactApp = "react-scripts" in packages;
+    return {
+      projectConfig: {
+        functions: isCreateReactApp
+          ? `src/${DEFAULT_FUNCTIONS_PATH}`
+          : DEFAULT_FUNCTIONS_PATH,
+        node: {
+          externalPackages: [],
+        },
+        generateCommonJSApi: false,
+        codegen: {
+          staticApi: false,
+          staticDataModel: false,
+        },
+      },
+      configPath: configName(),
+    };
+  }
+  let projectConfig;
+  const configPath = await configFilepath(ctx);
+  try {
+    projectConfig = await parseProjectConfig(
+      ctx,
+      JSON.parse(ctx.fs.readUtf8File(configPath)),
+    );
+  } catch (err) {
+    if (err instanceof ParseError || err instanceof SyntaxError) {
+      logError(ctx, chalk.red(`Error: Parsing "${configPath}" failed`));
+      logMessage(ctx, chalk.gray(err.toString()));
+    } else {
+      logFailure(
+        ctx,
+        `Error: Unable to read project config file "${configPath}"\n` +
+          "  Are you running this command from the root directory of a Convex project? If so, run `npx convex dev` first.",
+      );
+      if (err instanceof Error) {
+        logError(ctx, chalk.red(err.message));
+      }
+    }
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "invalid filesystem data",
+      errForSentry: err,
+      // TODO -- move the logging above in here
+      printedMessage: null,
+    });
+  }
+  return {
+    projectConfig,
+    configPath,
+  };
+}
+
+export async function enforceDeprecatedConfigField(
+  ctx: Context,
+  config: ProjectConfig,
+  field: "team" | "project" | "prodUrl",
+): Promise<string> {
+  const value = config[field];
+  if (typeof value === "string") {
+    return value;
+  }
+  const err = new ParseError(`Expected ${field} to be a string`);
+  return await ctx.crash({
+    exitCode: 1,
+    errorType: "invalid filesystem data",
+    errForSentry: err,
+    printedMessage: `Error: Parsing convex.json failed:\n${chalk.gray(err.toString())}`,
+  });
+}
+
+/**
+ * Given a {@link ProjectConfig}, add in the bundled modules to produce the
+ * complete config.
+ */
+export async function configFromProjectConfig(
+  ctx: Context,
+  projectConfig: ProjectConfig,
+  configPath: string,
+  verbose: boolean,
+): Promise<{
+  config: Config;
+  bundledModuleInfos: BundledModuleInfo[];
+}> {
+  const baseDir = functionsDir(configPath, projectConfig);
+  // We bundle functions entry points separately since they execute on different
+  // platforms.
+  const entryPoints = await entryPointsByEnvironment(ctx, baseDir);
+  // es-build prints errors to console which would clobber
+  // our spinner.
+  if (verbose) {
+    showSpinner(ctx, "Bundling modules for Convex's runtime...");
+  }
+  const convexResult = await bundle(
+    ctx,
+    baseDir,
+    entryPoints.isolate,
+    true,
+    "browser",
+  );
+  if (verbose) {
+    logMessage(
+      ctx,
+      "Convex's runtime modules: ",
+      convexResult.modules.map((m) => m.path),
+    );
+  }
+
+  // Bundle node modules.
+  if (verbose && entryPoints.node.length !== 0) {
+    showSpinner(ctx, "Bundling modules for Node.js runtime...");
+  }
+  const nodeResult = await bundle(
+    ctx,
+    baseDir,
+    entryPoints.node,
+    true,
+    "node",
+    path.join("_deps", "node"),
+    projectConfig.node.externalPackages,
+  );
+  if (verbose && entryPoints.node.length !== 0) {
+    logMessage(
+      ctx,
+      "Node.js runtime modules: ",
+      nodeResult.modules.map((m) => m.path),
+    );
+    if (projectConfig.node.externalPackages.length > 0) {
+      logMessage(
+        ctx,
+        "Node.js runtime external dependencies (to be installed on the server): ",
+        [...nodeResult.externalDependencies.entries()].map(
+          (a) => `${a[0]}: ${a[1]}`,
+        ),
+      );
+    }
+  }
+  const modules = convexResult.modules;
+  modules.push(...nodeResult.modules);
+  modules.push(...(await bundleAuthConfig(ctx, baseDir)));
+
+  const nodeDependencies: NodeDependency[] = [];
+  for (const [moduleName, moduleVersion] of nodeResult.externalDependencies) {
+    nodeDependencies.push({ name: moduleName, version: moduleVersion });
+  }
+
+  const bundledModuleInfos: BundledModuleInfo[] = Array.from(
+    convexResult.bundledModuleNames.keys(),
+  ).map((moduleName) => {
+    return {
+      name: moduleName,
+      platform: "convex",
+    };
+  });
+  bundledModuleInfos.push(
+    ...Array.from(nodeResult.bundledModuleNames.keys()).map(
+      (moduleName): BundledModuleInfo => {
+        return {
+          name: moduleName,
+          platform: "node",
+        };
+      },
+    ),
+  );
+
+  return {
+    config: {
+      projectConfig: projectConfig,
+      modules: modules,
+      nodeDependencies: nodeDependencies,
+      // We're just using the version this CLI is running with for now.
+      // This could be different than the version of `convex` the app runs with
+      // if the CLI is installed globally.
+      udfServerVersion: version,
+    },
+    bundledModuleInfos,
+  };
+}
+
+/**
+ * Read the config from `convex.json` and bundle all the modules.
+ */
+export async function readConfig(
+  ctx: Context,
+  verbose: boolean,
+): Promise<{
+  config: Config;
+  configPath: string;
+  bundledModuleInfos: BundledModuleInfo[];
+}> {
+  const { projectConfig, configPath } = await readProjectConfig(ctx);
+  const { config, bundledModuleInfos } = await configFromProjectConfig(
+    ctx,
+    projectConfig,
+    configPath,
+    verbose,
+  );
+  return { config, configPath, bundledModuleInfos };
+}
+
+export async function upgradeOldAuthInfoToAuthConfig(
+  ctx: Context,
+  config: ProjectConfig,
+  functionsPath: string,
+) {
+  if (config.authInfo !== undefined) {
+    const authConfigPathJS = path.resolve(functionsPath, "auth.config.js");
+    const authConfigPathTS = path.resolve(functionsPath, "auth.config.js");
+    const authConfigPath = ctx.fs.exists(authConfigPathJS)
+      ? authConfigPathJS
+      : authConfigPathTS;
+    const authConfigRelativePath = path.join(
+      config.functions,
+      ctx.fs.exists(authConfigPathJS) ? "auth.config.js" : "auth.config.ts",
+    );
+    if (ctx.fs.exists(authConfigPath)) {
+      await ctx.crash({
+        exitCode: 1,
+        errorType: "invalid filesystem data",
+        printedMessage:
+          `Cannot set auth config in both \`${authConfigRelativePath}\` and convex.json,` +
+          ` remove it from convex.json`,
+      });
+    }
+    if (config.authInfo.length > 0) {
+      const providersStringLines = JSON.stringify(
+        config.authInfo,
+        null,
+        2,
+      ).split(EOL);
+      const indentedProvidersString = [providersStringLines[0]]
+        .concat(providersStringLines.slice(1).map((line) => `  ${line}`))
+        .join(EOL);
+      ctx.fs.writeUtf8File(
+        authConfigPath,
+        `\
+  export default {
+    providers: ${indentedProvidersString},
+  };`,
+      );
+      logMessage(
+        ctx,
+        chalk.yellowBright(
+          `Moved auth config from config.json to \`${authConfigRelativePath}\``,
+        ),
+      );
+    }
+    delete config.authInfo;
+  }
+  return config;
+}
+
+/** Write the config to `convex.json` in the current working directory. */
+export async function writeProjectConfig(
+  ctx: Context,
+  projectConfig: ProjectConfig,
+  { deleteIfAllDefault }: { deleteIfAllDefault: boolean } = {
+    deleteIfAllDefault: false,
+  },
+) {
+  const configPath = await configFilepath(ctx);
+  const strippedConfig = filterWriteableConfig(stripDefaults(projectConfig));
+  if (Object.keys(strippedConfig).length > 0) {
+    try {
+      const contents = JSON.stringify(strippedConfig, undefined, 2) + "\n";
+      ctx.fs.writeUtf8File(configPath, contents, 0o644);
+    } catch (err) {
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "invalid filesystem data",
+        errForSentry: err,
+        printedMessage:
+          `Error: Unable to write project config file "${configPath}" in current directory\n` +
+          "  Are you running this command from the root directory of a Convex project?",
+      });
+    }
+  } else if (deleteIfAllDefault && ctx.fs.exists(configPath)) {
+    ctx.fs.unlink(configPath);
+    logMessage(
+      ctx,
+      chalk.yellowBright(
+        `Deleted ${configPath} since it completely matched defaults`,
+      ),
+    );
+  }
+  ctx.fs.mkdir(functionsDir(configPath, projectConfig), {
+    allowExisting: true,
+  });
+}
+
+function stripDefaults(projectConfig: ProjectConfig): any {
+  const stripped: any = { ...projectConfig };
+  if (stripped.functions === DEFAULT_FUNCTIONS_PATH) {
+    delete stripped.functions;
+  }
+  if (Array.isArray(stripped.authInfo) && stripped.authInfo.length === 0) {
+    delete stripped.authInfo;
+  }
+  if (stripped.node.externalPackages.length === 0) {
+    delete stripped.node.externalPackages;
+  }
+  if (stripped.generateCommonJSApi === false) {
+    delete stripped.generateCommonJSApi;
+  }
+  // Remove "node" field if it has nothing nested under it
+  if (Object.keys(stripped.node).length === 0) {
+    delete stripped.node;
+  }
+  if (stripped.codegen.staticApi === false) {
+    delete stripped.codegen.staticApi;
+  }
+  if (stripped.codegen.staticDataModel === false) {
+    delete stripped.codegen.staticDataModel;
+  }
+  if (Object.keys(stripped.codegen).length === 0) {
+    delete stripped.codegen;
+  }
+  return stripped;
+}
+
+function filterWriteableConfig(projectConfig: any) {
+  const writeable: any = { ...projectConfig };
+  delete writeable.project;
+  delete writeable.team;
+  delete writeable.prodUrl;
+  return writeable;
+}
+
+export function removedExistingConfig(
+  ctx: Context,
+  configPath: string,
+  options: { allowExistingConfig?: boolean },
+) {
+  if (!options.allowExistingConfig) {
+    return false;
+  }
+  recursivelyDelete(ctx, configPath);
+  logFinishedStep(ctx, `Removed existing ${configPath}`);
+  return true;
+}
+
+/** Pull configuration from the given remote origin. */
+export async function pullConfig(
+  ctx: Context,
+  project: string | undefined,
+  team: string | undefined,
+  origin: string,
+  adminKey: string,
+): Promise<ConfigWithModuleHashes> {
+  const fetch = deploymentFetch(ctx, {
+    deploymentUrl: origin,
+    adminKey,
+  });
+
+  changeSpinner(ctx, "Downloading current deployment state...");
+  try {
+    const res = await fetch("/api/get_config_hashes", {
+      method: "POST",
+      body: JSON.stringify({ version, adminKey }),
+    });
+    deprecationCheckWarning(ctx, res);
+    const data = await res.json();
+    const backendConfig = parseBackendConfig(data.config);
+    const projectConfig = {
+      ...backendConfig,
+      // This field is not stored in the backend, which is ok since it is also
+      // not used to diff configs.
+      node: {
+        externalPackages: [],
+      },
+      // This field is not stored in the backend, it only affects the client.
+      generateCommonJSApi: false,
+      // This field is also not stored in the backend, it only affects the client.
+      codegen: {
+        staticApi: false,
+        staticDataModel: false,
+      },
+      project,
+      team,
+      prodUrl: origin,
+    };
+    return {
+      projectConfig,
+      moduleHashes: data.moduleHashes,
+      // TODO(presley): Add this to diffConfig().
+      nodeDependencies: data.nodeDependencies,
+      udfServerVersion: data.udfServerVersion,
+    };
+  } catch (err: unknown) {
+    logFailure(ctx, `Error: Unable to pull deployment config from ${origin}`);
+    return await logAndHandleFetchError(ctx, err);
+  }
+}
+
+interface BundledModuleInfo {
+  name: string;
+  platform: "node" | "convex";
+}
+
+/**
+ * A component definition spec contains enough information to create bundles
+ * of code that must be analyzed in order to construct a ComponentDefinition.
+ *
+ * Most paths are relative to the directory of the definitionPath.
+ */
+export type ComponentDefinitionSpec = {
+  /** This path is relative to the app (root component) directory. */
+  definitionPath: ComponentDefinitionPath;
+
+  /** Dependencies are paths to the directory of the dependency component definition from the app (root component) directory */
+  dependencies: ComponentDefinitionPath[];
+
+  // All other paths are relative to the directory of the definitionPath above.
+  definition: Bundle;
+  schema: Bundle;
+  functions: Bundle[];
+};
+
+export type AppDefinitionSpec = Omit<
+  ComponentDefinitionSpec,
+  "definitionPath"
+> & {
+  // Only app (root) component specs contain an auth bundle.
+  auth: Bundle | null;
+};
+
+export type ComponentDefinitionSpecWithoutImpls = Omit<
+  ComponentDefinitionSpec,
+  "schema" | "functions"
+>;
+export type AppDefinitionSpecWithoutImpls = Omit<
+  AppDefinitionSpec,
+  "schema" | "functions" | "auth"
+>;
+
+export function configJSON(
+  config: Config,
+  adminKey: string,
+  schemaId?: string,
+  pushMetrics?: PushMetrics,
+  bundledModuleInfos?: BundledModuleInfo[],
+) {
+  // Override origin with the url
+  const projectConfig = {
+    projectSlug: config.projectConfig.project,
+    teamSlug: config.projectConfig.team,
+    functions: config.projectConfig.functions,
+    authInfo: config.projectConfig.authInfo,
+  };
+  return {
+    config: projectConfig,
+    modules: config.modules,
+    nodeDependencies: config.nodeDependencies,
+    udfServerVersion: config.udfServerVersion,
+    schemaId,
+    adminKey,
+    pushMetrics,
+    bundledModuleInfos,
+  };
+}
+
+// Time in seconds of various spans of time during a push.
+export type PushMetrics = {
+  typecheck: number;
+  bundle: number;
+  schemaPush: number;
+  codePull: number;
+  totalBeforePush: number;
+};
+
+/** Push configuration to the given remote origin. */
+export async function pushConfig(
+  ctx: Context,
+  config: Config,
+  options: {
+    adminKey: string;
+    url: string;
+    deploymentName: string | null;
+    pushMetrics?: PushMetrics;
+    schemaId?: string;
+    bundledModuleInfos?: BundledModuleInfo[];
+  },
+): Promise<void> {
+  const serializedConfig = configJSON(
+    config,
+    options.adminKey,
+    options.schemaId,
+    options.pushMetrics,
+    options.bundledModuleInfos,
+  );
+  const fetch = deploymentFetch(ctx, {
+    deploymentUrl: options.url,
+    adminKey: options.adminKey,
+  });
+  try {
+    if (config.nodeDependencies.length > 0) {
+      changeSpinner(
+        ctx,
+        "Installing external packages and deploying source code...",
+      );
+    } else {
+      changeSpinner(ctx, "Analyzing and deploying source code...");
+    }
+    await fetch("/api/push_config", {
+      body: await brotli(JSON.stringify(serializedConfig), {
+        params: {
+          [zlib.constants.BROTLI_PARAM_MODE]: zlib.constants.BROTLI_MODE_TEXT,
+          [zlib.constants.BROTLI_PARAM_QUALITY]: 4,
+        },
+      }),
+      method: "POST",
+      headers: {
+        "Content-Type": "application/json",
+        "Content-Encoding": "br",
+      },
+    });
+  } catch (error: unknown) {
+    await handlePushConfigError(
+      ctx,
+      error,
+      "Error: Unable to push deployment config to " + options.url,
+      options.deploymentName,
+    );
+  }
+}
+
+type Files = { source: string; filename: string }[];
+
+export type CodegenResponse =
+  | {
+      success: true;
+      files: Files;
+    }
+  | {
+      success: false;
+      error: string;
+    };
+
+function renderModule(module: {
+  path: string;
+  sourceMapSize: number;
+  sourceSize: number;
+}): string {
+  return (
+    module.path +
+    ` (${formatSize(module.sourceSize)}, source map ${module.sourceMapSize})`
+  );
+}
+
+function hash(bundle: Bundle) {
+  return createHash("sha256")
+    .update(bundle.source)
+    .update(bundle.sourceMap || "")
+    .digest("hex");
+}
+
+type ModuleDiffStat = { count: number; size: number };
+export type ModuleDiffStats = {
+  updated: ModuleDiffStat;
+  identical: ModuleDiffStat;
+  added: ModuleDiffStat;
+  numDropped: number;
+};
+
+function compareModules(
+  oldModules: BundleHash[],
+  newModules: Bundle[],
+): {
+  diffString: string;
+  stats: ModuleDiffStats;
+} {
+  let diff = "";
+  const oldModuleMap = new Map(
+    oldModules.map((value) => [value.path, value.hash]),
+  );
+  const newModuleMap = new Map(
+    newModules.map((value) => [
+      value.path,
+      {
+        hash: hash(value),
+        sourceMapSize: value.sourceMap?.length ?? 0,
+        sourceSize: value.source.length,
+      },
+    ]),
+  );
+  const updatedModules: Array<{
+    path: string;
+    sourceMapSize: number;
+    sourceSize: number;
+  }> = [];
+  const identicalModules: Array<{ path: string; size: number }> = [];
+  const droppedModules: Array<string> = [];
+  const addedModules: Array<{
+    path: string;
+    sourceMapSize: number;
+    sourceSize: number;
+  }> = [];
+  for (const [path, oldHash] of oldModuleMap.entries()) {
+    const newModule = newModuleMap.get(path);
+    if (newModule === undefined) {
+      droppedModules.push(path);
+    } else if (newModule.hash !== oldHash) {
+      updatedModules.push({
+        path,
+        sourceMapSize: newModule.sourceMapSize,
+        sourceSize: newModule.sourceSize,
+      });
+    } else {
+      identicalModules.push({
+        path,
+        size: newModule.sourceSize + newModule.sourceMapSize,
+      });
+    }
+  }
+  for (const [path, newModule] of newModuleMap.entries()) {
+    if (oldModuleMap.get(path) === undefined) {
+      addedModules.push({
+        path,
+        sourceMapSize: newModule.sourceMapSize,
+        sourceSize: newModule.sourceSize,
+      });
+    }
+  }
+  if (droppedModules.length > 0 || updatedModules.length > 0) {
+    diff += "Delete the following modules:\n";
+    for (const module of droppedModules) {
+      diff += `[-] ${module}\n`;
+    }
+    for (const module of updatedModules) {
+      diff += `[-] ${module.path}\n`;
+    }
+  }
+
+  if (addedModules.length > 0 || updatedModules.length > 0) {
+    diff += "Add the following modules:\n";
+    for (const module of addedModules) {
+      diff += "[+] " + renderModule(module) + "\n";
+    }
+    for (const module of updatedModules) {
+      diff += "[+] " + renderModule(module) + "\n";
+    }
+  }
+
+  return {
+    diffString: diff,
+    stats: {
+      updated: {
+        count: updatedModules.length,
+        size: updatedModules.reduce((acc, curr) => {
+          return acc + curr.sourceMapSize + curr.sourceSize;
+        }, 0),
+      },
+      identical: {
+        count: identicalModules.length,
+        size: identicalModules.reduce((acc, curr) => {
+          return acc + curr.size;
+        }, 0),
+      },
+      added: {
+        count: addedModules.length,
+        size: addedModules.reduce((acc, curr) => {
+          return acc + curr.sourceMapSize + curr.sourceSize;
+        }, 0),
+      },
+      numDropped: droppedModules.length,
+    },
+  };
+}
+
+/** Generate a human-readable diff between the two configs. */
+export function diffConfig(
+  oldConfig: ConfigWithModuleHashes,
+  newConfig: Config,
+): { diffString: string; stats: ModuleDiffStats } {
+  const { diffString, stats } = compareModules(
+    oldConfig.moduleHashes,
+    newConfig.modules,
+  );
+  let diff = diffString;
+  const droppedAuth = [];
+  if (
+    oldConfig.projectConfig.authInfo !== undefined &&
+    newConfig.projectConfig.authInfo !== undefined
+  ) {
+    for (const oldAuth of oldConfig.projectConfig.authInfo) {
+      let matches = false;
+      for (const newAuth of newConfig.projectConfig.authInfo) {
+        if (equal(oldAuth, newAuth)) {
+          matches = true;
+          break;
+        }
+      }
+      if (!matches) {
+        droppedAuth.push(oldAuth);
+      }
+    }
+    if (droppedAuth.length > 0) {
+      diff += "Remove the following auth providers:\n";
+      for (const authInfo of droppedAuth) {
+        diff += "[-] " + JSON.stringify(authInfo) + "\n";
+      }
+    }
+
+    const addedAuth = [];
+    for (const newAuth of newConfig.projectConfig.authInfo) {
+      let matches = false;
+      for (const oldAuth of oldConfig.projectConfig.authInfo) {
+        if (equal(newAuth, oldAuth)) {
+          matches = true;
+          break;
+        }
+      }
+      if (!matches) {
+        addedAuth.push(newAuth);
+      }
+    }
+    if (addedAuth.length > 0) {
+      diff += "Add the following auth providers:\n";
+      for (const auth of addedAuth) {
+        diff += "[+] " + JSON.stringify(auth) + "\n";
+      }
+    }
+  } else if (
+    (oldConfig.projectConfig.authInfo !== undefined) !==
+    (newConfig.projectConfig.authInfo !== undefined)
+  ) {
+    diff += "Moved auth config into auth.config.ts\n";
+  }
+
+  let versionMessage = "";
+  const matches = oldConfig.udfServerVersion === newConfig.udfServerVersion;
+  if (oldConfig.udfServerVersion && (!newConfig.udfServerVersion || !matches)) {
+    versionMessage += `[-] ${oldConfig.udfServerVersion}\n`;
+  }
+  if (newConfig.udfServerVersion && (!oldConfig.udfServerVersion || !matches)) {
+    versionMessage += `[+] ${newConfig.udfServerVersion}\n`;
+  }
+  if (versionMessage) {
+    diff += "Change the server's function version:\n";
+    diff += versionMessage;
+  }
+
+  return { diffString: diff, stats };
+}
+
+export async function handlePushConfigError(
+  ctx: Context,
+  error: unknown,
+  defaultMessage: string,
+  deploymentName: string | null,
+) {
+  const data: ErrorData | undefined =
+    error instanceof ThrowingFetchError ? error.serverErrorData : undefined;
+  if (data?.code === "AuthConfigMissingEnvironmentVariable") {
+    const errorMessage = data.message || "(no error message given)";
+    const [, variableName] =
+      errorMessage.match(/Environment variable (\S+)/i) ?? [];
+    const envVarMessage =
+      `Environment variable ${chalk.bold(
+        variableName,
+      )} is used in auth config file but ` + `its value was not set.`;
+    let setEnvVarInstructions =
+      "Go set it in the dashboard or using `npx convex env set`";
+
+    // If `npx convex dev` is running using --url there might not be a configured deployment
+    if (deploymentName !== null) {
+      const variableQuery =
+        variableName !== undefined ? `?var=${variableName}` : "";
+      const dashboardUrl = deploymentDashboardUrlPage(
+        deploymentName,
+        `/settings/environment-variables${variableQuery}`,
+      );
+      setEnvVarInstructions = `Go to:\n\n    ${chalk.bold(
+        dashboardUrl,
+      )}\n\n  to set it up. `;
+    }
+    await ctx.crash({
+      exitCode: 1,
+      errorType: "invalid filesystem or env vars",
+      errForSentry: error,
+      printedMessage: envVarMessage + "\n" + setEnvVarInstructions,
+    });
+  }
+
+  if (data?.code === "InternalServerError") {
+    if (deploymentName?.startsWith("local-")) {
+      printLocalDeploymentOnError(ctx);
+      return ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        errForSentry: new LocalDeploymentError(
+          "InternalServerError while pushing to local deployment",
+        ),
+        printedMessage: defaultMessage,
+      });
+    }
+  }
+
+  logFailure(ctx, defaultMessage);
+  return await logAndHandleFetchError(ctx, error);
+}
diff --git a/synced/convex/libs/cli/lib/convexExport.ts b/synced/convex/libs/cli/lib/convexExport.ts
new file mode 100644
index 0000000..220074e
--- /dev/null
+++ b/synced/convex/libs/cli/lib/convexExport.ts
@@ -0,0 +1,238 @@
+import chalk from "chalk";
+import {
+  waitUntilCalled,
+  deploymentFetch,
+  logAndHandleFetchError,
+} from "./utils/utils.js";
+import {
+  logFailure,
+  Context,
+  showSpinner,
+  logFinishedStep,
+  logError,
+  stopSpinner,
+  changeSpinner,
+} from "../../bundler/context.js";
+import { subscribe } from "./run.js";
+import { nodeFs } from "../../bundler/fs.js";
+import path from "path";
+import { Readable } from "stream";
+
+export async function exportFromDeployment(
+  ctx: Context,
+  options: {
+    deploymentUrl: string;
+    adminKey: string;
+    path: string;
+    includeFileStorage?: boolean;
+    deploymentNotice: string;
+    snapshotExportDashboardLink: string | undefined;
+  },
+) {
+  const includeStorage = !!options.includeFileStorage;
+  const {
+    deploymentUrl,
+    adminKey,
+    path: inputPath,
+    deploymentNotice,
+    snapshotExportDashboardLink,
+  } = options;
+
+  showSpinner(ctx, `Creating snapshot export${deploymentNotice}`);
+
+  const snapshotExportState = await startSnapshotExport(ctx, {
+    includeStorage,
+    inputPath,
+    adminKey,
+    deploymentUrl,
+  });
+
+  switch (snapshotExportState.state) {
+    case "completed":
+      stopSpinner(ctx);
+      logFinishedStep(
+        ctx,
+        `Created snapshot export at timestamp ${snapshotExportState.start_ts}`,
+      );
+      if (snapshotExportDashboardLink !== undefined) {
+        logFinishedStep(
+          ctx,
+          `Export is available at ${snapshotExportDashboardLink}`,
+        );
+      }
+      break;
+    case "requested":
+    case "in_progress": {
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage: `WARNING: Export is continuing to run on the server.`,
+      });
+    }
+    default: {
+      const _: never = snapshotExportState;
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage: `unknown error: unexpected state ${snapshotExportState as any}`,
+        errForSentry: `unexpected snapshot export state ${(snapshotExportState as any).state}`,
+      });
+    }
+  }
+
+  showSpinner(ctx, `Downloading snapshot export to ${chalk.bold(inputPath)}`);
+  const { filePath } = await downloadSnapshotExport(ctx, {
+    snapshotExportTs: snapshotExportState.start_ts,
+    inputPath,
+    adminKey,
+    deploymentUrl,
+  });
+  stopSpinner(ctx);
+  logFinishedStep(ctx, `Downloaded snapshot export to ${chalk.bold(filePath)}`);
+}
+
+type SnapshotExportState =
+  | { state: "requested" }
+  | { state: "in_progress" }
+  | {
+      state: "completed";
+      complete_ts: bigint;
+      start_ts: bigint;
+      zip_object_key: string;
+    };
+
+async function waitForStableExportState(
+  ctx: Context,
+  deploymentUrl: string,
+  adminKey: string,
+): Promise<SnapshotExportState> {
+  const [donePromise, onDone] = waitUntilCalled();
+  let snapshotExportState: SnapshotExportState;
+  await subscribe(ctx, {
+    deploymentUrl,
+    adminKey,
+    parsedFunctionName: "_system/cli/exports:getLatest",
+    parsedFunctionArgs: {},
+    componentPath: undefined,
+    until: donePromise,
+    callbacks: {
+      onChange: (value: any) => {
+        // NOTE: `value` would only be `null` if there has never been an export
+        // requested.
+        snapshotExportState = value;
+        switch (snapshotExportState.state) {
+          case "requested":
+          case "in_progress":
+            // Not a stable state.
+            break;
+          case "completed":
+            onDone();
+            break;
+          default: {
+            const _: never = snapshotExportState;
+            onDone();
+          }
+        }
+      },
+    },
+  });
+  return snapshotExportState!;
+}
+
+export async function startSnapshotExport(
+  ctx: Context,
+  args: {
+    includeStorage: boolean;
+    inputPath: string;
+    adminKey: string;
+    deploymentUrl: string;
+  },
+) {
+  const fetch = deploymentFetch(ctx, {
+    deploymentUrl: args.deploymentUrl,
+    adminKey: args.adminKey,
+  });
+  try {
+    await fetch(
+      `/api/export/request/zip?includeStorage=${args.includeStorage}`,
+      {
+        method: "POST",
+      },
+    );
+  } catch (e) {
+    return await logAndHandleFetchError(ctx, e);
+  }
+
+  const snapshotExportState = await waitForStableExportState(
+    ctx,
+    args.deploymentUrl,
+    args.adminKey,
+  );
+  return snapshotExportState;
+}
+
+export async function downloadSnapshotExport(
+  ctx: Context,
+  args: {
+    snapshotExportTs: bigint;
+    inputPath: string;
+    adminKey: string;
+    deploymentUrl: string;
+  },
+): Promise<{ filePath: string }> {
+  const inputPath = args.inputPath;
+  const exportUrl = `/api/export/zip/${args.snapshotExportTs.toString()}`;
+  const fetch = deploymentFetch(ctx, {
+    deploymentUrl: args.deploymentUrl,
+    adminKey: args.adminKey,
+  });
+  let response: Response;
+  try {
+    response = await fetch(exportUrl, {
+      method: "GET",
+    });
+  } catch (e) {
+    return await logAndHandleFetchError(ctx, e);
+  }
+
+  let filePath;
+  if (ctx.fs.exists(inputPath)) {
+    const st = ctx.fs.stat(inputPath);
+    if (st.isDirectory()) {
+      const contentDisposition =
+        response.headers.get("content-disposition") ?? "";
+      let filename = `snapshot_${args.snapshotExportTs.toString()}.zip`;
+      if (contentDisposition.startsWith("attachment; filename=")) {
+        filename = contentDisposition.slice("attachment; filename=".length);
+      }
+      filePath = path.join(inputPath, filename);
+    } else {
+      // TODO(sarah) -- if this is called elsewhere, I'd like to catch the error + potentially
+      // have different logging
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "invalid filesystem data",
+        printedMessage: `Error: Path ${chalk.bold(inputPath)} already exists.`,
+      });
+    }
+  } else {
+    filePath = inputPath;
+  }
+  changeSpinner(ctx, `Downloading snapshot export to ${chalk.bold(filePath)}`);
+
+  try {
+    await nodeFs.writeFileStream(
+      filePath,
+      Readable.fromWeb(response.body! as any),
+    );
+  } catch (e) {
+    logFailure(ctx, `Exporting data failed`);
+    logError(ctx, chalk.red(e));
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: `Exporting data failed: ${chalk.red(e)}`,
+    });
+  }
+  return { filePath };
+}
diff --git a/synced/convex/libs/cli/lib/convexImport.ts b/synced/convex/libs/cli/lib/convexImport.ts
new file mode 100644
index 0000000..ae45b56
--- /dev/null
+++ b/synced/convex/libs/cli/lib/convexImport.ts
@@ -0,0 +1,486 @@
+import chalk from "chalk";
+import {
+  formatSize,
+  waitUntilCalled,
+  deploymentFetch,
+  logAndHandleFetchError,
+} from "./utils/utils.js";
+import {
+  logFailure,
+  Context,
+  showSpinner,
+  logFinishedStep,
+  logWarning,
+  logMessage,
+  stopSpinner,
+  changeSpinner,
+} from "../../bundler/context.js";
+import path from "path";
+import { subscribe } from "./run.js";
+import { ConvexHttpClient } from "../../browser/http_client.js";
+import { makeFunctionReference } from "../../server/index.js";
+import { promptYesNo } from "./utils/prompts.js";
+
+// Backend has minimum chunk size of 5MiB except for the last chunk,
+// so we use 5MiB as highWaterMark which makes fs.ReadStream[asyncIterator]
+// output 5MiB chunks before the last one. This value can be overridden by
+// setting `CONVEX_IMPORT_CHUNK_SIZE` (bytes) in the environment.
+const DEFAULT_CHUNK_SIZE = 5 * 1024 * 1024;
+const ENV_CHUNK_SIZE = process.env.CONVEX_IMPORT_CHUNK_SIZE
+  ? parseInt(process.env.CONVEX_IMPORT_CHUNK_SIZE, 10)
+  : undefined;
+
+export async function importIntoDeployment(
+  ctx: Context,
+  filePath: string,
+  options: {
+    deploymentUrl: string;
+    adminKey: string;
+    deploymentNotice: string;
+    snapshotImportDashboardLink: string | undefined;
+    table?: string;
+    format?: "csv" | "jsonLines" | "jsonArray" | "zip";
+    replace?: boolean;
+    append?: boolean;
+    replaceAll?: boolean;
+    yes?: boolean;
+    component?: string;
+  },
+) {
+  if (!ctx.fs.exists(filePath)) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "invalid filesystem data",
+      printedMessage: `Error: Path ${chalk.bold(filePath)} does not exist.`,
+    });
+  }
+
+  const format = await determineFormat(ctx, filePath, options.format ?? null);
+  const tableName = options.table ?? null;
+  if (tableName === null) {
+    if (format !== "zip") {
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage: `Error: The \`--table\` option is required for format ${format}`,
+      });
+    }
+  } else {
+    if (format === "zip") {
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage: `Error: The \`--table\` option is not allowed for format ${format}`,
+      });
+    }
+  }
+
+  const convexClient = new ConvexHttpClient(options.deploymentUrl);
+  convexClient.setAdminAuth(options.adminKey);
+  const existingImports = await convexClient.query(
+    makeFunctionReference<"query", Record<string, never>, Array<unknown>>(
+      "_system/cli/queryImport:list",
+    ),
+    {},
+  );
+  const ongoingImports = existingImports.filter(
+    (i) => (i as any).state.state === "in_progress",
+  );
+  if (ongoingImports.length > 0) {
+    await askToConfirmImportWithExistingImports(
+      ctx,
+      options.snapshotImportDashboardLink,
+      options.yes,
+    );
+  }
+
+  const fileStats = ctx.fs.stat(filePath);
+  showSpinner(ctx, `Importing ${filePath} (${formatSize(fileStats.size)})`);
+
+  let mode = "requireEmpty";
+  if (options.append) {
+    mode = "append";
+  } else if (options.replace) {
+    mode = "replace";
+  } else if (options.replaceAll) {
+    mode = "replaceAll";
+  }
+  const importArgs = {
+    tableName: tableName === null ? undefined : tableName,
+    componentPath: options.component,
+    mode,
+    format,
+  };
+  const tableNotice = tableName ? ` to table "${chalk.bold(tableName)}"` : "";
+  const onFailure = async () => {
+    logFailure(
+      ctx,
+      `Importing data from "${chalk.bold(
+        filePath,
+      )}"${tableNotice}${options.deploymentNotice} failed`,
+    );
+  };
+  const importId = await uploadForImport(ctx, {
+    deploymentUrl: options.deploymentUrl,
+    adminKey: options.adminKey,
+    filePath,
+    importArgs,
+    onImportFailed: onFailure,
+  });
+  changeSpinner(ctx, "Parsing uploaded data");
+  const onProgress = (
+    ctx: Context,
+    state: InProgressImportState,
+    checkpointCount: number,
+  ) => {
+    stopSpinner(ctx);
+    while ((state.checkpoint_messages?.length ?? 0) > checkpointCount) {
+      logFinishedStep(ctx, state.checkpoint_messages![checkpointCount]);
+      checkpointCount += 1;
+    }
+    showSpinner(ctx, state.progress_message ?? "Importing");
+    return checkpointCount;
+  };
+  while (true) {
+    const snapshotImportState = await waitForStableImportState(ctx, {
+      importId,
+      deploymentUrl: options.deploymentUrl,
+      adminKey: options.adminKey,
+      onProgress,
+    });
+    switch (snapshotImportState.state) {
+      case "completed":
+        logFinishedStep(
+          ctx,
+          `Added ${snapshotImportState.num_rows_written} documents${tableNotice}${options.deploymentNotice}.`,
+        );
+        return;
+      case "failed":
+        return await ctx.crash({
+          exitCode: 1,
+          errorType: "fatal",
+          printedMessage: `Importing data from "${chalk.bold(
+            filePath,
+          )}"${tableNotice}${options.deploymentNotice} failed\n\n${chalk.red(snapshotImportState.error_message)}`,
+        });
+      case "waiting_for_confirmation": {
+        // Clear spinner state so we can log and prompt without clobbering lines.
+        stopSpinner(ctx);
+        await askToConfirmImport(
+          ctx,
+          snapshotImportState.message_to_confirm,
+          snapshotImportState.require_manual_confirmation,
+          options.yes,
+        );
+        showSpinner(ctx, `Importing`);
+        await confirmImport(ctx, {
+          importId,
+          adminKey: options.adminKey,
+          deploymentUrl: options.deploymentUrl,
+          onError: async () => {
+            logFailure(
+              ctx,
+              `Importing data from "${chalk.bold(
+                filePath,
+              )}"${tableNotice}${options.deploymentNotice} failed`,
+            );
+          },
+        });
+        // Now we have kicked off the rest of the import, go around the loop again.
+        break;
+      }
+      case "uploaded": {
+        return await ctx.crash({
+          exitCode: 1,
+          errorType: "fatal",
+          printedMessage: `Import canceled while parsing uploaded file`,
+        });
+      }
+      case "in_progress": {
+        const visitDashboardLink = options.snapshotImportDashboardLink
+          ? ` Visit ${options.snapshotImportDashboardLink} to monitor its progress.`
+          : "";
+        return await ctx.crash({
+          exitCode: 1,
+          errorType: "fatal",
+          printedMessage: `WARNING: Import is continuing to run on the server.${visitDashboardLink}`,
+        });
+      }
+      default: {
+        const _: never = snapshotImportState;
+        return await ctx.crash({
+          exitCode: 1,
+          errorType: "fatal",
+          printedMessage: `unknown error: unexpected state ${snapshotImportState as any}`,
+          errForSentry: `unexpected snapshot import state ${(snapshotImportState as any).state}`,
+        });
+      }
+    }
+  }
+}
+
+async function askToConfirmImport(
+  ctx: Context,
+  messageToConfirm: string | undefined,
+  requireManualConfirmation: boolean | undefined,
+  yes: boolean | undefined,
+) {
+  if (!messageToConfirm?.length) {
+    return;
+  }
+  logMessage(ctx, messageToConfirm);
+  if (requireManualConfirmation !== false && !yes) {
+    const confirmed = await promptYesNo(ctx, {
+      message: "Perform import?",
+      default: true,
+    });
+    if (!confirmed) {
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage: "Import canceled",
+      });
+    }
+  }
+}
+
+async function askToConfirmImportWithExistingImports(
+  ctx: Context,
+  snapshotImportDashboardLink: string | undefined,
+  yes: boolean | undefined,
+) {
+  const atDashboardLink = snapshotImportDashboardLink
+    ? ` You can view its progress at ${snapshotImportDashboardLink}.`
+    : "";
+  logMessage(
+    ctx,
+    `There is already a snapshot import in progress.${atDashboardLink}`,
+  );
+  if (yes) {
+    return;
+  }
+  const confirmed = await promptYesNo(ctx, {
+    message: "Start another import?",
+    default: true,
+  });
+  if (!confirmed) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: "Import canceled",
+    });
+  }
+}
+
+type InProgressImportState = {
+  state: "in_progress";
+  progress_message?: string | undefined;
+  checkpoint_messages?: string[] | undefined;
+};
+
+type SnapshotImportState =
+  | { state: "uploaded" }
+  | {
+      state: "waiting_for_confirmation";
+      message_to_confirm?: string;
+      require_manual_confirmation?: boolean;
+    }
+  | InProgressImportState
+  | { state: "completed"; num_rows_written: bigint }
+  | { state: "failed"; error_message: string };
+
+export async function waitForStableImportState(
+  ctx: Context,
+  args: {
+    importId: string;
+    deploymentUrl: string;
+    adminKey: string;
+    onProgress: (
+      ctx: Context,
+      state: InProgressImportState,
+      checkpointCount: number,
+    ) => number;
+  },
+): Promise<SnapshotImportState> {
+  const { importId, deploymentUrl, adminKey, onProgress } = args;
+  const [donePromise, onDone] = waitUntilCalled();
+  let snapshotImportState: SnapshotImportState;
+  let checkpointCount = 0;
+  await subscribe(ctx, {
+    deploymentUrl,
+    adminKey,
+    parsedFunctionName: "_system/cli/queryImport",
+    parsedFunctionArgs: { importId },
+    componentPath: undefined,
+    until: donePromise,
+    callbacks: {
+      onChange: (value: any) => {
+        snapshotImportState = value.state;
+        switch (snapshotImportState.state) {
+          case "waiting_for_confirmation":
+          case "completed":
+          case "failed":
+            onDone();
+            break;
+          case "uploaded":
+            // Not a stable state. Ignore while the server continues working.
+            return;
+          case "in_progress":
+            // Not a stable state. Ignore while the server continues working.
+            checkpointCount = onProgress(
+              ctx,
+              snapshotImportState,
+              checkpointCount,
+            );
+            return;
+        }
+      },
+    },
+  });
+  return snapshotImportState!;
+}
+
+async function determineFormat(
+  ctx: Context,
+  filePath: string,
+  format: string | null,
+) {
+  const fileExtension = path.extname(filePath);
+  if (fileExtension !== "") {
+    const formatToExtension: Record<string, string> = {
+      csv: ".csv",
+      jsonLines: ".jsonl",
+      jsonArray: ".json",
+      zip: ".zip",
+    };
+    const extensionToFormat = Object.fromEntries(
+      Object.entries(formatToExtension).map((a) => a.reverse()),
+    );
+    if (format !== null && fileExtension !== formatToExtension[format]) {
+      logWarning(
+        ctx,
+        chalk.yellow(
+          `Warning: Extension of file ${filePath} (${fileExtension}) does not match specified format: ${format} (${formatToExtension[format]}).`,
+        ),
+      );
+    }
+    format ??= extensionToFormat[fileExtension] ?? null;
+  }
+  if (format === null) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage:
+        "No input file format inferred by the filename extension or specified. Specify your input file's format using the `--format` flag.",
+    });
+  }
+  return format;
+}
+
+export async function confirmImport(
+  ctx: Context,
+  args: {
+    importId: string;
+    adminKey: string;
+    deploymentUrl: string;
+    onError: (e: any) => Promise<void>;
+  },
+) {
+  const { importId, adminKey, deploymentUrl } = args;
+  const fetch = deploymentFetch(ctx, {
+    deploymentUrl,
+    adminKey,
+  });
+  const performUrl = `/api/perform_import`;
+  try {
+    await fetch(performUrl, {
+      method: "POST",
+      body: JSON.stringify({ importId }),
+    });
+  } catch (e) {
+    await args.onError(e);
+    return await logAndHandleFetchError(ctx, e);
+  }
+}
+
+export async function uploadForImport(
+  ctx: Context,
+  args: {
+    deploymentUrl: string;
+    adminKey: string;
+    filePath: string;
+    importArgs: {
+      tableName?: string;
+      componentPath?: string;
+      mode: string;
+      format: string;
+    };
+    onImportFailed: (e: any) => Promise<void>;
+  },
+) {
+  const { deploymentUrl, adminKey, filePath } = args;
+  const fetch = deploymentFetch(ctx, {
+    deploymentUrl,
+    adminKey,
+  });
+
+  const fileStats = ctx.fs.stat(filePath);
+  // The backend rejects uploads of 10k or more parts. We use 9999 instead of
+  // 10000 so rounding errors can't push us over the limit.
+  const minChunkSize = Math.ceil(fileStats.size / 9999);
+  let chunkSize = ENV_CHUNK_SIZE ?? DEFAULT_CHUNK_SIZE;
+  if (chunkSize < minChunkSize) {
+    chunkSize = minChunkSize;
+  }
+  const data = ctx.fs.createReadStream(filePath, {
+    highWaterMark: chunkSize,
+  });
+
+  showSpinner(ctx, `Importing ${filePath} (${formatSize(fileStats.size)})`);
+  let importId: string;
+  try {
+    const startResp = await fetch("/api/import/start_upload", {
+      method: "POST",
+    });
+    const { uploadToken } = await startResp.json();
+
+    const partTokens = [];
+    let partNumber = 1;
+
+    for await (const chunk of data) {
+      const partUrl = `/api/import/upload_part?uploadToken=${encodeURIComponent(
+        uploadToken,
+      )}&partNumber=${partNumber}`;
+      const partResp = await fetch(partUrl, {
+        headers: {
+          "Content-Type": "application/octet-stream",
+        },
+        body: chunk,
+        method: "POST",
+      });
+      partTokens.push(await partResp.json());
+      partNumber += 1;
+      changeSpinner(
+        ctx,
+        `Uploading ${filePath} (${formatSize(data.bytesRead)}/${formatSize(
+          fileStats.size,
+        )})`,
+      );
+    }
+
+    const finishResp = await fetch("/api/import/finish_upload", {
+      body: JSON.stringify({
+        import: args.importArgs,
+        uploadToken,
+        partTokens,
+      }),
+      method: "POST",
+    });
+    const body = await finishResp.json();
+    importId = body.importId;
+  } catch (e) {
+    await args.onImportFailed(e);
+    return await logAndHandleFetchError(ctx, e);
+  }
+  return importId;
+}
diff --git a/synced/convex/libs/cli/lib/dashboard.ts b/synced/convex/libs/cli/lib/dashboard.ts
new file mode 100644
index 0000000..b7732f4
--- /dev/null
+++ b/synced/convex/libs/cli/lib/dashboard.ts
@@ -0,0 +1,56 @@
+import { Context } from "../../bundler/context.js";
+import { DeploymentType } from "./api.js";
+import { dashboardUrl as localDashboardUrl } from "./localDeployment/dashboard.js";
+
+export const DASHBOARD_HOST = process.env.CONVEX_PROVISION_HOST
+  ? "http://localhost:6789"
+  : "https://dashboard.convex.dev";
+
+export function getDashboardUrl(
+  ctx: Context,
+  {
+    deploymentName,
+    deploymentType,
+  }: {
+    deploymentName: string;
+    deploymentType: DeploymentType;
+  },
+): string | null {
+  switch (deploymentType) {
+    case "anonymous": {
+      return localDashboardUrl(ctx, deploymentName);
+    }
+    case "local":
+    case "dev":
+    case "prod":
+    case "preview":
+      return deploymentDashboardUrlPage(deploymentName, "");
+    default: {
+      const _exhaustiveCheck: never = deploymentType;
+      return _exhaustiveCheck;
+    }
+  }
+}
+
+export function deploymentDashboardUrlPage(
+  configuredDeployment: string | null,
+  page: string,
+): string {
+  return `${DASHBOARD_HOST}/d/${configuredDeployment}${page}`;
+}
+
+export function deploymentDashboardUrl(
+  team: string,
+  project: string,
+  deploymentName: string,
+) {
+  return `${projectDashboardUrl(team, project)}/${deploymentName}`;
+}
+
+export function projectDashboardUrl(team: string, project: string) {
+  return `${teamDashboardUrl(team)}/${project}`;
+}
+
+export function teamDashboardUrl(team: string) {
+  return `${DASHBOARD_HOST}/t/${team}`;
+}
diff --git a/synced/convex/libs/cli/lib/data.ts b/synced/convex/libs/cli/lib/data.ts
new file mode 100644
index 0000000..9d7eb04
--- /dev/null
+++ b/synced/convex/libs/cli/lib/data.ts
@@ -0,0 +1,217 @@
+import chalk from "chalk";
+import {
+  Context,
+  logError,
+  logOutput,
+  logWarning,
+} from "../../bundler/context.js";
+import { Base64 } from "../../values/index.js";
+import { Value } from "../../values/value.js";
+import { runSystemPaginatedQuery } from "./run.js";
+
+export async function dataInDeployment(
+  ctx: Context,
+  options: {
+    deploymentUrl: string;
+    adminKey: string;
+    deploymentNotice: string;
+    tableName?: string;
+    limit: number;
+    order: "asc" | "desc";
+    component?: string;
+  },
+) {
+  if (options.tableName !== undefined) {
+    await listDocuments(
+      ctx,
+      options.deploymentUrl,
+      options.adminKey,
+      options.tableName,
+      {
+        limit: options.limit,
+        order: options.order as "asc" | "desc",
+        componentPath: options.component ?? "",
+      },
+    );
+  } else {
+    await listTables(
+      ctx,
+      options.deploymentUrl,
+      options.adminKey,
+      options.deploymentNotice,
+      options.component ?? "",
+    );
+  }
+}
+
+async function listTables(
+  ctx: Context,
+  deploymentUrl: string,
+  adminKey: string,
+  deploymentNotice: string,
+  componentPath: string,
+) {
+  const tables = (await runSystemPaginatedQuery(ctx, {
+    deploymentUrl,
+    adminKey,
+    functionName: "_system/cli/tables",
+    componentPath,
+    args: {},
+  })) as { name: string }[];
+  if (tables.length === 0) {
+    logError(ctx, `There are no tables in the ${deploymentNotice}database.`);
+    return;
+  }
+  const tableNames = tables.map((table) => table.name);
+  tableNames.sort();
+  logOutput(ctx, tableNames.join("\n"));
+}
+
+async function listDocuments(
+  ctx: Context,
+  deploymentUrl: string,
+  adminKey: string,
+  tableName: string,
+  options: {
+    limit: number;
+    order: "asc" | "desc";
+    componentPath: string;
+  },
+) {
+  const data = (await runSystemPaginatedQuery(ctx, {
+    deploymentUrl,
+    adminKey,
+    functionName: "_system/cli/tableData",
+    componentPath: options.componentPath,
+    args: {
+      table: tableName,
+      order: options.order ?? "desc",
+    },
+    limit: options.limit + 1,
+  })) as Record<string, Value>[];
+
+  if (data.length === 0) {
+    logError(ctx, "There are no documents in this table.");
+    return;
+  }
+
+  logDocumentsTable(
+    ctx,
+    data.slice(0, options.limit).map((document) => {
+      const printed: Record<string, string> = {};
+      for (const key in document) {
+        printed[key] = stringify(document[key]);
+      }
+      return printed;
+    }),
+  );
+  if (data.length > options.limit) {
+    logWarning(
+      ctx,
+      chalk.yellow(
+        `Showing the ${options.limit} ${
+          options.order === "desc" ? "most recently" : "oldest"
+        } created document${
+          options.limit > 1 ? "s" : ""
+        }. Use the --limit option to see more.`,
+      ),
+    );
+  }
+}
+
+function logDocumentsTable(ctx: Context, rows: Record<string, string>[]) {
+  const columnsToWidths: Record<string, number> = {};
+  for (const row of rows) {
+    for (const column in row) {
+      const value = row[column];
+      columnsToWidths[column] = Math.max(
+        value.length,
+        columnsToWidths[column] ?? 0,
+      );
+    }
+  }
+  const unsortedFields = Object.keys(columnsToWidths);
+  unsortedFields.sort();
+  const fields = Array.from(
+    new Set(["_id", "_creationTime", ...unsortedFields]),
+  );
+  const columnWidths = fields.map((field) => columnsToWidths[field]);
+  const lineLimit = process.stdout.isTTY ? process.stdout.columns : undefined;
+
+  let didTruncate = false;
+
+  function limitLine(line: string, limit: number | undefined) {
+    if (limit === undefined) {
+      return line;
+    }
+    const limitWithBufferForUnicode = limit - 10;
+    if (line.length > limitWithBufferForUnicode) {
+      didTruncate = true;
+    }
+    return line.slice(0, limitWithBufferForUnicode);
+  }
+
+  logOutput(
+    ctx,
+    limitLine(
+      fields.map((field, i) => field.padEnd(columnWidths[i])).join(" | "),
+      lineLimit,
+    ),
+  );
+  logOutput(
+    ctx,
+    limitLine(
+      columnWidths.map((width) => "-".repeat(width)).join("-|-"),
+      lineLimit,
+    ),
+  );
+  for (const row of rows) {
+    logOutput(
+      ctx,
+      limitLine(
+        fields
+          .map((field, i) => (row[field] ?? "").padEnd(columnWidths[i]))
+          .join(" | "),
+        lineLimit,
+      ),
+    );
+  }
+  if (didTruncate) {
+    logWarning(
+      ctx,
+      chalk.yellow(
+        "Lines were truncated to fit the terminal width. Pipe the command to see " +
+          "the full output, such as:\n  `npx convex data tableName | less -S`",
+      ),
+    );
+  }
+}
+
+function stringify(value: Value): string {
+  if (value === null) {
+    return "null";
+  }
+  if (typeof value === "bigint") {
+    return `${value.toString()}n`;
+  }
+  if (typeof value === "number") {
+    return value.toString();
+  }
+  if (typeof value === "boolean") {
+    return value.toString();
+  }
+  if (typeof value === "string") {
+    return JSON.stringify(value);
+  }
+  if (value instanceof ArrayBuffer) {
+    const base64Encoded = Base64.fromByteArray(new Uint8Array(value));
+    return `Bytes("${base64Encoded}")`;
+  }
+  if (value instanceof Array) {
+    return `[${value.map(stringify).join(", ")}]`;
+  }
+  const pairs = Object.entries(value)
+    .map(([k, v]) => `"${k}": ${stringify(v!)}`)
+    .join(", ");
+  return `{ ${pairs} }`;
+}
diff --git a/synced/convex/libs/cli/lib/debugBundlePath.ts b/synced/convex/libs/cli/lib/debugBundlePath.ts
new file mode 100644
index 0000000..2a6262e
--- /dev/null
+++ b/synced/convex/libs/cli/lib/debugBundlePath.ts
@@ -0,0 +1,50 @@
+import path from "path";
+import { Context } from "../../bundler/context.js";
+import { Config } from "./config.js";
+
+export async function handleDebugBundlePath(
+  ctx: Context,
+  debugBundleDir: string,
+  config: Config,
+) {
+  if (!ctx.fs.exists(debugBundleDir)) {
+    ctx.fs.mkdir(debugBundleDir);
+  } else if (!ctx.fs.stat(debugBundleDir).isDirectory()) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: `Path \`${debugBundleDir}\` is not a directory. Please choose an empty directory for \`--debug-bundle-path\`.`,
+    });
+  } else if (ctx.fs.listDir(debugBundleDir).length !== 0) {
+    await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: `Directory \`${debugBundleDir}\` is not empty. Please remove it or choose an empty directory for \`--debug-bundle-path\`.`,
+    });
+  }
+  ctx.fs.writeUtf8File(
+    path.join(debugBundleDir, "fullConfig.json"),
+    JSON.stringify(config),
+  );
+
+  for (const moduleInfo of config.modules) {
+    const trimmedPath = moduleInfo.path.endsWith(".js")
+      ? moduleInfo.path.slice(0, moduleInfo.path.length - ".js".length)
+      : moduleInfo.path;
+    const environmentDir = path.join(debugBundleDir, moduleInfo.environment);
+    ctx.fs.mkdir(path.dirname(path.join(environmentDir, `${trimmedPath}.js`)), {
+      allowExisting: true,
+      recursive: true,
+    });
+    ctx.fs.writeUtf8File(
+      path.join(environmentDir, `${trimmedPath}.js`),
+      moduleInfo.source,
+    );
+    if (moduleInfo.sourceMap !== undefined) {
+      ctx.fs.writeUtf8File(
+        path.join(environmentDir, `${trimmedPath}.js.map`),
+        moduleInfo.sourceMap,
+      );
+    }
+  }
+}
diff --git a/synced/convex/libs/cli/lib/deploy2.ts b/synced/convex/libs/cli/lib/deploy2.ts
new file mode 100644
index 0000000..90deb60
--- /dev/null
+++ b/synced/convex/libs/cli/lib/deploy2.ts
@@ -0,0 +1,404 @@
+import {
+  changeSpinner,
+  Context,
+  logError,
+  logFailure,
+  logFinishedStep,
+  logVerbose,
+  showSpinner,
+} from "../../bundler/context.js";
+import { spawnSync } from "child_process";
+import { deploymentFetch, logAndHandleFetchError } from "./utils/utils.js";
+import {
+  schemaStatus,
+  SchemaStatus,
+  StartPushRequest,
+  startPushResponse,
+  StartPushResponse,
+} from "./deployApi/startPush.js";
+import {
+  AppDefinitionConfig,
+  ComponentDefinitionConfig,
+} from "./deployApi/definitionConfig.js";
+import chalk from "chalk";
+import { finishPushDiff, FinishPushDiff } from "./deployApi/finishPush.js";
+import { Reporter, Span } from "./tracing.js";
+import { promisify } from "node:util";
+import zlib from "node:zlib";
+import { PushOptions } from "./push.js";
+import { runPush } from "./components.js";
+import { suggestedEnvVarName } from "./envvars.js";
+import { runSystemQuery } from "./run.js";
+import { handlePushConfigError } from "./config.js";
+
+const brotli = promisify(zlib.brotliCompress);
+
+async function brotliCompress(ctx: Context, data: string): Promise<Buffer> {
+  const start = performance.now();
+  const result = await brotli(data, {
+    params: {
+      [zlib.constants.BROTLI_PARAM_MODE]: zlib.constants.BROTLI_MODE_TEXT,
+      [zlib.constants.BROTLI_PARAM_QUALITY]: 4,
+    },
+  });
+  const end = performance.now();
+  const duration = end - start;
+  logVerbose(
+    ctx,
+    `Compressed ${(data.length / 1024).toFixed(2)}KiB to ${(result.length / 1024).toFixed(2)}KiB (${((result.length / data.length) * 100).toFixed(2)}%) in ${duration.toFixed(2)}ms`,
+  );
+  return result;
+}
+
+/** Push configuration2 to the given remote origin. */
+export async function startPush(
+  ctx: Context,
+  span: Span,
+  request: StartPushRequest,
+  options: {
+    url: string;
+    deploymentName: string | null;
+  },
+): Promise<StartPushResponse> {
+  const custom = (_k: string | number, s: any) =>
+    typeof s === "string" ? s.slice(0, 40) + (s.length > 40 ? "..." : "") : s;
+  logVerbose(ctx, JSON.stringify(request, custom, 2));
+  const onError = (err: any) => {
+    if (err.toString() === "TypeError: fetch failed") {
+      changeSpinner(
+        ctx,
+        `Fetch failed, is ${options.url} correct? Retrying...`,
+      );
+    }
+  };
+  const fetch = deploymentFetch(ctx, {
+    deploymentUrl: options.url,
+    adminKey: request.adminKey,
+    onError,
+  });
+  changeSpinner(ctx, "Analyzing source code...");
+  try {
+    const response = await fetch("/api/deploy2/start_push", {
+      body: await brotliCompress(ctx, JSON.stringify(request)),
+      method: "POST",
+      headers: {
+        "Content-Type": "application/json",
+        "Content-Encoding": "br",
+        traceparent: span.encodeW3CTraceparent(),
+      },
+    });
+    return startPushResponse.parse(await response.json());
+  } catch (error: unknown) {
+    return await handlePushConfigError(
+      ctx,
+      error,
+      "Error: Unable to start push to " + options.url,
+      options.deploymentName,
+    );
+  }
+}
+
+// Long poll every 10s for progress on schema validation.
+const SCHEMA_TIMEOUT_MS = 10_000;
+
+export async function waitForSchema(
+  ctx: Context,
+  span: Span,
+  startPush: StartPushResponse,
+  options: {
+    adminKey: string;
+    url: string;
+    dryRun: boolean;
+  },
+) {
+  const fetch = deploymentFetch(ctx, {
+    deploymentUrl: options.url,
+    adminKey: options.adminKey,
+  });
+
+  changeSpinner(
+    ctx,
+    "Backfilling indexes and checking that documents match your schema...",
+  );
+
+  while (true) {
+    let currentStatus: SchemaStatus;
+    try {
+      const response = await fetch("/api/deploy2/wait_for_schema", {
+        body: JSON.stringify({
+          adminKey: options.adminKey,
+          schemaChange: startPush.schemaChange,
+          timeoutMs: SCHEMA_TIMEOUT_MS,
+          dryRun: options.dryRun,
+        }),
+        method: "POST",
+        headers: {
+          traceparent: span.encodeW3CTraceparent(),
+        },
+      });
+      currentStatus = schemaStatus.parse(await response.json());
+    } catch (error: unknown) {
+      logFailure(ctx, "Error: Unable to wait for schema from " + options.url);
+      return await logAndHandleFetchError(ctx, error);
+    }
+    switch (currentStatus.type) {
+      case "inProgress": {
+        let schemaDone = true;
+        let indexesComplete = 0;
+        let indexesTotal = 0;
+        for (const componentStatus of Object.values(currentStatus.components)) {
+          if (!componentStatus.schemaValidationComplete) {
+            schemaDone = false;
+          }
+          indexesComplete += componentStatus.indexesComplete;
+          indexesTotal += componentStatus.indexesTotal;
+        }
+        const indexesDone = indexesComplete === indexesTotal;
+        let msg: string;
+        if (!indexesDone && !schemaDone) {
+          msg = `Backfilling indexes (${indexesComplete}/${indexesTotal} ready) and checking that documents match your schema...`;
+        } else if (!indexesDone) {
+          msg = `Backfilling indexes (${indexesComplete}/${indexesTotal} ready)...`;
+        } else {
+          msg = "Checking that documents match your schema...";
+        }
+        changeSpinner(ctx, msg);
+        break;
+      }
+      case "failed": {
+        // Schema validation failed. This could be either because the data
+        // is bad or the schema is wrong. Classify this as a filesystem error
+        // because adjusting `schema.ts` is the most normal next step.
+        let msg = "Schema validation failed";
+        if (currentStatus.componentPath) {
+          msg += ` in component "${currentStatus.componentPath}"`;
+        }
+        msg += ".";
+        logFailure(ctx, msg);
+        logError(ctx, chalk.red(`${currentStatus.error}`));
+        return await ctx.crash({
+          exitCode: 1,
+          errorType: {
+            "invalid filesystem or db data": currentStatus.tableName
+              ? {
+                  tableName: currentStatus.tableName,
+                  componentPath: currentStatus.componentPath,
+                }
+              : null,
+          },
+          printedMessage: null, // TODO - move logging into here
+        });
+      }
+      case "raceDetected": {
+        return await ctx.crash({
+          exitCode: 1,
+          errorType: "fatal",
+          printedMessage: `Schema was overwritten by another push.`,
+        });
+      }
+      case "complete": {
+        changeSpinner(ctx, "Schema validation complete.");
+        return;
+      }
+    }
+  }
+}
+
+export async function finishPush(
+  ctx: Context,
+  span: Span,
+  startPush: StartPushResponse,
+  options: {
+    adminKey: string;
+    url: string;
+    dryRun: boolean;
+    verbose?: boolean;
+  },
+): Promise<FinishPushDiff> {
+  changeSpinner(ctx, "Finalizing push...");
+  const fetch = deploymentFetch(ctx, {
+    deploymentUrl: options.url,
+    adminKey: options.adminKey,
+  });
+  const request = {
+    adminKey: options.adminKey,
+    startPush,
+    dryRun: options.dryRun,
+  };
+  try {
+    const response = await fetch("/api/deploy2/finish_push", {
+      body: await brotliCompress(ctx, JSON.stringify(request)),
+      method: "POST",
+      headers: {
+        "Content-Type": "application/json",
+        "Content-Encoding": "br",
+        traceparent: span.encodeW3CTraceparent(),
+      },
+    });
+    return finishPushDiff.parse(await response.json());
+  } catch (error: unknown) {
+    logFailure(ctx, "Error: Unable to finish push to " + options.url);
+    return await logAndHandleFetchError(ctx, error);
+  }
+}
+
+export type ComponentDefinitionConfigWithoutImpls = Omit<
+  ComponentDefinitionConfig,
+  "schema" | "functions"
+>;
+export type AppDefinitionConfigWithoutImpls = Omit<
+  AppDefinitionConfig,
+  "schema" | "functions" | "auth"
+>;
+
+export async function reportPushCompleted(
+  ctx: Context,
+  adminKey: string,
+  url: string,
+  reporter: Reporter,
+) {
+  const fetch = deploymentFetch(ctx, {
+    deploymentUrl: url,
+    adminKey,
+  });
+  try {
+    const response = await fetch("/api/deploy2/report_push_completed", {
+      body: JSON.stringify({
+        adminKey,
+        spans: reporter.spans,
+      }),
+      method: "POST",
+    });
+    await response.json();
+  } catch (error: unknown) {
+    logFailure(
+      ctx,
+      "Error: Unable to report push completed to " + url + ": " + error,
+    );
+  }
+}
+
+export async function deployToDeployment(
+  ctx: Context,
+  credentials: {
+    url: string;
+    adminKey: string;
+    deploymentName: string | null;
+  },
+  options: {
+    verbose?: boolean | undefined;
+    dryRun?: boolean | undefined;
+    yes?: boolean | undefined;
+    typecheck: "enable" | "try" | "disable";
+    typecheckComponents: boolean;
+    codegen: "enable" | "disable";
+    cmd?: string | undefined;
+    cmdUrlEnvVarName?: string | undefined;
+
+    debugBundlePath?: string | undefined;
+    debug?: boolean | undefined;
+    writePushRequest?: string | undefined;
+    liveComponentSources?: boolean | undefined;
+    partitionId?: string | undefined;
+  },
+) {
+  const { url, adminKey } = credentials;
+  await runCommand(ctx, { ...options, url, adminKey });
+
+  const pushOptions: PushOptions = {
+    deploymentName: credentials.deploymentName,
+    adminKey,
+    verbose: !!options.verbose,
+    dryRun: !!options.dryRun,
+    typecheck: options.typecheck,
+    typecheckComponents: options.typecheckComponents,
+    debug: !!options.debug,
+    debugBundlePath: options.debugBundlePath,
+    codegen: options.codegen === "enable",
+    url,
+    writePushRequest: options.writePushRequest,
+    liveComponentSources: !!options.liveComponentSources,
+  };
+  showSpinner(
+    ctx,
+    `Deploying to ${url}...${options.dryRun ? " [dry run]" : ""}`,
+  );
+  await runPush(ctx, pushOptions);
+  logFinishedStep(
+    ctx,
+    `${
+      options.dryRun ? "Would have deployed" : "Deployed"
+    } Convex functions to ${url}`,
+  );
+}
+
+export async function runCommand(
+  ctx: Context,
+  options: {
+    cmdUrlEnvVarName?: string | undefined;
+    cmd?: string | undefined;
+    dryRun?: boolean | undefined;
+    url: string;
+    adminKey: string;
+  },
+) {
+  if (options.cmd === undefined) {
+    return;
+  }
+
+  const urlVar =
+    options.cmdUrlEnvVarName ?? (await suggestedEnvVarName(ctx)).envVar;
+  showSpinner(
+    ctx,
+    `Running '${options.cmd}' with environment variable "${urlVar}" set...${
+      options.dryRun ? " [dry run]" : ""
+    }`,
+  );
+  if (!options.dryRun) {
+    const canonicalCloudUrl = await fetchDeploymentCanonicalCloudUrl(ctx, {
+      deploymentUrl: options.url,
+      adminKey: options.adminKey,
+    });
+
+    const env = { ...process.env };
+    env[urlVar] = canonicalCloudUrl;
+    const result = spawnSync(options.cmd, {
+      env,
+      stdio: "inherit",
+      shell: true,
+    });
+    if (result.status !== 0) {
+      await ctx.crash({
+        exitCode: 1,
+        errorType: "invalid filesystem data",
+        printedMessage: `'${options.cmd}' failed`,
+      });
+    }
+  }
+  logFinishedStep(
+    ctx,
+    `${options.dryRun ? "Would have run" : "Ran"} "${
+      options.cmd
+    }" with environment variable "${urlVar}" set`,
+  );
+}
+
+export async function fetchDeploymentCanonicalCloudUrl(
+  ctx: Context,
+  options: { deploymentUrl: string; adminKey: string },
+): Promise<string> {
+  const result = await runSystemQuery(ctx, {
+    ...options,
+    functionName: "_system/cli/convexUrl:cloudUrl",
+    componentPath: undefined,
+    args: {},
+  });
+  if (typeof result !== "string") {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "invalid filesystem or env vars",
+      printedMessage: "Invalid process.env.CONVEX_CLOUD_URL",
+    });
+  }
+  return result;
+}
diff --git a/synced/convex/libs/cli/lib/deployApi/checkedComponent.ts b/synced/convex/libs/cli/lib/deployApi/checkedComponent.ts
new file mode 100644
index 0000000..df85d30
--- /dev/null
+++ b/synced/convex/libs/cli/lib/deployApi/checkedComponent.ts
@@ -0,0 +1,63 @@
+import { z } from "zod";
+import {
+  componentDefinitionPath,
+  componentFunctionPath,
+  ComponentDefinitionPath,
+  ComponentPath,
+  componentPath,
+} from "./paths.js";
+import { Identifier, identifier } from "./types.js";
+import { looseObject } from "./utils.js";
+
+export const resource = z.union([
+  looseObject({ type: z.literal("value"), value: z.string() }),
+  looseObject({
+    type: z.literal("function"),
+    path: componentFunctionPath,
+  }),
+]);
+export type Resource = z.infer<typeof resource>;
+
+export type CheckedExport =
+  | { type: "branch"; children: Record<Identifier, CheckedExport> }
+  | { type: "leaf"; resource: Resource };
+export const checkedExport: z.ZodType<CheckedExport> = z.lazy(() =>
+  z.union([
+    looseObject({
+      type: z.literal("branch"),
+      children: z.record(identifier, checkedExport),
+    }),
+    looseObject({
+      type: z.literal("leaf"),
+      resource,
+    }),
+  ]),
+);
+
+export const httpActionRoute = looseObject({
+  method: z.string(),
+  path: z.string(),
+});
+
+export const checkedHttpRoutes = looseObject({
+  httpModuleRoutes: z.nullable(z.array(httpActionRoute)),
+  mounts: z.array(z.string()),
+});
+export type CheckedHttpRoutes = z.infer<typeof checkedHttpRoutes>;
+
+export type CheckedComponent = {
+  definitionPath: ComponentDefinitionPath;
+  componentPath: ComponentPath;
+  args: Record<Identifier, Resource>;
+  childComponents: Record<Identifier, CheckedComponent>;
+};
+export const checkedComponent: z.ZodType<CheckedComponent> = z.lazy(() =>
+  looseObject({
+    definitionPath: componentDefinitionPath,
+    componentPath,
+    args: z.record(identifier, resource),
+    childComponents: z.record(identifier, checkedComponent),
+    httpRoutes: checkedHttpRoutes,
+    exports: z.record(identifier, checkedExport),
+  }),
+);
diff --git a/synced/convex/libs/cli/lib/deployApi/componentDefinition.ts b/synced/convex/libs/cli/lib/deployApi/componentDefinition.ts
new file mode 100644
index 0000000..85d7818
--- /dev/null
+++ b/synced/convex/libs/cli/lib/deployApi/componentDefinition.ts
@@ -0,0 +1,104 @@
+import { z } from "zod";
+import { canonicalizedModulePath, componentDefinitionPath } from "./paths.js";
+import { Identifier, Reference, identifier, reference } from "./types.js";
+import { analyzedModule, udfConfig } from "./modules.js";
+import { looseObject } from "./utils.js";
+import { convexValidator } from "./validator.js";
+
+export const componentArgumentValidator = looseObject({
+  type: z.literal("value"),
+  // Validator serialized to JSON.
+  value: z.string(),
+});
+
+export const componentDefinitionType = z.union([
+  looseObject({ type: z.literal("app") }),
+  looseObject({
+    type: z.literal("childComponent"),
+    name: identifier,
+    args: z.array(z.tuple([identifier, componentArgumentValidator])),
+  }),
+]);
+
+export const componentArgument = looseObject({
+  type: z.literal("value"),
+  // Value serialized to JSON.
+  value: z.string(),
+});
+
+export const componentInstantiation = looseObject({
+  name: identifier,
+  path: componentDefinitionPath,
+  args: z.nullable(z.array(z.tuple([identifier, componentArgument]))),
+});
+
+export type ComponentExports =
+  | { type: "leaf"; leaf: Reference }
+  | { type: "branch"; branch: [Identifier, ComponentExports][] };
+
+export const componentExports: z.ZodType<ComponentExports> = z.lazy(() =>
+  z.union([
+    looseObject({
+      type: z.literal("leaf"),
+      leaf: reference,
+    }),
+    looseObject({
+      type: z.literal("branch"),
+      branch: z.array(z.tuple([identifier, componentExports])),
+    }),
+  ]),
+);
+
+export const componentDefinitionMetadata = looseObject({
+  path: componentDefinitionPath,
+  definitionType: componentDefinitionType,
+  childComponents: z.array(componentInstantiation),
+  httpMounts: z.record(z.string(), reference),
+  exports: looseObject({
+    type: z.literal("branch"),
+    branch: z.array(z.tuple([identifier, componentExports])),
+  }),
+});
+
+export const indexSchema = looseObject({
+  indexDescriptor: z.string(),
+  fields: z.array(z.string()),
+});
+
+export const vectorIndexSchema = looseObject({
+  indexDescriptor: z.string(),
+  vectorField: z.string(),
+  dimensions: z.number().optional(),
+  filterFields: z.array(z.string()),
+});
+
+export const searchIndexSchema = looseObject({
+  indexDescriptor: z.string(),
+  searchField: z.string(),
+  filterFields: z.array(z.string()),
+});
+
+export const tableDefinition = looseObject({
+  tableName: z.string(),
+  indexes: z.array(indexSchema),
+  searchIndexes: z.array(searchIndexSchema).optional().nullable(),
+  vectorIndexes: z.array(vectorIndexSchema).optional().nullable(),
+  documentType: convexValidator,
+});
+export type TableDefinition = z.infer<typeof tableDefinition>;
+
+export const analyzedSchema = looseObject({
+  tables: z.array(tableDefinition),
+  schemaValidation: z.boolean(),
+});
+export type AnalyzedSchema = z.infer<typeof analyzedSchema>;
+
+export const evaluatedComponentDefinition = looseObject({
+  definition: componentDefinitionMetadata,
+  schema: analyzedSchema.optional().nullable(),
+  functions: z.record(canonicalizedModulePath, analyzedModule),
+  udfConfig,
+});
+export type EvaluatedComponentDefinition = z.infer<
+  typeof evaluatedComponentDefinition
+>;
diff --git a/synced/convex/libs/cli/lib/deployApi/definitionConfig.ts b/synced/convex/libs/cli/lib/deployApi/definitionConfig.ts
new file mode 100644
index 0000000..9b6f2a6
--- /dev/null
+++ b/synced/convex/libs/cli/lib/deployApi/definitionConfig.ts
@@ -0,0 +1,25 @@
+import { z } from "zod";
+import { componentDefinitionPath } from "./paths.js";
+import { moduleConfig } from "./modules.js";
+import { looseObject } from "./utils.js";
+
+export const appDefinitionConfig = looseObject({
+  definition: z.nullable(moduleConfig),
+  dependencies: z.array(componentDefinitionPath),
+  schema: z.nullable(moduleConfig),
+  functions: z.array(moduleConfig),
+  udfServerVersion: z.string(),
+});
+export type AppDefinitionConfig = z.infer<typeof appDefinitionConfig>;
+
+export const componentDefinitionConfig = looseObject({
+  definitionPath: componentDefinitionPath,
+  definition: moduleConfig,
+  dependencies: z.array(componentDefinitionPath),
+  schema: z.nullable(moduleConfig),
+  functions: z.array(moduleConfig),
+  udfServerVersion: z.string(),
+});
+export type ComponentDefinitionConfig = z.infer<
+  typeof componentDefinitionConfig
+>;
diff --git a/synced/convex/libs/cli/lib/deployApi/finishPush.ts b/synced/convex/libs/cli/lib/deployApi/finishPush.ts
new file mode 100644
index 0000000..038efbf
--- /dev/null
+++ b/synced/convex/libs/cli/lib/deployApi/finishPush.ts
@@ -0,0 +1,97 @@
+import { z } from "zod";
+import { looseObject } from "./utils.js";
+
+export const authDiff = looseObject({
+  added: z.array(z.string()),
+  removed: z.array(z.string()),
+});
+export type AuthDiff = z.infer<typeof authDiff>;
+
+export const componentDefinitionDiff = looseObject({});
+export type ComponentDefinitionDiff = z.infer<typeof componentDefinitionDiff>;
+
+export const componentDiffType = z.discriminatedUnion("type", [
+  looseObject({
+    type: z.literal("create"),
+  }),
+  looseObject({
+    type: z.literal("modify"),
+  }),
+  looseObject({
+    type: z.literal("unmount"),
+  }),
+  looseObject({
+    type: z.literal("remount"),
+  }),
+]);
+export type ComponentDiffType = z.infer<typeof componentDiffType>;
+
+export const moduleDiff = looseObject({
+  added: z.array(z.string()),
+  removed: z.array(z.string()),
+});
+export type ModuleDiff = z.infer<typeof moduleDiff>;
+
+export const udfConfigDiff = looseObject({
+  previous_version: z.string(),
+  next_version: z.string(),
+});
+export type UdfConfigDiff = z.infer<typeof udfConfigDiff>;
+
+export const cronDiff = looseObject({
+  added: z.array(z.string()),
+  updated: z.array(z.string()),
+  deleted: z.array(z.string()),
+});
+export type CronDiff = z.infer<typeof cronDiff>;
+
+const developerIndexConfig = z.discriminatedUnion("type", [
+  looseObject({
+    name: z.string(),
+    type: z.literal("database"),
+    fields: z.array(z.string()),
+  }),
+  looseObject({
+    name: z.string(),
+    type: z.literal("search"),
+    searchField: z.string(),
+    filterFields: z.array(z.string()),
+  }),
+  looseObject({
+    name: z.string(),
+    type: z.literal("vector"),
+    dimensions: z.number(),
+    vectorField: z.string(),
+    filterFields: z.array(z.string()),
+  }),
+]);
+export type DeveloperIndexConfig = z.infer<typeof developerIndexConfig>;
+
+export const indexDiff = looseObject({
+  added_indexes: z.array(developerIndexConfig),
+  removed_indexes: z.array(developerIndexConfig),
+});
+export type IndexDiff = z.infer<typeof indexDiff>;
+
+export const schemaDiff = looseObject({
+  previous_schema: z.nullable(z.string()),
+  next_schema: z.nullable(z.string()),
+});
+export type SchemaDiff = z.infer<typeof schemaDiff>;
+
+export const componentDiff = looseObject({
+  diffType: componentDiffType,
+  moduleDiff,
+  udfConfigDiff: z.nullable(udfConfigDiff),
+  cronDiff,
+  indexDiff,
+  schemaDiff: z.nullable(schemaDiff),
+});
+export type ComponentDiff = z.infer<typeof componentDiff>;
+
+export const finishPushDiff = looseObject({
+  authDiff,
+  definitionDiffs: z.record(z.string(), componentDefinitionDiff),
+  componentDiffs: z.record(z.string(), componentDiff),
+});
+export type FinishPushDiff = z.infer<typeof finishPushDiff>;
diff --git a/synced/convex/libs/cli/lib/deployApi/modules.ts b/synced/convex/libs/cli/lib/deployApi/modules.ts
new file mode 100644
index 0000000..3337892
--- /dev/null
+++ b/synced/convex/libs/cli/lib/deployApi/modules.ts
@@ -0,0 +1,62 @@
+import { z } from "zod";
+import { looseObject } from "./utils.js";
+
+export const moduleEnvironment = z.union([
+  z.literal("isolate"),
+  z.literal("node"),
+]);
+export type ModuleEnvironment = z.infer<typeof moduleEnvironment>;
+
+export const moduleConfig = looseObject({
+  path: z.string(),
+  source: z.string(),
+  sourceMap: z.optional(z.string()),
+  environment: moduleEnvironment,
+});
+export type ModuleConfig = z.infer<typeof moduleConfig>;
+
+export const nodeDependency = looseObject({
+  name: z.string(),
+  version: z.string(),
+});
+export type NodeDependency = z.infer<typeof nodeDependency>;
+
+export const udfConfig = looseObject({
+  serverVersion: z.string(),
+  // RNG seed encoded as Convex bytes in JSON.
+  importPhaseRngSeed: z.any(),
+  // Timestamp encoded as a Convex Int64 in JSON.
+  importPhaseUnixTimestamp: z.any(),
+});
+export type UdfConfig = z.infer<typeof udfConfig>;
+
+export const sourcePackage = z.any();
+export type SourcePackage = z.infer<typeof sourcePackage>;
+
+export const visibility = z.union([
+  looseObject({ kind: z.literal("public") }),
+  looseObject({ kind: z.literal("internal") }),
+]);
+export type Visibility = z.infer<typeof visibility>;
+
+export const analyzedFunction = looseObject({
+  name: z.string(),
+  pos: z.any(),
+  udfType: z.union([
+    z.literal("Query"),
+    z.literal("Mutation"),
+    z.literal("Action"),
+  ]),
+  visibility: z.nullable(visibility),
+  args: z.nullable(z.string()),
+  returns: z.nullable(z.string()),
+});
+export type AnalyzedFunction = z.infer<typeof analyzedFunction>;
+
+export const analyzedModule = looseObject({
+  functions: z.array(analyzedFunction),
+  httpRoutes: z.any(),
+  cronSpecs: z.any(),
+  sourceMapped: z.any(),
+});
+export type AnalyzedModule = z.infer<typeof analyzedModule>;
diff --git a/synced/convex/libs/cli/lib/deployApi/paths.ts b/synced/convex/libs/cli/lib/deployApi/paths.ts
new file mode 100644
index 0000000..af53801
--- /dev/null
+++ b/synced/convex/libs/cli/lib/deployApi/paths.ts
@@ -0,0 +1,18 @@
+import { z } from "zod";
+import { looseObject } from "./utils.js";
+
+// TODO share some of these types, to distinguish between encodedComponentDefinitionPaths etc.
+export const componentDefinitionPath = z.string();
+export type ComponentDefinitionPath = z.infer<typeof componentDefinitionPath>;
+
+export const componentPath = z.string();
+export type ComponentPath = z.infer<typeof componentPath>;
+
+export const canonicalizedModulePath = z.string();
+export type CanonicalizedModulePath = z.infer<typeof canonicalizedModulePath>;
+
+export const componentFunctionPath = looseObject({
+  component: z.string(),
+  udfPath: z.string(),
+});
+export type ComponentFunctionPath = z.infer<typeof componentFunctionPath>;
diff --git a/synced/convex/libs/cli/lib/deployApi/startPush.ts b/synced/convex/libs/cli/lib/deployApi/startPush.ts
new file mode 100644
index 0000000..4b3e107
--- /dev/null
+++ b/synced/convex/libs/cli/lib/deployApi/startPush.ts
@@ -0,0 +1,72 @@
+import { z } from "zod";
+import { componentDefinitionPath, componentPath } from "./paths.js";
+import { nodeDependency, sourcePackage } from "./modules.js";
+import { checkedComponent } from "./checkedComponent.js";
+import { evaluatedComponentDefinition } from "./componentDefinition.js";
+import {
+  appDefinitionConfig,
+  componentDefinitionConfig,
+} from "./definitionConfig.js";
+import { authInfo } from "./types.js";
+import { looseObject } from "./utils.js";
+
+export const startPushRequest = looseObject({
+  adminKey: z.string(),
+  dryRun: z.boolean(),
+
+  functions: z.string(),
+
+  appDefinition: appDefinitionConfig,
+  componentDefinitions: z.array(componentDefinitionConfig),
+
+  nodeDependencies: z.array(nodeDependency),
+});
+export type StartPushRequest = z.infer<typeof startPushRequest>;
+
+export const schemaChange = looseObject({
+  allocatedComponentIds: z.any(),
+  schemaIds: z.any(),
+});
+export type SchemaChange = z.infer<typeof schemaChange>;
+
+export const startPushResponse = looseObject({
+  environmentVariables: z.record(z.string(), z.string()),
+
+  externalDepsId: z.nullable(z.string()),
+  componentDefinitionPackages: z.record(componentDefinitionPath, sourcePackage),
+
+  appAuth: z.array(authInfo),
+  analysis: z.record(componentDefinitionPath, evaluatedComponentDefinition),
+
+  app: checkedComponent,
+
+  schemaChange,
+});
+export type StartPushResponse = z.infer<typeof startPushResponse>;
+
+export const componentSchemaStatus = looseObject({
+  schemaValidationComplete: z.boolean(),
+  indexesComplete: z.number(),
+  indexesTotal: z.number(),
+});
+export type ComponentSchemaStatus = z.infer<typeof componentSchemaStatus>;
+
+export const schemaStatus = z.union([
+  looseObject({
+    type: z.literal("inProgress"),
+    components: z.record(componentPath, componentSchemaStatus),
+  }),
+  looseObject({
+    type: z.literal("failed"),
+    error: z.string(),
+    componentPath,
+    tableName: z.nullable(z.string()),
+  }),
+  looseObject({
+    type: z.literal("raceDetected"),
+  }),
+  looseObject({
+    type: z.literal("complete"),
+  }),
+]);
+export type SchemaStatus = z.infer<typeof schemaStatus>;
diff --git a/synced/convex/libs/cli/lib/deployApi/types.ts b/synced/convex/libs/cli/lib/deployApi/types.ts
new file mode 100644
index 0000000..8860221
--- /dev/null
+++ b/synced/convex/libs/cli/lib/deployApi/types.ts
@@ -0,0 +1,32 @@
+import { z } from "zod";
+
+export const reference = z.string();
+export type Reference = z.infer<typeof reference>;
+
+// These validators parse the response from the backend so although
+// they roughly correspond with convex/auth.config.ts providers they
+// have been processed.
+
+// Passthrough so old CLIs can operate on new backend formats.
+const Oidc = z
+  .object({
+    applicationID: z.string(),
+    domain: z.string(),
+  })
+  .passthrough();
+const CustomJwt = z
+  .object({
+    type: z.literal("customJwt"),
+    applicationID: z.string().nullable(),
+    issuer: z.string(),
+    jwks: z.string(),
+    algorithm: z.string(),
+  })
+  .passthrough();
+
+export const authInfo = z.union([CustomJwt, Oidc]);
+
+export type AuthInfo = z.infer<typeof authInfo>;
+
+export const identifier = z.string();
+export type Identifier = z.infer<typeof identifier>;
diff --git a/synced/convex/libs/cli/lib/deployApi/utils.ts b/synced/convex/libs/cli/lib/deployApi/utils.ts
new file mode 100644
index 0000000..4f30bd0
--- /dev/null
+++ b/synced/convex/libs/cli/lib/deployApi/utils.ts
@@ -0,0 +1,37 @@
+import { z } from "zod";
+
+/**
+ * Convenience wrapper for z.object(...).passthrough().
+ *
+ * This object validator allows extra properties and passes them through.
+ * This is useful for forwards compatibility if the server adds extra unknown
+ * fields.
+ */
+export function looseObject<T extends z.ZodRawShape>(
+  shape: T,
+  params?: z.RawCreateParams,
+): z.ZodObject<
+  T,
+  "passthrough",
+  z.ZodTypeAny,
+  {
+    [k_1 in keyof z.objectUtil.addQuestionMarks<
+      z.baseObjectOutputType<T>,
+      {
+        [k in keyof z.baseObjectOutputType<T>]: undefined extends z.baseObjectOutputType<T>[k]
+          ? never
+          : k;
+      }[keyof T]
+    >]: z.objectUtil.addQuestionMarks<
+      z.baseObjectOutputType<T>,
+      {
+        [k in keyof z.baseObjectOutputType<T>]: undefined extends z.baseObjectOutputType<T>[k]
+          ? never
+          : k;
+      }[keyof T]
+    >[k_1];
+  },
+  { [k_2 in keyof z.baseObjectInputType<T>]: z.baseObjectInputType<T>[k_2] }
+> {
+  return z.object(shape, params).passthrough();
+}
diff --git a/synced/convex/libs/cli/lib/deployApi/validator.ts b/synced/convex/libs/cli/lib/deployApi/validator.ts
new file mode 100644
index 0000000..9e58f59
--- /dev/null
+++ b/synced/convex/libs/cli/lib/deployApi/validator.ts
@@ -0,0 +1,54 @@
+import { z } from "zod";
+import { looseObject } from "./utils.js";
+
+const baseConvexValidator = z.discriminatedUnion("type", [
+  looseObject({ type: z.literal("null") }),
+  looseObject({ type: z.literal("number") }),
+  looseObject({ type: z.literal("bigint") }),
+  looseObject({ type: z.literal("boolean") }),
+  looseObject({ type: z.literal("string") }),
+  looseObject({ type: z.literal("bytes") }),
+  looseObject({ type: z.literal("any") }),
+  looseObject({ type: z.literal("literal"), value: z.any() }),
+  looseObject({ type: z.literal("id"), tableName: z.string() }),
+]);
+export type ConvexValidator =
+  | z.infer<typeof baseConvexValidator>
+  | { type: "array"; value: ConvexValidator }
+  | {
+      type: "record";
+      keys: ConvexValidator;
+      values: { fieldType: ConvexValidator; optional: false };
+    }
+  | { type: "union"; value: ConvexValidator[] }
+  | {
+      type: "object";
+      value: Record<string, { fieldType: ConvexValidator; optional: boolean }>;
+    };
+export const convexValidator: z.ZodType<ConvexValidator> = z.lazy(() =>
+  z.union([
+    baseConvexValidator,
+    looseObject({ type: z.literal("array"), value: convexValidator }),
+    looseObject({
+      type: z.literal("record"),
+      keys: convexValidator,
+      values: z.object({
+        fieldType: convexValidator,
+        optional: z.literal(false),
+      }),
+    }),
+    looseObject({
+      type: z.literal("union"),
+      value: z.array(convexValidator),
+    }),
+    looseObject({
+      type: z.literal("object"),
+      value: z.record(
+        looseObject({
+          fieldType: convexValidator,
+          optional: z.boolean(),
+        }),
+      ),
+    }),
+  ]),
+);
diff --git a/synced/convex/libs/cli/lib/deployment.test.ts b/synced/convex/libs/cli/lib/deployment.test.ts
new file mode 100644
index 0000000..24f13c7
--- /dev/null
+++ b/synced/convex/libs/cli/lib/deployment.test.ts
@@ -0,0 +1,85 @@
+import { test, expect } from "vitest";
+import { changesToEnvVarFile, changesToGitIgnore } from "./deployment.js";
+
+const DEPLOYMENT = {
+  team: "snoops",
+  project: "earth",
+  deploymentName: "tall-bar",
+};
+
+test("env var changes", () => {
+  expect(changesToEnvVarFile(null, "prod", DEPLOYMENT)).toEqual(
+    "# Deployment used by `npx convex dev`\n" +
+      "CONVEX_DEPLOYMENT=prod:tall-bar # team: snoops, project: earth\n",
+  );
+
+  expect(changesToEnvVarFile("CONVEX_DEPLOYMENT=", "prod", DEPLOYMENT)).toEqual(
+    "CONVEX_DEPLOYMENT=prod:tall-bar # team: snoops, project: earth",
+  );
+
+  expect(
+    changesToEnvVarFile("CONVEX_DEPLOYMENT=foo", "prod", DEPLOYMENT),
+  ).toEqual("CONVEX_DEPLOYMENT=prod:tall-bar # team: snoops, project: earth");
+
+  expect(changesToEnvVarFile("RAD_DEPLOYMENT=foo", "prod", DEPLOYMENT)).toEqual(
+    "RAD_DEPLOYMENT=foo\n" +
+      "\n" +
+      "# Deployment used by `npx convex dev`\n" +
+      "CONVEX_DEPLOYMENT=prod:tall-bar # team: snoops, project: earth\n",
+  );
+
+  expect(
+    changesToEnvVarFile(
+      "RAD_DEPLOYMENT=foo\n" + "CONVEX_DEPLOYMENT=foo",
+      "prod",
+      DEPLOYMENT,
+    ),
+  ).toEqual(
+    "RAD_DEPLOYMENT=foo\n" +
+      "CONVEX_DEPLOYMENT=prod:tall-bar # team: snoops, project: earth",
+  );
+
+  expect(
+    changesToEnvVarFile(
+      "CONVEX_DEPLOYMENT=\n" + "RAD_DEPLOYMENT=foo",
+      "prod",
+      DEPLOYMENT,
+    ),
+  ).toEqual(
+    "CONVEX_DEPLOYMENT=prod:tall-bar # team: snoops, project: earth\n" +
+      "RAD_DEPLOYMENT=foo",
+  );
+});
+
+test("git ignore changes", () => {
+  // Handle additions
+  expect(changesToGitIgnore(null)).toEqual(".env.local\n");
+  expect(changesToGitIgnore("")).toEqual("\n.env.local\n");
+  expect(changesToGitIgnore(".env")).toEqual(".env\n.env.local\n");
+  expect(changesToGitIgnore("# .env.local")).toEqual(
+    "# .env.local\n.env.local\n",
+  );
+
+  // Handle existing
+  expect(changesToGitIgnore(".env.local")).toEqual(null);
+  expect(changesToGitIgnore(".env.*")).toEqual(null);
+  expect(changesToGitIgnore(".env*")).toEqual(null);
+
+  expect(changesToGitIgnore(".env*.local")).toEqual(null);
+  expect(changesToGitIgnore("*.local")).toEqual(null);
+  expect(changesToGitIgnore("# convex env\n.env.local")).toEqual(null);
+
+  // Handle Windows
+  expect(changesToGitIgnore(".env.local\r")).toEqual(null);
+  expect(changesToGitIgnore("foo\r\n.env.local")).toEqual(null);
+  expect(changesToGitIgnore("foo\r\n.env.local\r\n")).toEqual(null);
+  expect(changesToGitIgnore("foo\r\n.env.local\r\nbar")).toEqual(null);
+
+  // Handle trailing whitespace
+  expect(changesToGitIgnore(" .env.local ")).toEqual(null);
+
+  // Add .env.local (even if it's negated) to guide the user to solve the problem
+  expect(changesToGitIgnore("!.env.local")).toEqual(
+    "!.env.local\n.env.local\n",
+  );
+});
diff --git a/synced/convex/libs/cli/lib/deployment.ts b/synced/convex/libs/cli/lib/deployment.ts
new file mode 100644
index 0000000..4bb4129
--- /dev/null
+++ b/synced/convex/libs/cli/lib/deployment.ts
@@ -0,0 +1,254 @@
+import * as dotenv from "dotenv";
+import { Context } from "../../bundler/context.js";
+import { changedEnvVarFile, getEnvVarRegex } from "./envvars.js";
+import {
+  CONVEX_DEPLOY_KEY_ENV_VAR_NAME,
+  CONVEX_DEPLOYMENT_ENV_VAR_NAME,
+  ENV_VAR_FILE_PATH,
+} from "./utils/utils.js";
+import { DeploymentType } from "./api.js";
+
+// Given a deployment string like "dev:tall-forest-1234"
+// returns only the slug "tall-forest-1234".
+// If there's no prefix returns the original string.
+export function stripDeploymentTypePrefix(deployment: string) {
+  return deployment.split(":").at(-1)!;
+}
+
+// Handling legacy CONVEX_DEPLOYMENT without type prefix as well
+export function getDeploymentTypeFromConfiguredDeployment(raw: string) {
+  const typeRaw = raw.split(":")[0];
+  const type =
+    typeRaw === "prod" ||
+    typeRaw === "dev" ||
+    typeRaw === "preview" ||
+    typeRaw === "local"
+      ? typeRaw
+      : null;
+  return type;
+}
+
+export function isAnonymousDeployment(deploymentName: string) {
+  return deploymentName.startsWith("anonymous-");
+}
+
+export function removeAnonymousPrefix(deploymentName: string) {
+  if (isAnonymousDeployment(deploymentName)) {
+    return deploymentName.slice("anonymous-".length);
+  }
+  return deploymentName;
+}
+
+export async function writeDeploymentEnvVar(
+  ctx: Context,
+  deploymentType: DeploymentType,
+  deployment: {
+    team: string | null;
+    project: string | null;
+    deploymentName: string;
+  },
+  existingValue: string | null,
+): Promise<{ wroteToGitIgnore: boolean; changedDeploymentEnvVar: boolean }> {
+  const existingFile = ctx.fs.exists(ENV_VAR_FILE_PATH)
+    ? ctx.fs.readUtf8File(ENV_VAR_FILE_PATH)
+    : null;
+  const changedFile = changesToEnvVarFile(
+    existingFile,
+    deploymentType,
+    deployment,
+  );
+  const deploymentEnvVarValue =
+    deploymentType + ":" + deployment.deploymentName;
+
+  if (changedFile !== null) {
+    ctx.fs.writeUtf8File(ENV_VAR_FILE_PATH, changedFile);
+    // Only do this if we're not reinitializing an existing setup
+    return {
+      wroteToGitIgnore: await gitIgnoreEnvVarFile(ctx),
+      changedDeploymentEnvVar: existingValue !== deploymentEnvVarValue,
+    };
+  }
+  return {
+    wroteToGitIgnore: false,
+    changedDeploymentEnvVar: existingValue !== deploymentEnvVarValue,
+  };
+}
+
+// Only used in the internal --url flow
+export async function eraseDeploymentEnvVar(ctx: Context): Promise<boolean> {
+  const existingFile = ctx.fs.exists(ENV_VAR_FILE_PATH)
+    ? ctx.fs.readUtf8File(ENV_VAR_FILE_PATH)
+    : null;
+  if (existingFile === null) {
+    return false;
+  }
+  const config = dotenv.parse(existingFile);
+  const existing = config[CONVEX_DEPLOYMENT_ENV_VAR_NAME];
+  if (existing === undefined) {
+    return false;
+  }
+  const changedFile = existingFile.replace(
+    getEnvVarRegex(CONVEX_DEPLOYMENT_ENV_VAR_NAME),
+    "",
+  );
+  ctx.fs.writeUtf8File(ENV_VAR_FILE_PATH, changedFile);
+  return true;
+}
+
+async function gitIgnoreEnvVarFile(ctx: Context): Promise<boolean> {
+  const gitIgnorePath = ".gitignore";
+  const gitIgnoreContents = ctx.fs.exists(gitIgnorePath)
+    ? ctx.fs.readUtf8File(gitIgnorePath)
+    : "";
+  const changedGitIgnore = changesToGitIgnore(gitIgnoreContents);
+  if (changedGitIgnore !== null) {
+    ctx.fs.writeUtf8File(gitIgnorePath, changedGitIgnore);
+    return true;
+  }
+  return false;
+}
+
+// exported for tests
+export function changesToEnvVarFile(
+  existingFile: string | null,
+  deploymentType: DeploymentType,
+  {
+    team,
+    project,
+    deploymentName,
+  }: { team: string | null; project: string | null; deploymentName: string },
+): string | null {
+  const deploymentValue = deploymentType + ":" + deploymentName;
+  const commentOnPreviousLine = "# Deployment used by `npx convex dev`";
+  const commentAfterValue =
+    team !== null && project !== null
+      ? `team: ${team}, project: ${project}`
+      : null;
+  return changedEnvVarFile({
+    existingFileContent: existingFile,
+    envVarName: CONVEX_DEPLOYMENT_ENV_VAR_NAME,
+    envVarValue: deploymentValue,
+    commentAfterValue,
+    commentOnPreviousLine,
+  });
+}
+
+// exported for tests
+export function changesToGitIgnore(existingFile: string | null): string | null {
+  if (existingFile === null) {
+    return `${ENV_VAR_FILE_PATH}\n`;
+  }
+  const gitIgnoreLines = existingFile.split("\n");
+  const envVarFileIgnored = gitIgnoreLines.some((line) => {
+    if (line.startsWith("#")) return false;
+    if (line.startsWith("!")) return false;
+
+    // .gitignore ignores trailing whitespace, and also we need to remove
+    // the trailing `\r` from Windows-style newline since we split on `\n`.
+    const trimmedLine = line.trimEnd();
+
+    const envIgnorePatterns = [
+      /^\.env\.local$/,
+      /^\.env\.\*$/,
+      /^\.env\*$/,
+      /^.*\.local$/,
+      /^\.env\*\.local$/,
+    ];
+
+    return envIgnorePatterns.some((pattern) => pattern.test(trimmedLine));
+  });
+  if (!envVarFileIgnored) {
+    return `${existingFile}\n${ENV_VAR_FILE_PATH}\n`;
+  } else {
+    return null;
+  }
+}
+
+export async function deploymentNameFromAdminKeyOrCrash(
+  ctx: Context,
+  adminKey: string,
+) {
+  const deploymentName = deploymentNameFromAdminKey(adminKey);
+  if (deploymentName === null) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: `Please set ${CONVEX_DEPLOY_KEY_ENV_VAR_NAME} to a new key which you can find on your Convex dashboard.`,
+    });
+  }
+  return deploymentName;
+}
+
+function deploymentNameFromAdminKey(adminKey: string) {
+  const parts = adminKey.split("|");
+  if (parts.length === 1) {
+    return null;
+  }
+  if (isPreviewDeployKey(adminKey)) {
+    // Preview deploy keys do not contain a deployment name.
+    return null;
+  }
+  return stripDeploymentTypePrefix(parts[0]);
+}
+
+// Needed to differentiate a preview deploy key
+// from a concrete preview deployment's deploy key.
+// preview deploy key: `preview:team:project|key`
+// preview deployment's deploy key: `preview:deploymentName|key`
+export function isPreviewDeployKey(adminKey: string) {
+  const parts = adminKey.split("|");
+  if (parts.length === 1) {
+    return false;
+  }
+  const [prefix] = parts;
+  const prefixParts = prefix.split(":");
+  return prefixParts[0] === "preview" && prefixParts.length === 3;
+}
+
+export function isProjectKey(adminKey: string) {
+  return /^project:.*\|/.test(adminKey);
+}
+
+// For current keys returns prod|dev|preview,
+// for legacy keys returns "prod".
+// Examples:
+//  "prod:deploymentName|key" -> "prod"
+//  "preview:deploymentName|key" -> "preview"
+//  "dev:deploymentName|key" -> "dev"
+//  "key" -> "prod"
+export function deploymentTypeFromAdminKey(adminKey: string) {
+  const parts = adminKey.split(":");
+  if (parts.length === 1) {
+    return "prod";
+  }
+  return parts.at(0)! as DeploymentType;
+}
+
+export async function getTeamAndProjectFromPreviewAdminKey(
+  ctx: Context,
+  adminKey: string,
+) {
+  const parts = adminKey.split("|")[0].split(":");
+  if (parts.length !== 3) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage:
+        "Malformed preview CONVEX_DEPLOY_KEY, get a new key from Project Settings.",
+    });
+  }
+  const [_preview, teamSlug, projectSlug] = parts;
+  return { teamSlug, projectSlug };
+}
+
+export type OnDeploymentActivityFunc = (
+  isOffline: boolean,
+  wasOffline: boolean,
+) => Promise<void>;
+export type CleanupDeploymentFunc = () => Promise<void>;
+export type DeploymentDetails = {
+  deploymentName: string;
+  deploymentUrl: string;
+  adminKey: string;
+  onActivity: OnDeploymentActivityFunc | null;
+};
diff --git a/synced/convex/libs/cli/lib/deploymentSelection.ts b/synced/convex/libs/cli/lib/deploymentSelection.ts
new file mode 100644
index 0000000..88cd187
--- /dev/null
+++ b/synced/convex/libs/cli/lib/deploymentSelection.ts
@@ -0,0 +1,628 @@
+import { BigBrainAuth, Context, logVerbose } from "../../bundler/context.js";
+import {
+  AccountRequiredDeploymentType,
+  DeploymentType,
+  fetchTeamAndProjectForKey,
+} from "./api.js";
+import { readProjectConfig } from "./config.js";
+import {
+  deploymentNameFromAdminKeyOrCrash,
+  deploymentTypeFromAdminKey,
+  getDeploymentTypeFromConfiguredDeployment,
+  isAnonymousDeployment,
+  isPreviewDeployKey,
+  isProjectKey,
+  stripDeploymentTypePrefix,
+} from "./deployment.js";
+import { buildEnvironment } from "./envvars.js";
+import { readGlobalConfig } from "./utils/globalConfig.js";
+import {
+  CONVEX_DEPLOYMENT_ENV_VAR_NAME,
+  CONVEX_DEPLOY_KEY_ENV_VAR_NAME,
+  CONVEX_SELF_HOSTED_ADMIN_KEY_VAR_NAME,
+  CONVEX_SELF_HOSTED_URL_VAR_NAME,
+  ENV_VAR_FILE_PATH,
+  bigBrainAPI,
+} from "./utils/utils.js";
+import * as dotenv from "dotenv";
+
+// ----------------------------------------------------------------------------
+// Big Brain Auth
+// ----------------------------------------------------------------------------
+
+/**
+ * The auth header can be a few different things:
+ * * An access token (corresponds to device authorization, usually stored in `~/.convex/config.json`)
+ * * A preview deploy key (set via the `CONVEX_DEPLOY_KEY` environment variable)
+ * * A project key (set via the `CONVEX_DEPLOY_KEY` environment variable)
+ *
+ * Project keys take precedence over the the access token.
+ *
+ * We check for the `CONVEX_DEPLOY_KEY` in the `--env-file` if it's provided.
+ * Otherwise, we check in the `.env` and `.env.local` files.
+ *
+ * If we later prompt for log in, we need to call `ctx.setBigBrainAuthHeader` to
+ * update the value.
+ *
+ * @param ctx
+ * @param envFile
+ * @returns
+ */
+export async function initializeBigBrainAuth(
+  ctx: Context,
+  initialArgs: {
+    url?: string;
+    adminKey?: string;
+    envFile?: string;
+  },
+): Promise<void> {
+  if (initialArgs.url !== undefined && initialArgs.adminKey !== undefined) {
+    // Do not check any env vars if `url` and `adminKey` are specified via CLI
+    ctx._updateBigBrainAuth(
+      getBigBrainAuth(ctx, {
+        previewDeployKey: null,
+        projectKey: null,
+      }),
+    );
+    return;
+  }
+  if (initialArgs.envFile !== undefined) {
+    const existingFile = ctx.fs.exists(initialArgs.envFile)
+      ? ctx.fs.readUtf8File(initialArgs.envFile)
+      : null;
+    if (existingFile === null) {
+      return ctx.crash({
+        exitCode: 1,
+        errorType: "invalid filesystem or env vars",
+        printedMessage: "env file does not exist",
+      });
+    }
+    const config = dotenv.parse(existingFile);
+    const deployKey = config[CONVEX_DEPLOY_KEY_ENV_VAR_NAME];
+    if (deployKey !== undefined) {
+      const bigBrainAuth = getBigBrainAuth(ctx, {
+        previewDeployKey: isPreviewDeployKey(deployKey) ? deployKey : null,
+        projectKey: isProjectKey(deployKey) ? deployKey : null,
+      });
+      ctx._updateBigBrainAuth(bigBrainAuth);
+    }
+    return;
+  }
+  dotenv.config({ path: ENV_VAR_FILE_PATH });
+  dotenv.config();
+  const deployKey = process.env[CONVEX_DEPLOY_KEY_ENV_VAR_NAME];
+  if (deployKey !== undefined) {
+    const bigBrainAuth = getBigBrainAuth(ctx, {
+      previewDeployKey: isPreviewDeployKey(deployKey) ? deployKey : null,
+      projectKey: isProjectKey(deployKey) ? deployKey : null,
+    });
+    ctx._updateBigBrainAuth(bigBrainAuth);
+    return;
+  }
+  ctx._updateBigBrainAuth(
+    getBigBrainAuth(ctx, {
+      previewDeployKey: null,
+      projectKey: null,
+    }),
+  );
+  return;
+}
+
+export async function updateBigBrainAuthAfterLogin(
+  ctx: Context,
+  accessToken: string,
+) {
+  const existingAuth = ctx.bigBrainAuth();
+  if (existingAuth !== null && existingAuth.kind === "projectKey") {
+    logVerbose(
+      ctx,
+      `Ignoring update to big brain auth since project key takes precedence`,
+    );
+    return;
+  }
+  ctx._updateBigBrainAuth({
+    accessToken: accessToken,
+    kind: "accessToken",
+    header: `Bearer ${accessToken}`,
+  });
+}
+
+export async function clearBigBrainAuth(ctx: Context) {
+  ctx._updateBigBrainAuth(null);
+}
+
+function getBigBrainAuth(
+  ctx: Context,
+  opts: {
+    previewDeployKey: string | null;
+    projectKey: string | null;
+  },
+): BigBrainAuth | null {
+  if (process.env.CONVEX_OVERRIDE_ACCESS_TOKEN) {
+    return {
+      accessToken: process.env.CONVEX_OVERRIDE_ACCESS_TOKEN,
+      kind: "accessToken",
+      header: `Bearer ${process.env.CONVEX_OVERRIDE_ACCESS_TOKEN}`,
+    };
+  }
+  if (opts.projectKey !== null) {
+    // Project keys take precedence over global config.
+    return {
+      header: `Bearer ${opts.projectKey}`,
+      kind: "projectKey",
+      projectKey: opts.projectKey,
+    };
+  }
+  const globalConfig = readGlobalConfig(ctx);
+  if (globalConfig) {
+    return {
+      kind: "accessToken",
+      header: `Bearer ${globalConfig.accessToken}`,
+      accessToken: globalConfig.accessToken,
+    };
+  }
+  if (opts.previewDeployKey !== null) {
+    return {
+      header: `Bearer ${opts.previewDeployKey}`,
+      kind: "previewDeployKey",
+      previewDeployKey: opts.previewDeployKey,
+    };
+  }
+  return null;
+}
+
+// ----------------------------------------------------------------------------
+// Deployment Selection
+// ----------------------------------------------------------------------------
+/**
+ * Our CLI has logic to select which deployment to act on.
+ *
+ * We first check whether we're targeting a deployment within a project, or if we
+ * know exactly which deployment to act on (e.g. in the case of self-hosting).
+ *
+ * We also special case preview deploys since the presence of a preview deploy key
+ * triggers different behavior in `npx convex deploy`.
+ *
+ * Most commands will immediately compute the deployment selection, and then combine
+ * that with any relevant CLI flags to figure out which deployment to talk to.
+ *
+ * Different commands do different things (e.g. `dev` will allow you to create a new project,
+ * `deploy` has different behavior for preview deploys)
+ *
+ * This should be kept in sync with `initializeBigBrainAuth` since environment variables
+ * like `CONVEX_DEPLOY_KEY` are used for both deployment selection and auth.
+ */
+export type DeploymentSelection =
+  | {
+      kind: "existingDeployment";
+      deploymentToActOn: {
+        url: string;
+        adminKey: string;
+        deploymentFields: {
+          deploymentName: string;
+          deploymentType: DeploymentType;
+          projectSlug: string;
+          teamSlug: string;
+        } | null;
+        source: "selfHosted" | "deployKey" | "cliArgs";
+      };
+    }
+  | {
+      kind: "deploymentWithinProject";
+      targetProject: ProjectSelection;
+    }
+  | {
+      kind: "preview";
+      previewDeployKey: string;
+    }
+  | {
+      kind: "chooseProject";
+    }
+  | {
+      kind: "anonymous";
+      deploymentName: string | null;
+    };
+
+export type ProjectSelection =
+  | {
+      kind: "teamAndProjectSlugs";
+      teamSlug: string;
+      projectSlug: string;
+    }
+  | {
+      kind: "deploymentName";
+      deploymentName: string;
+      deploymentType: AccountRequiredDeploymentType | null;
+    }
+  | {
+      kind: "projectDeployKey";
+      projectDeployKey: string;
+    };
+
+export async function getDeploymentSelection(
+  ctx: Context,
+  cliArgs: {
+    url?: string;
+    adminKey?: string;
+    envFile?: string;
+  },
+): Promise<DeploymentSelection> {
+  const metadata = await _getDeploymentSelection(ctx, cliArgs);
+  logDeploymentSelection(ctx, metadata);
+  return metadata;
+}
+
+function logDeploymentSelection(ctx: Context, selection: DeploymentSelection) {
+  switch (selection.kind) {
+    case "existingDeployment": {
+      logVerbose(
+        ctx,
+        `Existing deployment: ${selection.deploymentToActOn.url} ${selection.deploymentToActOn.source}`,
+      );
+      break;
+    }
+    case "deploymentWithinProject": {
+      logVerbose(
+        ctx,
+        `Deployment within project: ${prettyProjectSelection(selection.targetProject)}`,
+      );
+      break;
+    }
+    case "preview": {
+      logVerbose(ctx, `Preview deploy key`);
+      break;
+    }
+    case "chooseProject": {
+      logVerbose(ctx, `Choose project`);
+      break;
+    }
+    case "anonymous": {
+      logVerbose(
+        ctx,
+        `Anonymous, has selected deployment?: ${selection.deploymentName !== null}`,
+      );
+      break;
+    }
+    default: {
+      const _exhaustivenessCheck: never = selection;
+      logVerbose(ctx, `Unknown deployment selection`);
+    }
+  }
+  return null;
+}
+
+function prettyProjectSelection(selection: ProjectSelection) {
+  switch (selection.kind) {
+    case "teamAndProjectSlugs": {
+      return `Team and project slugs: ${selection.teamSlug} ${selection.projectSlug}`;
+    }
+    case "deploymentName": {
+      return `Deployment name: ${selection.deploymentName}`;
+    }
+    case "projectDeployKey": {
+      return `Project deploy key`;
+    }
+    default: {
+      const _exhaustivenessCheck: never = selection;
+      return `Unknown`;
+    }
+  }
+}
+
+async function _getDeploymentSelection(
+  ctx: Context,
+  cliArgs: {
+    url?: string;
+    adminKey?: string;
+    envFile?: string;
+  },
+): Promise<DeploymentSelection> {
+  /*
+   - url + adminKey specified via CLI
+   - Do not check any env vars (including ones relevant for auth)
+  */
+  if (cliArgs.url && cliArgs.adminKey) {
+    return {
+      kind: "existingDeployment",
+      deploymentToActOn: {
+        url: cliArgs.url,
+        adminKey: cliArgs.adminKey,
+        deploymentFields: null,
+        source: "cliArgs",
+      },
+    };
+  }
+
+  if (cliArgs.envFile) {
+    // If an `--env-file` is specified, it must contain enough information for both auth and deployment selection.
+    logVerbose(ctx, `Checking env file: ${cliArgs.envFile}`);
+    const existingFile = ctx.fs.exists(cliArgs.envFile)
+      ? ctx.fs.readUtf8File(cliArgs.envFile)
+      : null;
+    if (existingFile === null) {
+      return ctx.crash({
+        exitCode: 1,
+        errorType: "invalid filesystem or env vars",
+        printedMessage: "env file does not exist",
+      });
+    }
+    const config = dotenv.parse(existingFile);
+    const result = await getDeploymentSelectionFromEnv(ctx, (name) =>
+      config[name] === undefined || config[name] === "" ? null : config[name],
+    );
+    if (result.kind === "unknown") {
+      return ctx.crash({
+        exitCode: 1,
+        errorType: "invalid filesystem or env vars",
+        printedMessage:
+          `env file \`${cliArgs.envFile}\` did not contain environment variables for a Convex deployment. ` +
+          `Expected \`${CONVEX_DEPLOY_KEY_ENV_VAR_NAME}\`, \`${CONVEX_DEPLOYMENT_ENV_VAR_NAME}\`, or both \`${CONVEX_SELF_HOSTED_URL_VAR_NAME}\` and \`${CONVEX_SELF_HOSTED_ADMIN_KEY_VAR_NAME}\` to be set.`,
+      });
+    }
+    return result.metadata;
+  }
+  dotenv.config({ path: ENV_VAR_FILE_PATH });
+  dotenv.config();
+  const result = await getDeploymentSelectionFromEnv(ctx, (name) => {
+    const value = process.env[name];
+    if (value === undefined || value === "") {
+      return null;
+    }
+    return value;
+  });
+  if (result.kind !== "unknown") {
+    return result.metadata;
+  }
+  // none of these?
+
+  // Check the `convex.json` for a configured team and project
+  const { projectConfig } = await readProjectConfig(ctx);
+  if (projectConfig.team !== undefined && projectConfig.project !== undefined) {
+    return {
+      kind: "deploymentWithinProject",
+      targetProject: {
+        kind: "teamAndProjectSlugs",
+        teamSlug: projectConfig.team,
+        projectSlug: projectConfig.project,
+      },
+    };
+  }
+
+  // Check if they're logged in
+  const isLoggedIn = ctx.bigBrainAuth() !== null;
+  if (!isLoggedIn && shouldAllowAnonymousDevelopment()) {
+    return {
+      kind: "anonymous",
+      deploymentName: null,
+    };
+  }
+
+  // Choose a project interactively later
+  return {
+    kind: "chooseProject",
+  };
+}
+
+async function getDeploymentSelectionFromEnv(
+  ctx: Context,
+  getEnv: (name: string) => string | null,
+): Promise<
+  { kind: "success"; metadata: DeploymentSelection } | { kind: "unknown" }
+> {
+  const deployKey = getEnv(CONVEX_DEPLOY_KEY_ENV_VAR_NAME);
+  if (deployKey !== null) {
+    const deployKeyType = isPreviewDeployKey(deployKey)
+      ? "preview"
+      : isProjectKey(deployKey)
+        ? "project"
+        : "deployment";
+    switch (deployKeyType) {
+      case "preview": {
+        // `CONVEX_DEPLOY_KEY` is set to a preview deploy key so this takes precedence over anything else.
+        // At the moment, we don't verify that there aren't other env vars that would also be used for deployment selection (e.g. `CONVEX_DEPLOYMENT`)
+        return {
+          kind: "success",
+          metadata: {
+            kind: "preview",
+            previewDeployKey: deployKey,
+          },
+        };
+      }
+      case "project": {
+        // `CONVEX_DEPLOY_KEY` is set to a project deploy key.
+        // Commands can select any deployment within the project. At the moment we don't check for other env vars (e.g. `CONVEX_DEPLOYMENT`)
+        return {
+          kind: "success",
+          metadata: {
+            kind: "deploymentWithinProject",
+            targetProject: {
+              kind: "projectDeployKey",
+              projectDeployKey: deployKey,
+            },
+          },
+        };
+      }
+      case "deployment": {
+        // `CONVEX_DEPLOY_KEY` is set to a deployment's deploy key.
+        // Deploy to this deployment -- selectors like `--prod` / `--preview-name` will be ignored.
+        // At the moment, we don't verify that there aren't other env vars that would also be used for deployment selection (e.g. `CONVEX_DEPLOYMENT`)
+        const deploymentName = await deploymentNameFromAdminKeyOrCrash(
+          ctx,
+          deployKey,
+        );
+        const deploymentType = deploymentTypeFromAdminKey(deployKey);
+        // We cannot derive the deployment URL from the deploy key, because it
+        // might be a custom domain. Ask big brain for the URL.
+        const url = await bigBrainAPI({
+          ctx,
+          method: "POST",
+          url: "deployment/url_for_key",
+          data: {
+            deployKey: deployKey,
+          },
+        });
+        const slugs = await fetchTeamAndProjectForKey(ctx, deployKey);
+        return {
+          kind: "success",
+          metadata: {
+            kind: "existingDeployment",
+            deploymentToActOn: {
+              url: url,
+              adminKey: deployKey,
+              deploymentFields: {
+                deploymentName: deploymentName,
+                deploymentType: deploymentType,
+                teamSlug: slugs.team,
+                projectSlug: slugs.project,
+              },
+              source: "deployKey",
+            },
+          },
+        };
+      }
+      default: {
+        const _exhaustivenessCheck: never = deployKeyType;
+        return ctx.crash({
+          exitCode: 1,
+          errorType: "fatal",
+          printedMessage: `Unexpected deploy key type: ${deployKeyType as any}`,
+        });
+      }
+    }
+  }
+  // Throw a nice error if we're in something like a CI environment where we need a `CONVEX_DEPLOY_KEY`
+  await checkIfBuildEnvironmentExpectsConvexDeployKey(ctx);
+
+  const convexDeployment = getEnv(CONVEX_DEPLOYMENT_ENV_VAR_NAME);
+  const selfHostedUrl = getEnv(CONVEX_SELF_HOSTED_URL_VAR_NAME);
+  const selfHostedAdminKey = getEnv(CONVEX_SELF_HOSTED_ADMIN_KEY_VAR_NAME);
+
+  if (selfHostedUrl !== null && selfHostedAdminKey !== null) {
+    if (convexDeployment !== null) {
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "invalid filesystem or env vars",
+        printedMessage: `${CONVEX_DEPLOYMENT_ENV_VAR_NAME} must not be set when ${CONVEX_SELF_HOSTED_URL_VAR_NAME} and ${CONVEX_SELF_HOSTED_ADMIN_KEY_VAR_NAME} are set`,
+      });
+    }
+    return {
+      kind: "success",
+      metadata: {
+        kind: "existingDeployment",
+        deploymentToActOn: {
+          url: selfHostedUrl,
+          adminKey: selfHostedAdminKey,
+          deploymentFields: null,
+          source: "selfHosted",
+        },
+      },
+    };
+  }
+
+  if (convexDeployment !== null) {
+    if (selfHostedUrl !== null || selfHostedAdminKey !== null) {
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "invalid filesystem or env vars",
+        printedMessage: `${CONVEX_SELF_HOSTED_URL_VAR_NAME} and ${CONVEX_SELF_HOSTED_ADMIN_KEY_VAR_NAME} must not be set when ${CONVEX_DEPLOYMENT_ENV_VAR_NAME} is set`,
+      });
+    }
+    const targetDeploymentType =
+      getDeploymentTypeFromConfiguredDeployment(convexDeployment);
+    const targetDeploymentName = stripDeploymentTypePrefix(convexDeployment);
+    const isAnonymous = isAnonymousDeployment(targetDeploymentName);
+    if (isAnonymous) {
+      if (!shouldAllowAnonymousDevelopment()) {
+        return {
+          kind: "unknown",
+        };
+      }
+      return {
+        kind: "success",
+        metadata: {
+          kind: "anonymous",
+          deploymentName: targetDeploymentName,
+        },
+      };
+    }
+    // Commands can select a deployment within the project that this deployment belongs to.
+    return {
+      kind: "success",
+      metadata: {
+        kind: "deploymentWithinProject",
+        targetProject: {
+          kind: "deploymentName",
+          deploymentName: targetDeploymentName,
+          deploymentType: targetDeploymentType,
+        },
+      },
+    };
+  }
+
+  return { kind: "unknown" };
+}
+
+async function checkIfBuildEnvironmentExpectsConvexDeployKey(ctx: Context) {
+  const buildEnvironmentExpectsConvexDeployKey = buildEnvironment();
+  if (buildEnvironmentExpectsConvexDeployKey) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage:
+        `${buildEnvironmentExpectsConvexDeployKey} build environment detected but ${CONVEX_DEPLOY_KEY_ENV_VAR_NAME} is not set. ` +
+        `Set this environment variable to deploy from this environment. See https://docs.convex.dev/production/hosting`,
+    });
+  }
+}
+
+/**
+ * Used for things like `npx convex docs` where we want to best effort extract a deployment name
+ * but don't do the full deployment selection logic.
+ */
+export const deploymentNameFromSelection = (
+  selection: DeploymentSelection,
+): string | null => {
+  return deploymentNameAndTypeFromSelection(selection)?.name ?? null;
+};
+
+export const deploymentNameAndTypeFromSelection = (
+  selection: DeploymentSelection,
+): { name: string | null; type: string | null } | null => {
+  switch (selection.kind) {
+    case "existingDeployment": {
+      return {
+        name:
+          selection.deploymentToActOn.deploymentFields?.deploymentName ?? null,
+        type:
+          selection.deploymentToActOn.deploymentFields?.deploymentType ?? null,
+      };
+    }
+    case "deploymentWithinProject": {
+      return selection.targetProject.kind === "deploymentName"
+        ? {
+            name: selection.targetProject.deploymentName,
+            type: selection.targetProject.deploymentType,
+          }
+        : null;
+    }
+    case "preview": {
+      return null;
+    }
+    case "chooseProject": {
+      return null;
+    }
+    case "anonymous": {
+      return null;
+    }
+  }
+  const _exhaustivenessCheck: never = selection;
+  return null;
+};
+
+export const shouldAllowAnonymousDevelopment = (): boolean => {
+  // Kill switch / temporary opt out
+  if (process.env.CONVEX_ALLOW_ANONYMOUS === "false") {
+    return false;
+  }
+  return true;
+};
diff --git a/synced/convex/libs/cli/lib/dev.ts b/synced/convex/libs/cli/lib/dev.ts
new file mode 100644
index 0000000..5bd6563
--- /dev/null
+++ b/synced/convex/libs/cli/lib/dev.ts
@@ -0,0 +1,479 @@
+import chalk from "chalk";
+import {
+  logError,
+  logFinishedStep,
+  logMessage,
+  logWarning,
+  OneoffCtx,
+  showSpinner,
+  showSpinnerIfSlow,
+  stopSpinner,
+} from "../../bundler/context.js";
+import { runPush } from "./components.js";
+import { performance } from "perf_hooks";
+import path from "path";
+import { LogManager, LogMode, watchLogs } from "./logs.js";
+import { PushOptions } from "./push.js";
+import {
+  formatDuration,
+  getCurrentTimeString,
+  spawnAsync,
+  waitForever,
+  waitUntilCalled,
+} from "./utils/utils.js";
+import { Crash, WatchContext, Watcher } from "./watch.js";
+import { runFunctionAndLog, subscribe } from "./run.js";
+import { Value } from "../../values/index.js";
+
+export async function devAgainstDeployment(
+  ctx: OneoffCtx,
+  credentials: {
+    url: string;
+    adminKey: string;
+    deploymentName: string | null;
+  },
+  devOptions: {
+    verbose: boolean;
+    typecheck: "enable" | "try" | "disable";
+    typecheckComponents: boolean;
+    codegen: boolean;
+    once: boolean;
+    untilSuccess: boolean;
+    run?:
+      | { kind: "function"; name: string; component?: string }
+      | { kind: "shell"; command: string };
+    tailLogs: LogMode;
+    traceEvents: boolean;
+    debugBundlePath?: string;
+    liveComponentSources: boolean;
+  },
+) {
+  const logManager = new LogManager(devOptions.tailLogs);
+
+  const promises = [];
+  if (devOptions.tailLogs !== "disable") {
+    promises.push(
+      watchLogs(ctx, credentials.url, credentials.adminKey, "stderr", {
+        logManager,
+        success: false,
+      }),
+    );
+  }
+
+  promises.push(
+    watchAndPush(
+      ctx,
+      {
+        ...credentials,
+        verbose: devOptions.verbose,
+        dryRun: false,
+        typecheck: devOptions.typecheck,
+        typecheckComponents: devOptions.typecheckComponents,
+        debug: false,
+        debugBundlePath: devOptions.debugBundlePath,
+        codegen: devOptions.codegen,
+        liveComponentSources: devOptions.liveComponentSources,
+        logManager, // Pass logManager to control logs during deploy
+      },
+      devOptions,
+    ),
+  );
+  await Promise.race(promises);
+  await ctx.flushAndExit(0);
+}
+
+export async function watchAndPush(
+  outerCtx: OneoffCtx,
+  options: PushOptions,
+  cmdOptions: {
+    run?:
+      | { kind: "function"; name: string; component?: string }
+      | { kind: "shell"; command: string };
+    once: boolean;
+    untilSuccess: boolean;
+    traceEvents: boolean;
+  },
+) {
+  const watch: { watcher: Watcher | undefined } = { watcher: undefined };
+  let numFailures = 0;
+  let ran = false;
+  let pushed = false;
+  let tableNameTriggeringRetry;
+  let shouldRetryOnDeploymentEnvVarChange;
+
+  while (true) {
+    const start = performance.now();
+    tableNameTriggeringRetry = null;
+    shouldRetryOnDeploymentEnvVarChange = false;
+
+    const ctx = new WatchContext(
+      cmdOptions.traceEvents,
+      outerCtx.bigBrainAuth(),
+    );
+    options.logManager?.beginDeploy();
+    showSpinner(ctx, "Preparing Convex functions...");
+    try {
+      await runPush(ctx, options);
+      const end = performance.now();
+      // NOTE: If `runPush` throws, `endDeploy` will not be called.
+      // This allows you to see the output from the failed deploy without
+      // logs getting in the way.
+      options.logManager?.endDeploy();
+      numFailures = 0;
+      logFinishedStep(
+        ctx,
+        `${getCurrentTimeString()} Convex functions ready! (${formatDuration(
+          end - start,
+        )})`,
+      );
+      if (cmdOptions.run !== undefined && !ran) {
+        switch (cmdOptions.run.kind) {
+          case "function":
+            await runFunctionInDev(
+              ctx,
+              options,
+              cmdOptions.run.name,
+              cmdOptions.run.component,
+            );
+            break;
+          case "shell":
+            try {
+              await spawnAsync(ctx, cmdOptions.run.command, [], {
+                stdio: "inherit",
+                shell: true,
+              });
+            } catch (e) {
+              // `spawnAsync` throws an error like `{ status: 1, error: Error }`
+              // when the command fails.
+              const errorMessage =
+                e === null || e === undefined
+                  ? null
+                  : (e as any).error instanceof Error
+                    ? ((e as any).error.message ?? null)
+                    : null;
+              const printedMessage = `Failed to run command \`${cmdOptions.run.command}\`: ${errorMessage ?? "Unknown error"}`;
+              // Don't return this since it'll bypass the `catch` below.
+              await ctx.crash({
+                exitCode: 1,
+                errorType: "fatal",
+                printedMessage,
+              });
+            }
+            break;
+          default: {
+            const _exhaustiveCheck: never = cmdOptions.run;
+            // Don't return this since it'll bypass the `catch` below.
+            await ctx.crash({
+              exitCode: 1,
+              errorType: "fatal",
+              printedMessage: `Unexpected arguments for --run`,
+              errForSentry: `Unexpected arguments for --run: ${JSON.stringify(
+                cmdOptions.run,
+              )}`,
+            });
+          }
+        }
+        ran = true;
+      }
+      pushed = true;
+    } catch (e: any) {
+      // Crash the app on unexpected errors.
+      if (!(e instanceof Crash) || !e.errorType) {
+        // eslint-disable-next-line no-restricted-syntax
+        throw e;
+      }
+      if (e.errorType === "fatal") {
+        break;
+      }
+      // Retry after an exponential backoff if we hit a transient error.
+      if (e.errorType === "transient") {
+        const delay = nextBackoff(numFailures);
+        numFailures += 1;
+        logWarning(
+          ctx,
+          chalk.yellow(
+            `Failed due to network error, retrying in ${formatDuration(
+              delay,
+            )}...`,
+          ),
+        );
+        await new Promise((resolve) => setTimeout(resolve, delay));
+        continue;
+      }
+
+      // Fall through if we had a filesystem-based error.
+      // TODO(sarah): Replace this with `logError`.
+      // eslint-disable-next-line no-console
+      console.assert(
+        e.errorType === "invalid filesystem data" ||
+          e.errorType === "invalid filesystem or env vars" ||
+          e.errorType["invalid filesystem or db data"] !== undefined,
+      );
+      if (e.errorType === "invalid filesystem or env vars") {
+        shouldRetryOnDeploymentEnvVarChange = true;
+      } else if (
+        e.errorType !== "invalid filesystem data" &&
+        e.errorType["invalid filesystem or db data"] !== undefined
+      ) {
+        tableNameTriggeringRetry = e.errorType["invalid filesystem or db data"];
+      }
+      if (cmdOptions.once) {
+        await outerCtx.flushAndExit(1, e.errorType);
+      }
+      // Make sure that we don't spin if this push failed
+      // in any edge cases that didn't call `logFailure`
+      // before throwing.
+      stopSpinner(ctx);
+    }
+    if (cmdOptions.once) {
+      return;
+    }
+    if (pushed && cmdOptions.untilSuccess) {
+      return;
+    }
+    const fileSystemWatch = getFileSystemWatch(ctx, watch, cmdOptions);
+    const tableWatch = getTableWatch(
+      ctx,
+      options,
+      tableNameTriggeringRetry?.tableName ?? null,
+      tableNameTriggeringRetry?.componentPath,
+    );
+    const envVarWatch = getDeplymentEnvVarWatch(
+      ctx,
+      options,
+      shouldRetryOnDeploymentEnvVarChange,
+    );
+    await Promise.race([
+      fileSystemWatch.watch(),
+      tableWatch.watch(),
+      envVarWatch.watch(),
+    ]);
+    fileSystemWatch.stop();
+    void tableWatch.stop();
+    void envVarWatch.stop();
+  }
+}
+
+async function runFunctionInDev(
+  ctx: WatchContext,
+  credentials: {
+    url: string;
+    adminKey: string;
+  },
+  functionName: string,
+  componentPath: string | undefined,
+) {
+  await runFunctionAndLog(ctx, {
+    deploymentUrl: credentials.url,
+    adminKey: credentials.adminKey,
+    functionName,
+    argsString: "{}",
+    componentPath,
+    callbacks: {
+      onSuccess: () => {
+        logFinishedStep(ctx, `Finished running function "${functionName}"`);
+      },
+    },
+  });
+}
+
+function getTableWatch(
+  ctx: WatchContext,
+  credentials: {
+    url: string;
+    adminKey: string;
+  },
+  tableName: string | null,
+  componentPath: string | undefined,
+) {
+  return getFunctionWatch(ctx, {
+    deploymentUrl: credentials.url,
+    adminKey: credentials.adminKey,
+    parsedFunctionName: "_system/cli/queryTable",
+    getArgs: () => (tableName !== null ? { tableName } : null),
+    componentPath,
+  });
+}
+
+function getDeplymentEnvVarWatch(
+  ctx: WatchContext,
+  credentials: {
+    url: string;
+    adminKey: string;
+  },
+  shouldRetryOnDeploymentEnvVarChange: boolean,
+) {
+  return getFunctionWatch(ctx, {
+    deploymentUrl: credentials.url,
+    adminKey: credentials.adminKey,
+    parsedFunctionName: "_system/cli/queryEnvironmentVariables",
+    getArgs: () => (shouldRetryOnDeploymentEnvVarChange ? {} : null),
+    componentPath: undefined,
+  });
+}
+
+function getFunctionWatch(
+  ctx: WatchContext,
+  args: {
+    deploymentUrl: string;
+    adminKey: string;
+    parsedFunctionName: string;
+    getArgs: () => Record<string, Value> | null;
+    componentPath: string | undefined;
+  },
+) {
+  const [stopPromise, stop] = waitUntilCalled();
+  return {
+    watch: async () => {
+      const functionArgs = args.getArgs();
+      if (functionArgs === null) {
+        return waitForever();
+      }
+      let changes = 0;
+      return subscribe(ctx, {
+        deploymentUrl: args.deploymentUrl,
+        adminKey: args.adminKey,
+        parsedFunctionName: args.parsedFunctionName,
+        parsedFunctionArgs: functionArgs,
+        componentPath: args.componentPath,
+        until: stopPromise,
+        callbacks: {
+          onChange: () => {
+            changes++;
+            // First bump is just the initial results reporting
+            if (changes > 1) {
+              stop();
+            }
+          },
+        },
+      });
+    },
+    stop: () => {
+      stop();
+    },
+  };
+}
+
+function getFileSystemWatch(
+  ctx: WatchContext,
+  watch: { watcher: Watcher | undefined },
+  cmdOptions: { traceEvents: boolean },
+) {
+  let hasStopped = false;
+  return {
+    watch: async () => {
+      const observations = ctx.fs.finalize();
+      if (observations === "invalidated") {
+        logMessage(ctx, "Filesystem changed during push, retrying...");
+        return;
+      }
+      // Initialize the watcher if we haven't done it already. Chokidar expects to have a
+      // nonempty watch set at initialization, so we can't do it before running our first
+      // push.
+      if (!watch.watcher) {
+        watch.watcher = new Watcher(observations);
+        await showSpinnerIfSlow(
+          ctx,
+          "Preparing to watch files...",
+          500,
+          async () => {
+            await watch.watcher!.ready();
+          },
+        );
+        stopSpinner(ctx);
+      }
+      // Watch new directories if needed.
+      watch.watcher.update(observations);
+
+      // Process events until we find one that overlaps with our previous observations.
+      let anyChanges = false;
+      do {
+        await watch.watcher.waitForEvent();
+        if (hasStopped) {
+          return;
+        }
+        for (const event of watch.watcher.drainEvents()) {
+          if (cmdOptions.traceEvents) {
+            logMessage(
+              ctx,
+              "Processing",
+              event.name,
+              path.relative("", event.absPath),
+            );
+          }
+          const result = observations.overlaps(event);
+          if (result.overlaps) {
+            const relPath = path.relative("", event.absPath);
+            if (cmdOptions.traceEvents) {
+              logMessage(ctx, `${relPath} ${result.reason}, rebuilding...`);
+            }
+            anyChanges = true;
+            break;
+          }
+        }
+      } while (!anyChanges);
+
+      // Wait for the filesystem to quiesce before starting a new push. It's okay to
+      // drop filesystem events at this stage since we're already committed to doing
+      // a push and resubscribing based on that push's observations.
+      let deadline = performance.now() + quiescenceDelay;
+      while (true) {
+        const now = performance.now();
+        if (now >= deadline) {
+          break;
+        }
+        const remaining = deadline - now;
+        if (cmdOptions.traceEvents) {
+          logMessage(
+            ctx,
+            `Waiting for ${formatDuration(remaining)} to quiesce...`,
+          );
+        }
+        const remainingWait = new Promise<"timeout">((resolve) =>
+          setTimeout(() => resolve("timeout"), deadline - now),
+        );
+        const result = await Promise.race([
+          remainingWait,
+          watch.watcher.waitForEvent().then<"newEvents">(() => "newEvents"),
+        ]);
+        if (result === "newEvents") {
+          for (const event of watch.watcher.drainEvents()) {
+            const result = observations.overlaps(event);
+            // Delay another `quiescenceDelay` since we had an overlapping event.
+            if (result.overlaps) {
+              if (cmdOptions.traceEvents) {
+                logMessage(
+                  ctx,
+                  `Received an overlapping event at ${event.absPath}, delaying push.`,
+                );
+              }
+              deadline = performance.now() + quiescenceDelay;
+            }
+          }
+        } else {
+          // Let the check above `break` from the loop if we're past our deadlne.
+          if (result !== "timeout") {
+            logError(
+              ctx,
+              "Assertion failed: Unexpected result from watcher: " + result,
+            );
+          }
+        }
+      }
+    },
+    stop: () => {
+      hasStopped = true;
+    },
+  };
+}
+
+const initialBackoff = 500;
+const maxBackoff = 16000;
+const quiescenceDelay = 500;
+
+export function nextBackoff(prevFailures: number): number {
+  const baseBackoff = initialBackoff * Math.pow(2, prevFailures);
+  const actualBackoff = Math.min(baseBackoff, maxBackoff);
+  const jitter = actualBackoff * (Math.random() - 0.5);
+  return actualBackoff + jitter;
+}
diff --git a/synced/convex/libs/cli/lib/env.ts b/synced/convex/libs/cli/lib/env.ts
new file mode 100644
index 0000000..d446f9b
--- /dev/null
+++ b/synced/convex/libs/cli/lib/env.ts
@@ -0,0 +1,141 @@
+import chalk from "chalk";
+import {
+  Context,
+  logFailure,
+  logFinishedStep,
+  logMessage,
+  logOutput,
+} from "../../bundler/context.js";
+import { runSystemQuery } from "./run.js";
+import { deploymentFetch, logAndHandleFetchError } from "./utils/utils.js";
+
+export async function envSetInDeployment(
+  ctx: Context,
+  deployment: {
+    deploymentUrl: string;
+    adminKey: string;
+    deploymentNotice: string;
+  },
+  originalName: string,
+  originalValue: string | undefined,
+) {
+  const [name, value] = await allowEqualsSyntax(
+    ctx,
+    originalName,
+    originalValue,
+  );
+  await callUpdateEnvironmentVariables(ctx, deployment, [{ name, value }]);
+  const formatted = /\s/.test(value) ? `"${value}"` : value;
+  logFinishedStep(
+    ctx,
+    `Successfully set ${chalk.bold(name)} to ${chalk.bold(formatted)}${deployment.deploymentNotice}`,
+  );
+}
+
+async function allowEqualsSyntax(
+  ctx: Context,
+  name: string,
+  value: string | undefined,
+) {
+  if (value === undefined) {
+    if (/^[a-zA-Z][a-zA-Z0-9_]+=/.test(name)) {
+      return name.split("=", 2);
+    } else {
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage: "error: missing required argument 'value'",
+      });
+    }
+  }
+  return [name, value];
+}
+
+export async function envGetInDeployment(
+  ctx: Context,
+  deployment: {
+    deploymentUrl: string;
+    adminKey: string;
+  },
+  name: string,
+) {
+  const envVar = (await runSystemQuery(ctx, {
+    ...deployment,
+    functionName: "_system/cli/queryEnvironmentVariables:get",
+    componentPath: undefined,
+    args: { name },
+  })) as EnvVar | null;
+  if (envVar === null) {
+    logFailure(ctx, `Environment variable "${name}" not found.`);
+    return;
+  }
+  logOutput(ctx, `${envVar.value}`);
+}
+
+export async function envRemoveInDeployment(
+  ctx: Context,
+  deployment: {
+    deploymentUrl: string;
+    adminKey: string;
+    deploymentNotice: string;
+  },
+  name: string,
+) {
+  await callUpdateEnvironmentVariables(ctx, deployment, [{ name }]);
+  logFinishedStep(
+    ctx,
+    `Successfully unset ${chalk.bold(name)}${deployment.deploymentNotice}`,
+  );
+}
+
+export async function envListInDeployment(
+  ctx: Context,
+  deployment: {
+    deploymentUrl: string;
+    adminKey: string;
+  },
+) {
+  const envs = (await runSystemQuery(ctx, {
+    ...deployment,
+    functionName: "_system/cli/queryEnvironmentVariables",
+    componentPath: undefined,
+    args: {},
+  })) as EnvVar[];
+  if (envs.length === 0) {
+    logMessage(ctx, "No environment variables set.");
+    return;
+  }
+  for (const { name, value } of envs) {
+    logOutput(ctx, `${name}=${value}`);
+  }
+}
+
+export type EnvVarChange = {
+  name: string;
+  value?: string;
+};
+
+export type EnvVar = {
+  name: string;
+  value: string;
+};
+
+async function callUpdateEnvironmentVariables(
+  ctx: Context,
+  deployment: {
+    deploymentUrl: string;
+    adminKey: string;
+    deploymentNotice: string;
+  },
+  changes: EnvVarChange[],
+) {
+  const fetch = deploymentFetch(ctx, deployment);
+  try {
+    await fetch("/api/update_environment_variables", {
+      body: JSON.stringify({ changes }),
+      method: "POST",
+    });
+  } catch (e) {
+    return await logAndHandleFetchError(ctx, e);
+  }
+}
diff --git a/synced/convex/libs/cli/lib/envvars.ts b/synced/convex/libs/cli/lib/envvars.ts
new file mode 100644
index 0000000..ad5a709
--- /dev/null
+++ b/synced/convex/libs/cli/lib/envvars.ts
@@ -0,0 +1,299 @@
+/**
+ * Help the developer store the CONVEX_URL environment variable.
+ */
+import chalk from "chalk";
+import * as dotenv from "dotenv";
+
+import { Context, logWarning } from "../../bundler/context.js";
+import { loadPackageJson } from "./utils/utils.js";
+
+const _FRAMEWORKS = [
+  "create-react-app",
+  "Next.js",
+  "Vite",
+  "Remix",
+  "SvelteKit",
+  "Expo",
+  "TanStackStart",
+] as const;
+type Framework = (typeof _FRAMEWORKS)[number];
+
+type ConvexUrlWriteConfig = {
+  envFile: string;
+  envVar: string;
+  existingFileContent: string | null;
+} | null;
+
+export async function writeConvexUrlToEnvFile(
+  ctx: Context,
+  value: string,
+): Promise<ConvexUrlWriteConfig> {
+  const writeConfig = await envVarWriteConfig(ctx, value);
+
+  if (writeConfig === null) {
+    return null;
+  }
+
+  const { envFile, envVar, existingFileContent } = writeConfig;
+  const modified = changedEnvVarFile({
+    existingFileContent,
+    envVarName: envVar,
+    envVarValue: value,
+    commentAfterValue: null,
+    commentOnPreviousLine: null,
+  })!;
+  ctx.fs.writeUtf8File(envFile, modified);
+  return writeConfig;
+}
+
+export function changedEnvVarFile({
+  existingFileContent,
+  envVarName,
+  envVarValue,
+  commentAfterValue,
+  commentOnPreviousLine,
+}: {
+  existingFileContent: string | null;
+  envVarName: string;
+  envVarValue: string;
+  commentAfterValue: string | null;
+  commentOnPreviousLine: string | null;
+}): string | null {
+  const varAssignment = `${envVarName}=${envVarValue}${
+    commentAfterValue === null ? "" : ` # ${commentAfterValue}`
+  }`;
+  const commentOnPreviousLineWithLineBreak =
+    commentOnPreviousLine === null ? "" : `${commentOnPreviousLine}\n`;
+  if (existingFileContent === null) {
+    return `${commentOnPreviousLineWithLineBreak}${varAssignment}\n`;
+  }
+  const config = dotenv.parse(existingFileContent);
+  const existing = config[envVarName];
+  if (existing === envVarValue) {
+    return null;
+  }
+  if (existing !== undefined) {
+    return existingFileContent.replace(
+      getEnvVarRegex(envVarName),
+      `${varAssignment}`,
+    );
+  } else {
+    const doubleLineBreak = existingFileContent.endsWith("\n") ? "\n" : "\n\n";
+    return (
+      existingFileContent +
+      doubleLineBreak +
+      commentOnPreviousLineWithLineBreak +
+      varAssignment +
+      "\n"
+    );
+  }
+}
+
+export function getEnvVarRegex(envVarName: string) {
+  return new RegExp(`^${envVarName}.*$`, "m");
+}
+
+export async function suggestedEnvVarName(ctx: Context): Promise<{
+  detectedFramework?: Framework;
+  envVar: string;
+}> {
+  // no package.json, that's fine, just guess
+  if (!ctx.fs.exists("package.json")) {
+    return {
+      envVar: "CONVEX_URL",
+    };
+  }
+
+  const packages = await loadPackageJson(ctx);
+
+  // Is it create-react-app?
+  const isCreateReactApp = "react-scripts" in packages;
+  if (isCreateReactApp) {
+    return {
+      detectedFramework: "create-react-app",
+      envVar: "REACT_APP_CONVEX_URL",
+    };
+  }
+
+  const isNextJs = "next" in packages;
+  if (isNextJs) {
+    return {
+      detectedFramework: "Next.js",
+      envVar: "NEXT_PUBLIC_CONVEX_URL",
+    };
+  }
+
+  const isExpo = "expo" in packages;
+  if (isExpo) {
+    return {
+      detectedFramework: "Expo",
+      envVar: "EXPO_PUBLIC_CONVEX_URL",
+    };
+  }
+
+  const isRemix = "@remix-run/dev" in packages;
+  if (isRemix) {
+    return {
+      detectedFramework: "Remix",
+      envVar: "CONVEX_URL",
+    };
+  }
+
+  const isSvelteKit = "@sveltejs/kit" in packages;
+  if (isSvelteKit) {
+    return {
+      detectedFramework: "SvelteKit",
+      envVar: "PUBLIC_CONVEX_URL",
+    };
+  }
+
+  // Vite is a dependency of a lot of things; vite appearing in dependencies is not a strong indicator.
+  const isVite = "vite" in packages;
+
+  if (isVite) {
+    return {
+      detectedFramework: "Vite",
+      envVar: "VITE_CONVEX_URL",
+    };
+  }
+
+  // TanStackStart currently supports VITE_FOO for browser-side envvars.
+  const isTanStackStart =
+    "@tanstack/start" in packages || "@tanstack/react-start" in packages;
+
+  if (isTanStackStart) {
+    return {
+      detectedFramework: "TanStackStart",
+      envVar: "VITE_CONVEX_URL",
+    };
+  }
+
+  return {
+    envVar: "CONVEX_URL",
+  };
+}
+
+async function envVarWriteConfig(
+  ctx: Context,
+  value: string | null,
+): Promise<ConvexUrlWriteConfig> {
+  const { detectedFramework, envVar } = await suggestedEnvVarName(ctx);
+
+  const { envFile, existing } = suggestedDevEnvFile(ctx, detectedFramework);
+
+  if (!existing) {
+    return { envFile, envVar, existingFileContent: null };
+  }
+
+  const existingFileContent = ctx.fs.readUtf8File(envFile);
+  const config = dotenv.parse(existingFileContent);
+
+  const matching = Object.keys(config).filter((key) => EXPECTED_NAMES.has(key));
+  if (matching.length > 1) {
+    logWarning(
+      ctx,
+      chalk.yellow(
+        `Found multiple CONVEX_URL environment variables in ${envFile} so cannot update automatically.`,
+      ),
+    );
+    return null;
+  }
+  if (matching.length === 1) {
+    const [existingEnvVar, oldValue] = [matching[0], config[matching[0]]];
+    if (oldValue === value) {
+      return null;
+    }
+    if (
+      oldValue !== "" &&
+      Object.values(config).filter((v) => v === oldValue).length !== 1
+    ) {
+      logWarning(
+        ctx,
+        chalk.yellow(`Can't safely modify ${envFile}, please edit manually.`),
+      );
+      return null;
+    }
+    return { envFile, envVar: existingEnvVar, existingFileContent };
+  }
+  return { envFile, envVar, existingFileContent };
+}
+
+function suggestedDevEnvFile(
+  ctx: Context,
+  framework?: Framework,
+): {
+  existing: boolean;
+  envFile: string;
+} {
+  // If a .env.local file exists, that's unequivocally the right file
+  if (ctx.fs.exists(".env.local")) {
+    return {
+      existing: true,
+      envFile: ".env.local",
+    };
+  }
+
+  // Remix is on team "don't commit the .env file," so .env is for dev.
+  if (framework === "Remix") {
+    return {
+      existing: ctx.fs.exists(".env"),
+      envFile: ".env",
+    };
+  }
+
+  // The most dev-looking env file that exists, or .env.local
+  return {
+    existing: ctx.fs.exists(".env.local"),
+    envFile: ".env.local",
+  };
+}
+
+const EXPECTED_NAMES = new Set([
+  "CONVEX_URL",
+  "PUBLIC_CONVEX_URL",
+  "NEXT_PUBLIC_CONVEX_URL",
+  "VITE_CONVEX_URL",
+  "REACT_APP_CONVEX_URL",
+  "EXPO_PUBLIC_CONVEX_URL",
+]);
+
+export function buildEnvironment(): string | boolean {
+  return process.env.VERCEL
+    ? "Vercel"
+    : process.env.NETLIFY
+      ? "Netlify"
+      : false;
+}
+
+export function gitBranchFromEnvironment(): string | null {
+  if (process.env.VERCEL) {
+    // https://vercel.com/docs/projects/environment-variables/system-environment-variables
+    return process.env.VERCEL_GIT_COMMIT_REF ?? null;
+  }
+  if (process.env.NETLIFY) {
+    // https://docs.netlify.com/configure-builds/environment-variables/
+    return process.env.HEAD ?? null;
+  }
+
+  if (process.env.CI) {
+    // https://docs.github.com/en/actions/learn-github-actions/variables
+    // https://docs.gitlab.com/ee/ci/variables/predefined_variables.html
+    return (
+      process.env.GITHUB_HEAD_REF ?? process.env.CI_COMMIT_REF_NAME ?? null
+    );
+  }
+
+  return null;
+}
+
+export function isNonProdBuildEnvironment(): boolean {
+  if (process.env.VERCEL) {
+    // https://vercel.com/docs/projects/environment-variables/system-environment-variables
+    return process.env.VERCEL_ENV !== "production";
+  }
+  if (process.env.NETLIFY) {
+    // https://docs.netlify.com/configure-builds/environment-variables/
+    return process.env.CONTEXT !== "production";
+  }
+  return false;
+}
diff --git a/synced/convex/libs/cli/lib/fsUtils.test.ts b/synced/convex/libs/cli/lib/fsUtils.test.ts
new file mode 100644
index 0000000..5b51388
--- /dev/null
+++ b/synced/convex/libs/cli/lib/fsUtils.test.ts
@@ -0,0 +1,67 @@
+import { test, expect, describe, beforeEach, afterEach } from "vitest";
+import { oneoffContext, Context } from "../../bundler/context.js";
+import fs from "fs";
+import os from "os";
+import path from "path";
+import { recursivelyDelete } from "./fsUtils.js";
+
+describe("fsUtils", async () => {
+  let tmpDir: string;
+  let ctx: Context;
+
+  beforeEach(async () => {
+    ctx = await oneoffContext({
+      url: undefined,
+      adminKey: undefined,
+      envFile: undefined,
+    });
+    tmpDir = fs.mkdtempSync(`${os.tmpdir()}${path.sep}`);
+  });
+
+  describe("recursivelyDelete", () => {
+    test("deletes file", () => {
+      const file = path.join(tmpDir, "file");
+      ctx.fs.writeUtf8File(file, "contents");
+      expect(ctx.fs.exists(file)).toBe(true);
+
+      recursivelyDelete(ctx, file);
+      expect(ctx.fs.exists(file)).toBe(false);
+    });
+
+    test("throws an error on non-existent file", () => {
+      const nonexistentFile = path.join(tmpDir, "nonexistent_file");
+      expect(() => {
+        recursivelyDelete(ctx, nonexistentFile);
+      }).toThrow("ENOENT: no such file or directory");
+    });
+
+    test("does not throw error if `force` is used", () => {
+      const nonexistentFile = path.join(tmpDir, "nonexistent_file");
+      recursivelyDelete(ctx, nonexistentFile, { force: true });
+    });
+
+    test("recursively deletes a directory", () => {
+      const dir = path.join(tmpDir, "dir");
+      ctx.fs.mkdir(dir);
+      const nestedFile = path.join(dir, "nested_file");
+      ctx.fs.writeUtf8File(nestedFile, "content");
+      const nestedDir = path.join(dir, "nested_dir");
+      ctx.fs.mkdir(nestedDir);
+
+      expect(ctx.fs.exists(dir)).toBe(true);
+
+      recursivelyDelete(ctx, dir);
+      expect(ctx.fs.exists(dir)).toBe(false);
+    });
+
+    test("`recursive` and `force` work together", () => {
+      const nonexistentDir = path.join(tmpDir, "nonexistent_dir");
+      // Shouldn't throw an exception.
+      recursivelyDelete(ctx, nonexistentDir, { force: true });
+    });
+  });
+
+  afterEach(() => {
+    fs.rmSync(tmpDir, { recursive: true });
+  });
+});
diff --git a/synced/convex/libs/cli/lib/fsUtils.ts b/synced/convex/libs/cli/lib/fsUtils.ts
new file mode 100644
index 0000000..0a14c8f
--- /dev/null
+++ b/synced/convex/libs/cli/lib/fsUtils.ts
@@ -0,0 +1,74 @@
+import { Context, logOutput } from "../../bundler/context.js";
+import path from "path";
+import { NodeFs } from "../../bundler/fs.js";
+
+export function recursivelyDelete(
+  ctx: Context,
+  deletePath: string,
+  opts?: { force?: boolean; dryRun?: boolean },
+) {
+  const dryRun = !!opts?.dryRun;
+  let st;
+  try {
+    st = ctx.fs.stat(deletePath);
+  } catch (err: any) {
+    if (err.code === "ENOENT" && opts?.force) {
+      return;
+    }
+    // eslint-disable-next-line no-restricted-syntax
+    throw err;
+  }
+  if (st.isDirectory()) {
+    for (const entry of ctx.fs.listDir(deletePath)) {
+      recursivelyDelete(ctx, path.join(deletePath, entry.name), opts);
+    }
+    if (dryRun) {
+      logOutput(ctx, `Command would delete directory: ${deletePath}`);
+      return;
+    }
+    try {
+      ctx.fs.rmdir(deletePath);
+    } catch (err: any) {
+      if (err.code !== "ENOENT") {
+        // eslint-disable-next-line no-restricted-syntax
+        throw err;
+      }
+    }
+  } else {
+    if (dryRun) {
+      logOutput(ctx, `Command would delete file: ${deletePath}`);
+      return;
+    }
+    try {
+      ctx.fs.unlink(deletePath);
+    } catch (err: any) {
+      if (err.code !== "ENOENT") {
+        // eslint-disable-next-line no-restricted-syntax
+        throw err;
+      }
+    }
+  }
+}
+
+export async function recursivelyCopy(
+  ctx: Context,
+  nodeFs: NodeFs,
+  src: string,
+  dest: string,
+) {
+  const st = nodeFs.stat(src);
+  if (st.isDirectory()) {
+    nodeFs.mkdir(dest, { recursive: true });
+    for (const entry of nodeFs.listDir(src)) {
+      await recursivelyCopy(
+        ctx,
+        nodeFs,
+        path.join(src, entry.name),
+        path.join(dest, entry.name),
+      );
+    }
+  } else {
+    // Don't use writeUtf8File to allow copying arbitrary files
+    await nodeFs.writeFileStream(dest, nodeFs.createReadStream(src, {}));
+  }
+}
diff --git a/synced/convex/libs/cli/lib/functionSpec.ts b/synced/convex/libs/cli/lib/functionSpec.ts
new file mode 100644
index 0000000..35dcc7f
--- /dev/null
+++ b/synced/convex/libs/cli/lib/functionSpec.ts
@@ -0,0 +1,38 @@
+import chalk from "chalk";
+import { logOutput } from "../../bundler/context.js";
+import { runSystemQuery } from "./run.js";
+import { Context } from "../../bundler/context.js";
+
+export async function functionSpecForDeployment(
+  ctx: Context,
+  options: {
+    deploymentUrl: string;
+    adminKey: string;
+    file: boolean;
+  },
+) {
+  const functions = (await runSystemQuery(ctx, {
+    deploymentUrl: options.deploymentUrl,
+    adminKey: options.adminKey,
+    functionName: "_system/cli/modules:apiSpec",
+    componentPath: undefined,
+    args: {},
+  })) as any[];
+  const url = (await runSystemQuery(ctx, {
+    deploymentUrl: options.deploymentUrl,
+    adminKey: options.adminKey,
+    functionName: "_system/cli/convexUrl:cloudUrl",
+    componentPath: undefined,
+    args: {},
+  })) as string;
+
+  const output = JSON.stringify({ url, functions }, null, 2);
+
+  if (options.file) {
+    const fileName = `function_spec_${Date.now().valueOf()}.json`;
+    ctx.fs.writeUtf8File(fileName, output);
+    logOutput(ctx, chalk.green(`Wrote function spec to ${fileName}`));
+  } else {
+    logOutput(ctx, output);
+  }
+}
diff --git a/synced/convex/libs/cli/lib/indexes.ts b/synced/convex/libs/cli/lib/indexes.ts
new file mode 100644
index 0000000..a4464b1
--- /dev/null
+++ b/synced/convex/libs/cli/lib/indexes.ts
@@ -0,0 +1,236 @@
+import chalk from "chalk";
+import path from "path";
+import { bundleSchema } from "../../bundler/index.js";
+import {
+  Context,
+  changeSpinner,
+  logFailure,
+  logFinishedStep,
+  logError,
+} from "../../bundler/context.js";
+import {
+  poll,
+  logAndHandleFetchError,
+  deploymentFetch,
+  deprecationCheckWarning,
+} from "./utils/utils.js";
+
+type IndexMetadata = {
+  table: string;
+  name: string;
+  fields:
+    | string[]
+    | {
+        searchField: string;
+        filterFields: string[];
+      };
+  backfill: {
+    state: "in_progress" | "done";
+  };
+};
+
+type SchemaState =
+  | { state: "pending" }
+  | { state: "validated" }
+  | { state: "active" }
+  | { state: "overwritten" }
+  | { state: "failed"; error: string; tableName?: string };
+
+type SchemaStateResponse = {
+  indexes: IndexMetadata[];
+  schemaState: SchemaState;
+};
+type PrepareSchemaResponse = {
+  added: IndexMetadata[];
+  dropped: IndexMetadata[];
+  schemaId: string;
+};
+
+export async function pushSchema(
+  ctx: Context,
+  origin: string,
+  adminKey: string,
+  schemaDir: string,
+  dryRun: boolean,
+): Promise<{ schemaId?: string; schemaState?: SchemaState }> {
+  if (
+    !ctx.fs.exists(path.resolve(schemaDir, "schema.ts")) &&
+    !ctx.fs.exists(path.resolve(schemaDir, "schema.js"))
+  ) {
+    // Don't do anything.
+    return {};
+  }
+  const bundles = await bundleSchema(ctx, schemaDir, []);
+
+  changeSpinner(ctx, "Checking for index or schema changes...");
+
+  let data: PrepareSchemaResponse;
+  const fetch = deploymentFetch(ctx, {
+    deploymentUrl: origin,
+    adminKey,
+  });
+  try {
+    const res = await fetch("/api/prepare_schema", {
+      method: "POST",
+      body: JSON.stringify({
+        bundle: bundles[0],
+        adminKey,
+        dryRun,
+      }),
+    });
+    deprecationCheckWarning(ctx, res);
+    data = await res.json();
+  } catch (err: unknown) {
+    logFailure(ctx, `Error: Unable to run schema validation on ${origin}`);
+    return await logAndHandleFetchError(ctx, err);
+  }
+
+  const schemaId = data.schemaId;
+
+  const schemaState = await waitForReadySchema(ctx, origin, adminKey, schemaId);
+  logIndexChanges(ctx, data, dryRun);
+  return { schemaId, schemaState };
+}
+
+/// Wait for indexes to build and schema to be validated.
+async function waitForReadySchema(
+  ctx: Context,
+  origin: string,
+  adminKey: string,
+  schemaId: string,
+): Promise<SchemaState> {
+  const path = `api/schema_state/${schemaId}`;
+  const depFetch = deploymentFetch(ctx, {
+    deploymentUrl: origin,
+    adminKey,
+  });
+  const fetch = async () => {
+    try {
+      const resp = await depFetch(path, { method: "GET" });
+      const data: SchemaStateResponse = await resp.json();
+      return data;
+    } catch (err: unknown) {
+      logFailure(
+        ctx,
+        `Error: Unable to build indexes and run schema validation on ${origin}`,
+      );
+      return await logAndHandleFetchError(ctx, err);
+    }
+  };
+
+  // Set the spinner to the default progress message before the first `fetch` call returns.
+  setSchemaProgressSpinner(ctx, null);
+
+  const data = await poll(fetch, (data: SchemaStateResponse) => {
+    setSchemaProgressSpinner(ctx, data);
+    return (
+      data.indexes.every((index) => index.backfill.state === "done") &&
+      data.schemaState.state !== "pending"
+    );
+  });
+
+  switch (data.schemaState.state) {
+    case "failed":
+      // Schema validation failed. This could be either because the data
+      // is bad or the schema is wrong. Classify this as a filesystem error
+      // because adjusting `schema.ts` is the most normal next step.
+      logFailure(ctx, "Schema validation failed");
+      logError(ctx, chalk.red(`${data.schemaState.error}`));
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: {
+          "invalid filesystem or db data": data.schemaState.tableName
+            ? {
+                tableName: data.schemaState.tableName,
+              }
+            : null,
+        },
+        printedMessage: null, // TODO - move logging into here
+      });
+
+    case "overwritten":
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage: `Schema was overwritten by another push.`,
+      });
+    case "validated":
+      logFinishedStep(ctx, "Schema validation complete.");
+      break;
+    case "active":
+      break;
+  }
+  return data.schemaState;
+}
+
+function setSchemaProgressSpinner(
+  ctx: Context,
+  data: SchemaStateResponse | null,
+) {
+  if (!data) {
+    changeSpinner(
+      ctx,
+      "Backfilling indexes and checking that documents match your schema...",
+    );
+    return;
+  }
+  const indexesCompleted = data.indexes.filter(
+    (index) => index.backfill.state === "done",
+  ).length;
+  const numIndexes = data.indexes.length;
+
+  const indexesDone = indexesCompleted === numIndexes;
+  const schemaDone = data.schemaState.state !== "pending";
+
+  if (indexesDone && schemaDone) {
+    return;
+  }
+
+  let msg: string;
+  if (!indexesDone && !schemaDone) {
+    msg = `Backfilling indexes (${indexesCompleted}/${numIndexes} ready) and checking that documents match your schema...`;
+  } else if (!indexesDone) {
+    msg = `Backfilling indexes (${indexesCompleted}/${numIndexes} ready)...`;
+  } else {
+    msg = "Checking that documents match your schema...";
+  }
+  changeSpinner(ctx, msg);
+}
+
+function logIndexChanges(
+  ctx: Context,
+  indexes: {
+    added: IndexMetadata[];
+    dropped: IndexMetadata[];
+  },
+  dryRun: boolean,
+) {
+  if (indexes.dropped.length > 0) {
+    let indexDiff = "";
+    for (const index of indexes.dropped) {
+      indexDiff += `  [-] ${stringifyIndex(index)}\n`;
+    }
+    // strip last new line
+    indexDiff = indexDiff.slice(0, -1);
+    logFinishedStep(
+      ctx,
+      `${dryRun ? "Would delete" : "Deleted"} table indexes:\n${indexDiff}`,
+    );
+  }
+  if (indexes.added.length > 0) {
+    let indexDiff = "";
+    for (const index of indexes.added) {
+      indexDiff += `  [+] ${stringifyIndex(index)}\n`;
+    }
+    // strip last new line
+    indexDiff = indexDiff.slice(0, -1);
+    logFinishedStep(
+      ctx,
+      `${dryRun ? "Would add" : "Added"} table indexes:\n${indexDiff}`,
+    );
+  }
+}
+
+function stringifyIndex(index: IndexMetadata) {
+  return `${index.table}.${index.name} ${JSON.stringify(index.fields)}`;
+}
diff --git a/synced/convex/libs/cli/lib/init.ts b/synced/convex/libs/cli/lib/init.ts
new file mode 100644
index 0000000..961b218
--- /dev/null
+++ b/synced/convex/libs/cli/lib/init.ts
@@ -0,0 +1,75 @@
+import chalk from "chalk";
+import { Context, logFinishedStep, logMessage } from "../../bundler/context.js";
+import { DeploymentType } from "./api.js";
+import { writeConvexUrlToEnvFile } from "./envvars.js";
+import { getDashboardUrl } from "./dashboard.js";
+
+export async function finalizeConfiguration(
+  ctx: Context,
+  options: {
+    functionsPath: string;
+    deploymentType: DeploymentType;
+    deploymentName: string;
+    url: string;
+    wroteToGitIgnore: boolean;
+    changedDeploymentEnvVar: boolean;
+  },
+) {
+  const envVarWrite = await writeConvexUrlToEnvFile(ctx, options.url);
+  if (envVarWrite !== null) {
+    logFinishedStep(
+      ctx,
+      `${messageForDeploymentType(options.deploymentType, options.url)} and saved its:\n` +
+        `    name as CONVEX_DEPLOYMENT to .env.local\n` +
+        `    URL as ${envVarWrite.envVar} to ${envVarWrite.envFile}`,
+    );
+  } else if (options.changedDeploymentEnvVar) {
+    logFinishedStep(
+      ctx,
+      `${messageForDeploymentType(options.deploymentType, options.url)} and saved its name as CONVEX_DEPLOYMENT to .env.local`,
+    );
+  }
+  if (options.wroteToGitIgnore) {
+    logMessage(ctx, chalk.gray(`  Added ".env.local" to .gitignore`));
+  }
+  if (options.deploymentType === "anonymous") {
+    logMessage(
+      ctx,
+      `Run \`npx convex login\` at any time to create an account and link this deployment.`,
+    );
+  }
+
+  const anyChanges =
+    options.wroteToGitIgnore ||
+    options.changedDeploymentEnvVar ||
+    envVarWrite !== null;
+  if (anyChanges) {
+    const dashboardUrl = getDashboardUrl(ctx, {
+      deploymentName: options.deploymentName,
+      deploymentType: options.deploymentType,
+    });
+    logMessage(
+      ctx,
+      `\nWrite your Convex functions in ${chalk.bold(options.functionsPath)}\n` +
+        "Give us feedback at https://convex.dev/community or support@convex.dev\n" +
+        `View the Convex dashboard at ${dashboardUrl}\n`,
+    );
+  }
+}
+
+function messageForDeploymentType(deploymentType: DeploymentType, url: string) {
+  switch (deploymentType) {
+    case "anonymous":
+      return `Started running a deployment locally at ${url}`;
+    case "local":
+      return `Started running a deployment locally at ${url}`;
+    case "dev":
+    case "prod":
+    case "preview":
+      return `Provisioned a ${deploymentType} deployment`;
+    default: {
+      const _exhaustiveCheck: never = deploymentType;
+      return `Provisioned a ${deploymentType as any} deployment`;
+    }
+  }
+}
diff --git a/synced/convex/libs/cli/lib/localDeployment/anonymous.ts b/synced/convex/libs/cli/lib/localDeployment/anonymous.ts
new file mode 100644
index 0000000..b77b771
--- /dev/null
+++ b/synced/convex/libs/cli/lib/localDeployment/anonymous.ts
@@ -0,0 +1,512 @@
+// ----------------------------------------------------------------------------
+// Anonymous (No account)
+
+import path from "path";
+import {
+  Context,
+  logFinishedStep,
+  logMessage,
+  logVerbose,
+  logWarning,
+} from "../../../bundler/context.js";
+import { promptSearch, promptString, promptYesNo } from "../utils/prompts.js";
+import {
+  bigBrainGenerateAdminKeyForAnonymousDeployment,
+  bigBrainPause,
+  bigBrainStart,
+} from "./bigBrain.js";
+import { LocalDeploymentError, printLocalDeploymentOnError } from "./errors.js";
+import {
+  LocalDeploymentKind,
+  deploymentStateDir,
+  ensureUuidForAnonymousUser,
+  loadDeploymentConfig,
+  saveDeploymentConfig,
+} from "./filePaths.js";
+import { rootDeploymentStateDir } from "./filePaths.js";
+import { LocalDeploymentConfig } from "./filePaths.js";
+import { DeploymentDetails } from "./localDeployment.js";
+import { ensureBackendStopped, localDeploymentUrl } from "./run.js";
+import { ensureBackendRunning } from "./run.js";
+import { handlePotentialUpgrade } from "./upgrade.js";
+import {
+  isOffline,
+  generateInstanceSecret,
+  choosePorts,
+  LOCAL_BACKEND_INSTANCE_SECRET,
+} from "./utils.js";
+import { handleDashboard } from "./dashboard.js";
+import crypto from "crypto";
+import { recursivelyDelete, recursivelyCopy } from "../fsUtils.js";
+import { ensureBackendBinaryDownloaded } from "./download.js";
+import { isAnonymousDeployment } from "../deployment.js";
+import { createProject } from "../api.js";
+import { removeAnonymousPrefix } from "../deployment.js";
+import { nodeFs } from "../../../bundler/fs.js";
+
+export async function handleAnonymousDeployment(
+  ctx: Context,
+  options: {
+    ports?: {
+      cloud: number;
+      site: number;
+    };
+    backendVersion?: string;
+    dashboardVersion?: string;
+    forceUpgrade: boolean;
+    deploymentName: string | null;
+    chosenConfiguration: "new" | "existing" | "ask" | null;
+  },
+): Promise<DeploymentDetails> {
+  if (await isOffline()) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: "Cannot run a local deployment while offline",
+    });
+  }
+
+  const deployment = await chooseDeployment(ctx, {
+    deploymentName: options.deploymentName,
+    chosenConfiguration: options.chosenConfiguration,
+  });
+  if (deployment.kind === "first") {
+    logMessage(
+      ctx,
+      "This command, `npx convex dev`, will run your Convex backend locally and update it with the function you write in the `convex/` directory.",
+    );
+    logMessage(
+      ctx,
+      "Use `npx convex dashboard` to view and interact with your project from a web UI.",
+    );
+    logMessage(
+      ctx,
+      "Use `npx convex docs` to read the docs and `npx convex help` to see other commands.",
+    );
+    ensureUuidForAnonymousUser(ctx);
+    if (process.stdin.isTTY) {
+      const result = await promptYesNo(ctx, {
+        message: "Continue?",
+        default: true,
+      });
+      if (!result) {
+        return ctx.crash({
+          exitCode: 1,
+          errorType: "fatal",
+          printedMessage: "Exiting",
+        });
+      }
+    }
+  }
+  ctx.registerCleanup(async (_exitCode, err) => {
+    if (err instanceof LocalDeploymentError) {
+      printLocalDeploymentOnError(ctx);
+    }
+  });
+  const { binaryPath, version } = await ensureBackendBinaryDownloaded(
+    ctx,
+    options.backendVersion === undefined
+      ? {
+          kind: "latest",
+        }
+      : { kind: "version", version: options.backendVersion },
+  );
+  await handleDashboard(ctx, version);
+  let adminKey: string;
+  let instanceSecret: string;
+  if (deployment.kind === "existing") {
+    adminKey = deployment.config.adminKey;
+    instanceSecret =
+      deployment.config.instanceSecret ?? LOCAL_BACKEND_INSTANCE_SECRET;
+    // If it's still running for some reason, exit and tell the user to kill it.
+    // It's fine if a different backend is running on these ports though since we'll
+    // pick new ones.
+    await ensureBackendStopped(ctx, {
+      ports: {
+        cloud: deployment.config.ports.cloud,
+      },
+      maxTimeSecs: 5,
+      deploymentName: deployment.deploymentName,
+      allowOtherDeployments: true,
+    });
+  } else {
+    instanceSecret = generateInstanceSecret();
+    const data = await bigBrainGenerateAdminKeyForAnonymousDeployment(ctx, {
+      instanceName: deployment.deploymentName,
+      instanceSecret,
+    });
+    adminKey = data.adminKey;
+  }
+
+  const [cloudPort, sitePort] = await choosePorts(ctx, {
+    count: 2,
+    startPort: 3210,
+    requestedPorts: [options.ports?.cloud ?? null, options.ports?.site ?? null],
+  });
+  const onActivity = async (isOffline: boolean, _wasOffline: boolean) => {
+    await ensureBackendRunning(ctx, {
+      cloudPort,
+      deploymentName: deployment.deploymentName,
+      maxTimeSecs: 5,
+    });
+    if (isOffline) {
+      return;
+    }
+  };
+
+  const { cleanupHandle } = await handlePotentialUpgrade(ctx, {
+    deploymentName: deployment.deploymentName,
+    deploymentKind: "anonymous",
+    oldVersion:
+      deployment.kind === "existing" ? deployment.config.backendVersion : null,
+    newBinaryPath: binaryPath,
+    newVersion: version,
+    ports: { cloud: cloudPort, site: sitePort },
+    adminKey,
+    instanceSecret,
+    forceUpgrade: options.forceUpgrade,
+  });
+
+  const cleanupFunc = ctx.removeCleanup(cleanupHandle);
+  ctx.registerCleanup(async (exitCode, err) => {
+    if (cleanupFunc !== null) {
+      await cleanupFunc(exitCode, err);
+    }
+  });
+
+  return {
+    adminKey,
+    deploymentName: deployment.deploymentName,
+    deploymentUrl: localDeploymentUrl(cloudPort),
+    onActivity,
+  };
+}
+
+export async function loadAnonymousDeployment(
+  ctx: Context,
+  deploymentName: string,
+): Promise<LocalDeploymentConfig> {
+  const config = loadDeploymentConfig(ctx, "anonymous", deploymentName);
+  if (config === null) {
+    return ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: `Could not find deployment with name ${deploymentName}!`,
+    });
+  }
+  return config;
+}
+
+export async function listExistingAnonymousDeployments(ctx: Context): Promise<
+  Array<{
+    deploymentName: string;
+    config: LocalDeploymentConfig;
+  }>
+> {
+  const dir = rootDeploymentStateDir("anonymous");
+  if (!ctx.fs.exists(dir)) {
+    return [];
+  }
+  const deploymentNames = ctx.fs
+    .listDir(dir)
+    .map((d) => d.name)
+    .filter((d) => isAnonymousDeployment(d));
+  return deploymentNames.flatMap((deploymentName) => {
+    const config = loadDeploymentConfig(ctx, "anonymous", deploymentName);
+    if (config !== null) {
+      return [{ deploymentName, config }];
+    }
+    return [];
+  });
+}
+
+async function chooseDeployment(
+  ctx: Context,
+  options: {
+    deploymentName: string | null;
+    chosenConfiguration: "new" | "existing" | "ask" | null;
+  },
+): Promise<
+  | {
+      kind: "existing";
+      deploymentName: string;
+      config: LocalDeploymentConfig;
+    }
+  | {
+      kind: "new";
+      deploymentName: string;
+    }
+  | {
+      kind: "first";
+      deploymentName: string;
+    }
+> {
+  const deployments = await listExistingAnonymousDeployments(ctx);
+  if (options.deploymentName !== null && options.chosenConfiguration === null) {
+    const existing = deployments.find(
+      (d) => d.deploymentName === options.deploymentName,
+    );
+    if (existing === undefined) {
+      logWarning(
+        ctx,
+        `Could not find project with name ${options.deploymentName}!`,
+      );
+    } else {
+      return {
+        kind: "existing",
+        deploymentName: existing.deploymentName,
+        config: existing.config,
+      };
+    }
+  }
+  if (deployments.length === 0) {
+    logMessage(ctx, "Let's set up your first project.");
+    return await promptForNewDeployment(ctx, []);
+  }
+
+  if (options.chosenConfiguration === "new") {
+    const deploymentName = await promptString(ctx, {
+      message: "Choose a name for your new project:",
+      default: path.basename(process.cwd()),
+    });
+    const uniqueName = await getUniqueName(
+      ctx,
+      deploymentName,
+      deployments.map((d) => d.deploymentName),
+    );
+    logVerbose(ctx, `Deployment name: ${uniqueName}`);
+    return {
+      kind: "new",
+      deploymentName: uniqueName,
+    };
+  }
+
+  const newOrExisting = await promptSearch(ctx, {
+    message: "Which project would you like to use?",
+    choices: [
+      ...(options.chosenConfiguration === "existing"
+        ? []
+        : [
+            {
+              name: "Create a new one",
+              value: "new",
+            },
+          ]),
+      ...deployments.map((d) => ({
+        name: d.deploymentName,
+        value: d.deploymentName,
+      })),
+    ],
+  });
+
+  if (newOrExisting !== "new") {
+    const existingDeployment = deployments.find(
+      (d) => d.deploymentName === newOrExisting,
+    );
+    if (existingDeployment === undefined) {
+      return ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage: `Could not find project with name ${newOrExisting}!`,
+      });
+    }
+    return {
+      kind: "existing",
+      deploymentName: existingDeployment.deploymentName,
+      config: existingDeployment.config,
+    };
+  }
+  return await promptForNewDeployment(
+    ctx,
+    deployments.map((d) => d.deploymentName),
+  );
+}
+
+async function promptForNewDeployment(
+  ctx: Context,
+  existingNames: string[],
+): Promise<
+  | {
+      kind: "first";
+      deploymentName: string;
+    }
+  | {
+      kind: "new";
+      deploymentName: string;
+    }
+> {
+  const isFirstDeployment = existingNames.length === 0;
+  const deploymentName = await promptString(ctx, {
+    message: "Choose a name:",
+    default: path.basename(process.cwd()),
+  });
+
+  const uniqueName = await getUniqueName(
+    ctx,
+    `anonymous-${deploymentName}`,
+    existingNames,
+  );
+  logVerbose(ctx, `Deployment name: ${uniqueName}`);
+  return isFirstDeployment
+    ? {
+        kind: "first",
+        deploymentName: uniqueName,
+      }
+    : {
+        kind: "new",
+        deploymentName: uniqueName,
+      };
+}
+
+async function getUniqueName(
+  ctx: Context,
+  name: string,
+  existingNames: string[],
+) {
+  if (!existingNames.includes(name)) {
+    return name;
+  }
+  for (let i = 1; i <= 5; i++) {
+    const uniqueName = `${name}-${i}`;
+    if (!existingNames.includes(uniqueName)) {
+      return uniqueName;
+    }
+  }
+  const randomSuffix = crypto.randomBytes(4).toString("hex");
+
+  const uniqueName = `${name}-${randomSuffix}`;
+  if (!existingNames.includes(uniqueName)) {
+    return uniqueName;
+  }
+  return ctx.crash({
+    exitCode: 1,
+    errorType: "fatal",
+    printedMessage: `Could not generate a unique name for your project, please choose a different name`,
+  });
+}
+/**
+ * This takes an "anonymous" deployment and makes it a "local" deployment
+ * that is associated with a project in the given team.
+ */
+export async function handleLinkToProject(
+  ctx: Context,
+  args: {
+    deploymentName: string;
+    teamSlug: string;
+    projectSlug: string | null;
+  },
+): Promise<{
+  deploymentName: string;
+  deploymentUrl: string;
+  projectSlug: string;
+}> {
+  logVerbose(
+    ctx,
+    `Linking ${args.deploymentName} to a project in team ${args.teamSlug}`,
+  );
+  const config = await loadDeploymentConfig(
+    ctx,
+    "anonymous",
+    args.deploymentName,
+  );
+  if (config === null) {
+    return ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: "Failed to load deployment config",
+    });
+  }
+  await ensureBackendStopped(ctx, {
+    ports: {
+      cloud: config.ports.cloud,
+    },
+    deploymentName: args.deploymentName,
+    allowOtherDeployments: true,
+    maxTimeSecs: 5,
+  });
+  const projectName = removeAnonymousPrefix(args.deploymentName);
+  let projectSlug: string;
+  if (args.projectSlug !== null) {
+    projectSlug = args.projectSlug;
+  } else {
+    const { projectSlug: newProjectSlug } = await createProject(ctx, {
+      teamSlug: args.teamSlug,
+      projectName,
+      deploymentTypeToProvision: "prod",
+    });
+    projectSlug = newProjectSlug;
+  }
+  logVerbose(ctx, `Creating local deployment in project ${projectSlug}`);
+  // Register it in big brain
+  const { deploymentName: localDeploymentName, adminKey } = await bigBrainStart(
+    ctx,
+    {
+      port: config.ports.cloud,
+      projectSlug,
+      teamSlug: args.teamSlug,
+      instanceName: null,
+    },
+  );
+  const localConfig = loadDeploymentConfig(ctx, "local", localDeploymentName);
+  if (localConfig !== null) {
+    return ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: `Project ${projectSlug} already has a local deployment, so we cannot link this anonymous local deployment to it.`,
+    });
+  }
+  logVerbose(ctx, `Moving ${args.deploymentName} to ${localDeploymentName}`);
+  await moveDeployment(
+    ctx,
+    {
+      deploymentKind: "anonymous",
+      deploymentName: args.deploymentName,
+    },
+    {
+      deploymentKind: "local",
+      deploymentName: localDeploymentName,
+    },
+  );
+  logVerbose(ctx, `Saving deployment config for ${localDeploymentName}`);
+  await saveDeploymentConfig(ctx, "local", localDeploymentName, {
+    adminKey,
+    backendVersion: config.backendVersion,
+    ports: config.ports,
+  });
+  await bigBrainPause(ctx, {
+    projectSlug,
+    teamSlug: args.teamSlug,
+  });
+  logFinishedStep(
+    ctx,
+    `Linked ${args.deploymentName} to project ${projectSlug}`,
+  );
+  return {
+    projectSlug,
+    deploymentName: localDeploymentName,
+    deploymentUrl: localDeploymentUrl(config.ports.cloud),
+  };
+}
+
+export async function moveDeployment(
+  ctx: Context,
+  oldDeployment: {
+    deploymentKind: LocalDeploymentKind;
+    deploymentName: string;
+  },
+  newDeployment: {
+    deploymentKind: LocalDeploymentKind;
+    deploymentName: string;
+  },
+) {
+  const oldPath = deploymentStateDir(
+    oldDeployment.deploymentKind,
+    oldDeployment.deploymentName,
+  );
+  const newPath = deploymentStateDir(
+    newDeployment.deploymentKind,
+    newDeployment.deploymentName,
+  );
+  await recursivelyCopy(ctx, nodeFs, oldPath, newPath);
+  recursivelyDelete(ctx, oldPath);
+}
diff --git a/synced/convex/libs/cli/lib/localDeployment/bigBrain.ts b/synced/convex/libs/cli/lib/localDeployment/bigBrain.ts
new file mode 100644
index 0000000..acef229
--- /dev/null
+++ b/synced/convex/libs/cli/lib/localDeployment/bigBrain.ts
@@ -0,0 +1,110 @@
+import { Context } from "../../../bundler/context.js";
+import { bigBrainAPI } from "../utils/utils.js";
+
+export async function bigBrainStart(
+  ctx: Context,
+  data: {
+    // cloud port
+    port: number;
+    projectSlug: string;
+    teamSlug: string;
+    instanceName: string | null;
+  },
+): Promise<{ deploymentName: string; adminKey: string }> {
+  return bigBrainAPI({
+    ctx,
+    method: "POST",
+    url: "/api/local_deployment/start",
+    data,
+  });
+}
+
+export async function bigBrainPause(
+  ctx: Context,
+  data: {
+    projectSlug: string;
+    teamSlug: string;
+  },
+): Promise<void> {
+  return bigBrainAPI({
+    ctx,
+    method: "POST",
+    url: "/api/local_deployment/pause",
+    data,
+  });
+}
+
+export async function bigBrainRecordActivity(
+  ctx: Context,
+  data: {
+    instanceName: string;
+  },
+) {
+  return bigBrainAPI({
+    ctx,
+    method: "POST",
+    url: "/api/local_deployment/record_activity",
+    data,
+  });
+}
+
+export async function bigBrainEnableFeatureMetadata(
+  ctx: Context,
+): Promise<{ totalProjects: { kind: "none" | "one" | "multiple" } }> {
+  return bigBrainAPI({
+    ctx,
+    method: "POST",
+    url: "/api/local_deployment/enable_feature_metadata",
+    data: {},
+  });
+}
+
+export async function bigBrainGenerateAdminKeyForAnonymousDeployment(
+  ctx: Context,
+  data: {
+    instanceName: string;
+    instanceSecret: string;
+  },
+) {
+  return bigBrainAPI({
+    ctx,
+    method: "POST",
+    url: "/api/local_deployment/generate_admin_key",
+    data,
+  });
+}
+/** Whether a project already has a cloud dev deployment for this user. */
+export async function projectHasExistingCloudDev(
+  ctx: Context,
+  {
+    projectSlug,
+    teamSlug,
+  }: {
+    projectSlug: string;
+    teamSlug: string;
+  },
+) {
+  const response = await bigBrainAPI<
+    | {
+        kind: "Exists";
+      }
+    | {
+        kind: "DoesNotExist";
+      }
+  >({
+    ctx,
+    method: "POST",
+    url: "/api/deployment/existing_dev",
+    data: { projectSlug, teamSlug },
+  });
+  if (response.kind === "Exists") {
+    return true;
+  } else if (response.kind === "DoesNotExist") {
+    return false;
+  }
+  return await ctx.crash({
+    exitCode: 1,
+    errorType: "fatal",
+    printedMessage: `Unexpected /api/deployment/existing_dev response: ${JSON.stringify(response, null, 2)}`,
+  });
+}
diff --git a/synced/convex/libs/cli/lib/localDeployment/dashboard.ts b/synced/convex/libs/cli/lib/localDeployment/dashboard.ts
new file mode 100644
index 0000000..01c51c1
--- /dev/null
+++ b/synced/convex/libs/cli/lib/localDeployment/dashboard.ts
@@ -0,0 +1,169 @@
+import { Context } from "../../../bundler/context.js";
+import {
+  dashboardOutDir,
+  loadDashboardConfig,
+  loadUuidForAnonymousUser,
+  saveDashboardConfig,
+} from "./filePaths.js";
+import { choosePorts } from "./utils.js";
+import { startServer } from "./serve.js";
+import { listExistingAnonymousDeployments } from "./anonymous.js";
+import { localDeploymentUrl, selfHostedEventTag } from "./run.js";
+import serveHandler from "serve-handler";
+import { ensureDashboardDownloaded } from "./download.js";
+import { bigBrainAPIMaybeThrows } from "../utils/utils.js";
+
+export const DEFAULT_LOCAL_DASHBOARD_PORT = 6790;
+export const DEFAULT_LOCAL_DASHBOARD_API_PORT = 6791;
+
+/**
+ * This runs the `dashboard-self-hosted` app locally.
+ * It's currently just used for the `anonymous` flow, while everything else
+ * uses `dashboard.convex.dev`, and some of the code below is written
+ * assuming this is only used for `anonymous`.
+ */
+export async function handleDashboard(ctx: Context, version: string) {
+  const anonymousId = loadUuidForAnonymousUser(ctx) ?? undefined;
+  const isRunning = await checkIfDashboardIsRunning(ctx);
+  if (isRunning) {
+    // It's possible this is running with a different version, but
+    // let's not worry about that for now.
+    return;
+  }
+  await ensureDashboardDownloaded(ctx, version);
+  const [dashboardPort, apiPort] = await choosePorts(ctx, {
+    count: 2,
+    startPort: DEFAULT_LOCAL_DASHBOARD_PORT,
+    requestedPorts: [null, null],
+  });
+  await saveDashboardConfig(ctx, {
+    port: dashboardPort,
+    apiPort,
+    version,
+  });
+
+  let hasReportedSelfHostedEvent = false;
+
+  const { cleanupHandle } = await startServer(
+    ctx,
+    dashboardPort,
+    async (request, response) => {
+      if (!hasReportedSelfHostedEvent) {
+        hasReportedSelfHostedEvent = true;
+        void reportSelfHostedEvent(ctx, {
+          anonymousId,
+          eventName: "self_host_dashboard_connected",
+          tag: selfHostedEventTag("anonymous"),
+        });
+      }
+      await serveHandler(request, response, {
+        public: dashboardOutDir(),
+      });
+    },
+    {},
+  );
+  await startServingListDeploymentsApi(ctx, apiPort);
+  return {
+    dashboardPort,
+    cleanupHandle,
+  };
+}
+
+async function reportSelfHostedEvent(
+  ctx: Context,
+  {
+    anonymousId,
+    eventName,
+    eventFields,
+    tag,
+  }: {
+    anonymousId: string | undefined;
+    eventName: string;
+    eventFields?: Record<string, unknown>;
+    tag: string | undefined;
+  },
+) {
+  try {
+    await bigBrainAPIMaybeThrows({
+      ctx,
+      method: "POST",
+      url: "/api/self_hosted_event",
+      data: {
+        selfHostedUuid: anonymousId,
+        eventName,
+        eventFields,
+        tag,
+      },
+    });
+  } catch {
+    // ignore
+  }
+}
+
+/**
+ * This serves a really basic API that just returns a JSON blob with the deployments
+ * and their credentials.
+ * The locally running dashboard can hit this API.
+ */
+async function startServingListDeploymentsApi(ctx: Context, port: number) {
+  await startServer(
+    ctx,
+    port,
+    async (request, response) => {
+      const deployments = await listExistingAnonymousDeployments(ctx);
+      const deploymentsJson = deployments.map((d) => ({
+        name: d.deploymentName,
+        url: localDeploymentUrl(d.config.ports.cloud),
+        adminKey: d.config.adminKey,
+      }));
+      response.setHeader("Content-Type", "application/json");
+      response.end(JSON.stringify({ deployments: deploymentsJson }));
+    },
+    {
+      cors: true,
+    },
+  );
+}
+
+export async function checkIfDashboardIsRunning(ctx: Context) {
+  const dashboardConfig = loadDashboardConfig(ctx);
+  if (dashboardConfig === null) {
+    return false;
+  }
+  // We're checking if the mini API server is running and has a response that
+  // looks like a list of deployments, since it's easier than checking the
+  // dashboard UI + won't trigger the event for the developer opening the dashboard.
+  let resp: Response;
+  try {
+    resp = await fetch(`http://127.0.0.1:${dashboardConfig.apiPort}`);
+  } catch {
+    return false;
+  }
+  if (!resp.ok) {
+    return false;
+  }
+  let data: { deployments: { name: string; url: string; adminKey: string }[] };
+  try {
+    data = await resp.json();
+  } catch {
+    return false;
+  }
+  return Array.isArray(data.deployments);
+}
+
+export function dashboardUrl(ctx: Context, deploymentName: string) {
+  const dashboardConfig = loadDashboardConfig(ctx);
+  if (dashboardConfig === null) {
+    return null;
+  }
+
+  const queryParams = new URLSearchParams();
+  if (dashboardConfig.apiPort !== DEFAULT_LOCAL_DASHBOARD_API_PORT) {
+    queryParams.set("a", dashboardConfig.apiPort.toString());
+  }
+  queryParams.set("d", deploymentName);
+  const queryString = queryParams.toString();
+  const url = new URL(`http://127.0.0.1:${dashboardConfig.port}`);
+  url.search = queryString;
+  return url.href;
+}
diff --git a/synced/convex/libs/cli/lib/localDeployment/download.ts b/synced/convex/libs/cli/lib/localDeployment/download.ts
new file mode 100644
index 0000000..2b789f5
--- /dev/null
+++ b/synced/convex/libs/cli/lib/localDeployment/download.ts
@@ -0,0 +1,368 @@
+import AdmZip from "adm-zip";
+import {
+  Context,
+  logFinishedStep,
+  startLogProgress,
+  logVerbose,
+  logMessage,
+} from "../../../bundler/context.js";
+import {
+  dashboardZip,
+  executablePath,
+  versionedBinaryDir,
+  dashboardOutDir,
+  resetDashboardDir,
+  loadDashboardConfig,
+  executableName,
+} from "./filePaths.js";
+import child_process from "child_process";
+import { promisify } from "util";
+import { Readable } from "stream";
+import { TempPath, nodeFs, withTmpDir } from "../../../bundler/fs.js";
+import { components } from "@octokit/openapi-types";
+import { recursivelyDelete, recursivelyCopy } from "../fsUtils.js";
+import { LocalDeploymentError } from "./errors.js";
+import ProgressBar from "progress";
+import path from "path";
+
+async function makeExecutable(p: string) {
+  switch (process.platform) {
+    case "darwin":
+    case "linux": {
+      await promisify(child_process.exec)(`chmod +x ${p}`);
+    }
+  }
+}
+
+type GitHubRelease = components["schemas"]["release"];
+
+export async function ensureBackendBinaryDownloaded(
+  ctx: Context,
+  version: { kind: "latest" } | { kind: "version"; version: string },
+): Promise<{ binaryPath: string; version: string }> {
+  if (version.kind === "version") {
+    return _ensureBackendBinaryDownloaded(ctx, version.version);
+  }
+  const latestVersionWithBinary = await findLatestVersionWithBinary(ctx);
+  return _ensureBackendBinaryDownloaded(ctx, latestVersionWithBinary);
+}
+
+async function _ensureBackendBinaryDownloaded(
+  ctx: Context,
+  version: string,
+): Promise<{ binaryPath: string; version: string }> {
+  logVerbose(ctx, `Ensuring backend binary downloaded for version ${version}`);
+  const existingDownload = await checkForExistingDownload(ctx, version);
+  if (existingDownload !== null) {
+    logVerbose(ctx, `Using existing download at ${existingDownload}`);
+    return {
+      binaryPath: existingDownload,
+      version,
+    };
+  }
+  const binaryPath = await downloadBackendBinary(ctx, version);
+  return { version, binaryPath };
+}
+
+/**
+ * Parse the HTTP header like
+ * link: <https://api.github.com/repositories/1300192/issues?page=2>; rel="prev", <https://api.github.com/repositories/1300192/issues?page=4>; rel="next", <https://api.github.com/repositories/1300192/issues?page=515>; rel="last", <https://api.github.com/repositories/1300192/issues?page=1>; rel="first"
+ * into an object.
+ * https://docs.github.com/en/rest/using-the-rest-api/using-pagination-in-the-rest-api?apiVersion=2022-11-28#using-link-headers
+ */
+function parseLinkHeader(header: string): {
+  prev?: string;
+  next?: string;
+  first?: string;
+  last?: string;
+} {
+  const links: { [key: string]: string } = {};
+  const parts = header.split(",");
+  for (const part of parts) {
+    const section = part.split(";");
+    if (section.length !== 2) {
+      continue;
+    }
+    const url = section[0].trim().slice(1, -1);
+    const rel = section[1].trim().slice(5, -1);
+    links[rel] = url;
+  }
+  return links;
+}
+
+/**
+ * Finds the latest version of the convex backend that has a binary that works
+ * on this platform.
+ */
+export async function findLatestVersionWithBinary(
+  ctx: Context,
+): Promise<string> {
+  const targetName = getDownloadPath();
+  logVerbose(
+    ctx,
+    `Finding latest stable release containing binary named ${targetName}`,
+  );
+  let latestVersion: string | undefined;
+  let nextUrl =
+    "https://api.github.com/repos/get-convex/convex-backend/releases?per_page=30";
+
+  try {
+    while (nextUrl) {
+      const response = await fetch(nextUrl);
+
+      if (!response.ok) {
+        const text = await response.text();
+        return await ctx.crash({
+          exitCode: 1,
+          errorType: "fatal",
+          printedMessage: `GitHub API returned ${response.status}: ${text}`,
+          errForSentry: new LocalDeploymentError(
+            `GitHub API returned ${response.status}: ${text}`,
+          ),
+        });
+      }
+
+      const releases = (await response.json()) as GitHubRelease[];
+      if (releases.length === 0) {
+        break;
+      }
+
+      for (const release of releases) {
+        // Track the latest stable version we've seen even if it doesn't have our binary
+        if (!latestVersion && !release.prerelease && !release.draft) {
+          latestVersion = release.tag_name;
+          logVerbose(ctx, `Latest stable version is ${latestVersion}`);
+        }
+
+        // Only consider stable releases
+        if (!release.prerelease && !release.draft) {
+          // Check if this release has our binary
+          if (release.assets.find((asset) => asset.name === targetName)) {
+            logVerbose(
+              ctx,
+              `Latest stable version with appropriate binary is ${release.tag_name}`,
+            );
+            return release.tag_name;
+          }
+
+          logVerbose(
+            ctx,
+            `Version ${release.tag_name} does not contain a ${targetName}, checking previous version`,
+          );
+        }
+      }
+
+      // Get the next page URL from the Link header
+      const linkHeader = response.headers.get("Link");
+      if (!linkHeader) {
+        break;
+      }
+
+      const links = parseLinkHeader(linkHeader);
+      nextUrl = links["next"] || "";
+    }
+
+    // If we get here, we didn't find any suitable releases
+    if (!latestVersion) {
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage:
+          "Found no non-draft, non-prerelease convex backend releases.",
+        errForSentry: new LocalDeploymentError(
+          "Found no non-draft, non-prerelease convex backend releases.",
+        ),
+      });
+    }
+
+    // If we found stable releases but none had our binary
+    const message = `Failed to find a convex backend release that contained ${targetName}.`;
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: message,
+      errForSentry: new LocalDeploymentError(message),
+    });
+  } catch (e) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: "Failed to get latest convex backend releases",
+      errForSentry: new LocalDeploymentError(e?.toString()),
+    });
+  }
+}
+
+/**
+ *
+ * @param ctx
+ * @param version
+ * @returns The binary path if it exists, or null
+ */
+async function checkForExistingDownload(
+  ctx: Context,
+  version: string,
+): Promise<string | null> {
+  const destDir = versionedBinaryDir(version);
+  if (!ctx.fs.exists(destDir)) {
+    return null;
+  }
+  const p = executablePath(version);
+  if (!ctx.fs.exists(p)) {
+    // This directory isn't what we expected. Remove it.
+    recursivelyDelete(ctx, destDir, { force: true });
+    return null;
+  }
+  await makeExecutable(p);
+  return p;
+}
+
+async function downloadBackendBinary(
+  ctx: Context,
+  version: string,
+): Promise<string> {
+  const downloadPath = getDownloadPath();
+  // Note: We validate earlier that there's a binary for this platform at the specified version,
+  // so in practice, we should never hit errors here.
+  if (downloadPath === null) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: `Unsupported platform ${process.platform} and architecture ${process.arch} for local deployment.`,
+    });
+  }
+  await downloadZipFile(ctx, {
+    version,
+    filename: downloadPath,
+    nameForLogging: "Convex backend binary",
+    onDownloadComplete: async (ctx, unzippedPath) => {
+      const name = executableName();
+      const tempExecPath = path.join(unzippedPath, name);
+      await makeExecutable(tempExecPath);
+      logVerbose(ctx, "Marked as executable");
+      ctx.fs.mkdir(versionedBinaryDir(version), { recursive: true });
+      ctx.fs.swapTmpFile(tempExecPath as TempPath, executablePath(version));
+    },
+  });
+  return executablePath(version);
+}
+
+/**
+ * Get the artifact name, composed of the target convex-local-backend and
+ * the Rust "target triple" appropriate for the current machine.
+ **/
+function getDownloadPath() {
+  switch (process.platform) {
+    case "darwin":
+      if (process.arch === "arm64") {
+        return "convex-local-backend-aarch64-apple-darwin.zip";
+      } else if (process.arch === "x64") {
+        return "convex-local-backend-x86_64-apple-darwin.zip";
+      }
+      break;
+    case "linux":
+      if (process.arch === "arm64") {
+        return "convex-local-backend-aarch64-unknown-linux-gnu.zip";
+      } else if (process.arch === "x64") {
+        return "convex-local-backend-x86_64-unknown-linux-gnu.zip";
+      }
+      break;
+    case "win32":
+      return "convex-local-backend-x86_64-pc-windows-msvc.zip";
+  }
+  return null;
+}
+
+function getGithubDownloadUrl(version: string, filename: string) {
+  return `https://github.com/get-convex/convex-backend/releases/download/${version}/${filename}`;
+}
+
+async function downloadZipFile(
+  ctx: Context,
+  args: {
+    version: string;
+    filename: string;
+    nameForLogging: string;
+    onDownloadComplete: (ctx: Context, unzippedPath: TempPath) => Promise<void>;
+  },
+) {
+  const { version, filename, nameForLogging } = args;
+  const url = getGithubDownloadUrl(version, filename);
+  const response = await fetch(url);
+  const contentLength = parseInt(
+    response.headers.get("content-length") ?? "",
+    10,
+  );
+  let progressBar: ProgressBar | null = null;
+  if (!isNaN(contentLength) && contentLength !== 0 && process.stdout.isTTY) {
+    progressBar = startLogProgress(
+      ctx,
+      `Downloading ${nameForLogging} [:bar] :percent :etas`,
+      {
+        width: 40,
+        total: contentLength,
+        clear: true,
+      },
+    );
+  } else {
+    logMessage(ctx, `Downloading ${nameForLogging}`);
+  }
+  if (response.status !== 200) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: `File not found at ${url}.`,
+    });
+  }
+  await withTmpDir(async (tmpDir) => {
+    logVerbose(ctx, `Created tmp dir ${tmpDir.path}`);
+    // Create a file in the tmp dir
+    const zipLocation = tmpDir.registerTempPath(null);
+    const readable = Readable.fromWeb(response.body! as any);
+    await tmpDir.writeFileStream(zipLocation, readable, (chunk: any) => {
+      if (progressBar !== null) {
+        progressBar.tick(chunk.length);
+      }
+    });
+    if (progressBar) {
+      progressBar.terminate();
+      logFinishedStep(ctx, `Downloaded ${nameForLogging}`);
+    }
+    logVerbose(ctx, "Downloaded zip file");
+
+    const zip = new AdmZip(zipLocation);
+    await withTmpDir(async (versionDir) => {
+      logVerbose(ctx, `Created tmp dir ${versionDir.path}`);
+      zip.extractAllTo(versionDir.path, true);
+      logVerbose(ctx, "Extracted from zip file");
+      await args.onDownloadComplete(ctx, versionDir.path);
+    });
+  });
+  return executablePath(version);
+}
+
+export async function ensureDashboardDownloaded(ctx: Context, version: string) {
+  const config = loadDashboardConfig(ctx);
+  if (config !== null && config.version === version) {
+    return;
+  }
+  await resetDashboardDir(ctx);
+  await _ensureDashboardDownloaded(ctx, version);
+}
+async function _ensureDashboardDownloaded(ctx: Context, version: string) {
+  const zipLocation = dashboardZip();
+  if (ctx.fs.exists(zipLocation)) {
+    ctx.fs.unlink(zipLocation);
+  }
+  const outDir = dashboardOutDir();
+  await downloadZipFile(ctx, {
+    version,
+    filename: "dashboard.zip",
+    nameForLogging: "Convex dashboard",
+    onDownloadComplete: async (ctx, unzippedPath) => {
+      await recursivelyCopy(ctx, nodeFs, unzippedPath, outDir);
+      logVerbose(ctx, "Copied into out dir");
+    },
+  });
+  return outDir;
+}
diff --git a/synced/convex/libs/cli/lib/localDeployment/errors.ts b/synced/convex/libs/cli/lib/localDeployment/errors.ts
new file mode 100644
index 0000000..3664e67
--- /dev/null
+++ b/synced/convex/libs/cli/lib/localDeployment/errors.ts
@@ -0,0 +1,17 @@
+import { logFailure, logMessage, Context } from "../../../bundler/context.js";
+
+export class LocalDeploymentError extends Error {}
+
+export function printLocalDeploymentOnError(ctx: Context) {
+  // Note: Not printing the error message here since it should already be printed by
+  // ctx.crash.
+  logFailure(ctx, `Hit an error while running local deployment.`);
+  logMessage(
+    ctx,
+    "Your error has been reported to our team, and we'll be working on it.",
+  );
+  logMessage(
+    ctx,
+    "To opt out, run `npx convex disable-local-deployments`. Then re-run your original command.",
+  );
+}
diff --git a/synced/convex/libs/cli/lib/localDeployment/filePaths.ts b/synced/convex/libs/cli/lib/localDeployment/filePaths.ts
new file mode 100644
index 0000000..9f06922
--- /dev/null
+++ b/synced/convex/libs/cli/lib/localDeployment/filePaths.ts
@@ -0,0 +1,205 @@
+/*
+~/.cache/convex
+  binaries
+    0.0.1
+      convex-local-backend[.exe] // convex-local-backend.exe on windows
+    0.0.2
+      convex-local-backend[.exe]
+  dashboard
+    config.json
+    out
+    // if present, output files from building the self-hosted dashboard which can
+    // be served using `npx serve`
+    index.html
+
+
+~/.convex
+  convex-backend-state
+    local-my_team-chess
+      config.json // contains `LocalDeploymentConfig`
+      convex_local_storage
+      convex_local_backend.sqlite3
+    local-my_team-whisper
+      config.json
+      convex_local_storage
+      convex_local_backend.sqlite3
+    anonymous-convex-backend-state
+      config.json // contains { uuid: <uuid> }, used to identify the anonymous user
+      anonymous-chess
+        config.json
+        convex_local_storage
+        convex_local_backend.sqlite3
+*/
+
+import path from "path";
+import { cacheDir, rootDirectory } from "../utils/utils.js";
+import { Context, logVerbose } from "../../../bundler/context.js";
+import { recursivelyDelete } from "../fsUtils.js";
+import crypto from "crypto";
+
+// Naming is hard, but "local" refers to deployments linked to a Convex project
+// and "anonymous" refers to deployments that are not linked to a Convex project
+// (but in both cases they are running locally).
+export type LocalDeploymentKind = "local" | "anonymous";
+
+export function rootDeploymentStateDir(kind: LocalDeploymentKind) {
+  return path.join(
+    rootDirectory(),
+    kind === "local"
+      ? "convex-backend-state"
+      : "anonymous-convex-backend-state",
+  );
+}
+
+export function deploymentStateDir(
+  deploymentKind: LocalDeploymentKind,
+  deploymentName: string,
+) {
+  return path.join(rootDeploymentStateDir(deploymentKind), deploymentName);
+}
+
+export type LocalDeploymentConfig = {
+  ports: {
+    cloud: number;
+    site: number;
+  };
+  backendVersion: string;
+  adminKey: string;
+  // If not present, use the default instance secret for local backends
+  instanceSecret?: string;
+};
+export function loadDeploymentConfig(
+  ctx: Context,
+  deploymentKind: LocalDeploymentKind,
+  deploymentName: string,
+): LocalDeploymentConfig | null {
+  const dir = deploymentStateDir(deploymentKind, deploymentName);
+  const configFile = path.join(dir, "config.json");
+  if (!ctx.fs.exists(dir) || !ctx.fs.stat(dir).isDirectory()) {
+    logVerbose(ctx, `Deployment ${deploymentName} not found`);
+    return null;
+  }
+  if (ctx.fs.exists(configFile)) {
+    const content = ctx.fs.readUtf8File(configFile);
+    try {
+      return JSON.parse(content);
+    } catch (e) {
+      logVerbose(ctx, `Failed to parse local deployment config: ${e as any}`);
+      return null;
+    }
+  }
+  return null;
+}
+
+export function saveDeploymentConfig(
+  ctx: Context,
+  deploymentKind: LocalDeploymentKind,
+  deploymentName: string,
+  config: LocalDeploymentConfig,
+) {
+  const dir = deploymentStateDir(deploymentKind, deploymentName);
+  const configFile = path.join(dir, "config.json");
+  if (!ctx.fs.exists(dir)) {
+    ctx.fs.mkdir(dir, { recursive: true });
+  }
+  ctx.fs.writeUtf8File(configFile, JSON.stringify(config));
+}
+
+export function binariesDir() {
+  return path.join(cacheDir(), "binaries");
+}
+
+export function dashboardZip() {
+  return path.join(dashboardDir(), "dashboard.zip");
+}
+
+export function versionedBinaryDir(version: string) {
+  return path.join(binariesDir(), version);
+}
+
+export function executablePath(version: string) {
+  return path.join(versionedBinaryDir(version), executableName());
+}
+
+export function executableName() {
+  const ext = process.platform === "win32" ? ".exe" : "";
+  return `convex-local-backend${ext}`;
+}
+
+export function dashboardDir() {
+  return path.join(cacheDir(), "dashboard");
+}
+
+export async function resetDashboardDir(ctx: Context) {
+  const dir = dashboardDir();
+  if (ctx.fs.exists(dir)) {
+    await recursivelyDelete(ctx, dir);
+  }
+  ctx.fs.mkdir(dir, { recursive: true });
+}
+
+export function dashboardOutDir() {
+  return path.join(dashboardDir(), "out");
+}
+
+export type DashboardConfig = {
+  port: number;
+  apiPort: number;
+  version: string;
+};
+export function loadDashboardConfig(ctx: Context) {
+  const configFile = path.join(dashboardDir(), "config.json");
+  if (!ctx.fs.exists(configFile)) {
+    return null;
+  }
+  const content = ctx.fs.readUtf8File(configFile);
+  try {
+    return JSON.parse(content);
+  } catch (e) {
+    logVerbose(ctx, `Failed to parse dashboard config: ${e as any}`);
+    return null;
+  }
+}
+
+export function saveDashboardConfig(ctx: Context, config: DashboardConfig) {
+  const configFile = path.join(dashboardDir(), "config.json");
+  if (!ctx.fs.exists(dashboardDir())) {
+    ctx.fs.mkdir(dashboardDir(), { recursive: true });
+  }
+  ctx.fs.writeUtf8File(configFile, JSON.stringify(config));
+}
+
+export function loadUuidForAnonymousUser(ctx: Context) {
+  const configFile = path.join(
+    rootDeploymentStateDir("anonymous"),
+    "config.json",
+  );
+  if (!ctx.fs.exists(configFile)) {
+    return null;
+  }
+  const content = ctx.fs.readUtf8File(configFile);
+  try {
+    const config = JSON.parse(content);
+    return config.uuid ?? null;
+  } catch (e) {
+    logVerbose(ctx, `Failed to parse uuid for anonymous user: ${e as any}`);
+    return null;
+  }
+}
+
+export function ensureUuidForAnonymousUser(ctx: Context) {
+  const uuid = loadUuidForAnonymousUser(ctx);
+  if (uuid) {
+    return uuid;
+  }
+  const newUuid = crypto.randomUUID();
+  const anonymousDir = rootDeploymentStateDir("anonymous");
+  if (!ctx.fs.exists(anonymousDir)) {
+    ctx.fs.mkdir(anonymousDir, { recursive: true });
+  }
+  ctx.fs.writeUtf8File(
+    path.join(anonymousDir, "config.json"),
+    JSON.stringify({ uuid: newUuid }),
+  );
+  return newUuid;
+}
diff --git a/synced/convex/libs/cli/lib/localDeployment/localDeployment.ts b/synced/convex/libs/cli/lib/localDeployment/localDeployment.ts
new file mode 100644
index 0000000..487b6f4
--- /dev/null
+++ b/synced/convex/libs/cli/lib/localDeployment/localDeployment.ts
@@ -0,0 +1,284 @@
+import { Context, logVerbose } from "../../../bundler/context.js";
+import {
+  bigBrainPause,
+  bigBrainRecordActivity,
+  bigBrainStart,
+} from "./bigBrain.js";
+import {
+  LocalDeploymentConfig,
+  loadDeploymentConfig,
+  rootDeploymentStateDir,
+  saveDeploymentConfig,
+} from "./filePaths.js";
+import {
+  ensureBackendRunning,
+  ensureBackendStopped,
+  localDeploymentUrl,
+  runLocalBackend,
+} from "./run.js";
+import { handlePotentialUpgrade } from "./upgrade.js";
+import { OnDeploymentActivityFunc } from "../deployment.js";
+import { promptSearch } from "../utils/prompts.js";
+import { LocalDeploymentError, printLocalDeploymentOnError } from "./errors.js";
+import {
+  choosePorts,
+  printLocalDeploymentWelcomeMessage,
+  isOffline,
+  LOCAL_BACKEND_INSTANCE_SECRET,
+} from "./utils.js";
+import { ensureBackendBinaryDownloaded } from "./download.js";
+export type DeploymentDetails = {
+  deploymentName: string;
+  deploymentUrl: string;
+  adminKey: string;
+  onActivity: OnDeploymentActivityFunc;
+};
+
+export async function handleLocalDeployment(
+  ctx: Context,
+  options: {
+    teamSlug: string;
+    projectSlug: string;
+    ports?: {
+      cloud: number;
+      site: number;
+    };
+    backendVersion?: string;
+    forceUpgrade: boolean;
+  },
+): Promise<DeploymentDetails> {
+  if (await isOffline()) {
+    return handleOffline(ctx, options);
+  }
+
+  const existingDeploymentForProject = await getExistingDeployment(ctx, {
+    projectSlug: options.projectSlug,
+    teamSlug: options.teamSlug,
+  });
+  if (existingDeploymentForProject === null) {
+    printLocalDeploymentWelcomeMessage(ctx);
+  }
+  ctx.registerCleanup(async (_exitCode, err) => {
+    if (err instanceof LocalDeploymentError) {
+      printLocalDeploymentOnError(ctx);
+    }
+  });
+  if (existingDeploymentForProject !== null) {
+    logVerbose(
+      ctx,
+      `Found existing deployment for project ${options.projectSlug}`,
+    );
+    // If it's still running for some reason, exit and tell the user to kill it.
+    // It's fine if a different backend is running on these ports though since we'll
+    // pick new ones.
+    await ensureBackendStopped(ctx, {
+      ports: {
+        cloud: existingDeploymentForProject.config.ports.cloud,
+      },
+      maxTimeSecs: 5,
+      deploymentName: existingDeploymentForProject.deploymentName,
+      allowOtherDeployments: true,
+    });
+  }
+
+  const { binaryPath, version } = await ensureBackendBinaryDownloaded(
+    ctx,
+    options.backendVersion === undefined
+      ? {
+          kind: "latest",
+        }
+      : { kind: "version", version: options.backendVersion },
+  );
+  const [cloudPort, sitePort] = await choosePorts(ctx, {
+    count: 2,
+    startPort: 3210,
+    requestedPorts: [options.ports?.cloud ?? null, options.ports?.site ?? null],
+  });
+  const { deploymentName, adminKey } = await bigBrainStart(ctx, {
+    port: cloudPort,
+    projectSlug: options.projectSlug,
+    teamSlug: options.teamSlug,
+    instanceName: existingDeploymentForProject?.deploymentName ?? null,
+  });
+  const onActivity = async (isOffline: boolean, _wasOffline: boolean) => {
+    await ensureBackendRunning(ctx, {
+      cloudPort,
+      deploymentName,
+      maxTimeSecs: 5,
+    });
+    if (isOffline) {
+      return;
+    }
+    await bigBrainRecordActivity(ctx, {
+      instanceName: deploymentName,
+    });
+  };
+
+  const { cleanupHandle } = await handlePotentialUpgrade(ctx, {
+    deploymentKind: "local",
+    deploymentName,
+    oldVersion: existingDeploymentForProject?.config.backendVersion ?? null,
+    newBinaryPath: binaryPath,
+    newVersion: version,
+    ports: { cloud: cloudPort, site: sitePort },
+    adminKey,
+    instanceSecret: LOCAL_BACKEND_INSTANCE_SECRET,
+    forceUpgrade: options.forceUpgrade,
+  });
+
+  const cleanupFunc = ctx.removeCleanup(cleanupHandle);
+  ctx.registerCleanup(async (exitCode, err) => {
+    if (cleanupFunc !== null) {
+      await cleanupFunc(exitCode, err);
+    }
+    await bigBrainPause(ctx, {
+      projectSlug: options.projectSlug,
+      teamSlug: options.teamSlug,
+    });
+  });
+
+  return {
+    adminKey,
+    deploymentName,
+    deploymentUrl: localDeploymentUrl(cloudPort),
+    onActivity,
+  };
+}
+
+export async function loadLocalDeploymentCredentials(
+  ctx: Context,
+  deploymentName: string,
+): Promise<{
+  deploymentName: string;
+  deploymentUrl: string;
+  adminKey: string;
+}> {
+  const config = loadDeploymentConfig(ctx, "local", deploymentName);
+  if (config === null) {
+    return ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: "Failed to load deployment config",
+    });
+  }
+  return {
+    deploymentName,
+    deploymentUrl: localDeploymentUrl(config.ports.cloud),
+    adminKey: config.adminKey,
+  };
+}
+
+async function handleOffline(
+  ctx: Context,
+  options: {
+    teamSlug: string;
+    projectSlug: string;
+    ports?: { cloud: number; site: number };
+  },
+): Promise<DeploymentDetails> {
+  const { deploymentName, config } =
+    await chooseFromExistingLocalDeployments(ctx);
+  const { binaryPath } = await ensureBackendBinaryDownloaded(ctx, {
+    kind: "version",
+    version: config.backendVersion,
+  });
+  const [cloudPort, sitePort] = await choosePorts(ctx, {
+    count: 2,
+    startPort: 3210,
+    requestedPorts: [options.ports?.cloud ?? null, options.ports?.site ?? null],
+  });
+  saveDeploymentConfig(ctx, "local", deploymentName, config);
+  await runLocalBackend(ctx, {
+    binaryPath,
+    ports: { cloud: cloudPort, site: sitePort },
+    deploymentName,
+    deploymentKind: "local",
+    instanceSecret: LOCAL_BACKEND_INSTANCE_SECRET,
+    isLatestVersion: false,
+  });
+  return {
+    adminKey: config.adminKey,
+    deploymentName,
+    deploymentUrl: localDeploymentUrl(cloudPort),
+    onActivity: async (isOffline: boolean, wasOffline: boolean) => {
+      await ensureBackendRunning(ctx, {
+        cloudPort,
+        deploymentName,
+        maxTimeSecs: 5,
+      });
+      if (isOffline) {
+        return;
+      }
+      if (wasOffline) {
+        await bigBrainStart(ctx, {
+          port: cloudPort,
+          projectSlug: options.projectSlug,
+          teamSlug: options.teamSlug,
+          instanceName: deploymentName,
+        });
+      }
+      await bigBrainRecordActivity(ctx, {
+        instanceName: deploymentName,
+      });
+    },
+  };
+}
+
+async function getExistingDeployment(
+  ctx: Context,
+  options: {
+    projectSlug: string;
+    teamSlug: string;
+  },
+): Promise<{ deploymentName: string; config: LocalDeploymentConfig } | null> {
+  const { projectSlug, teamSlug } = options;
+  const prefix = `local-${teamSlug.replace(/-/g, "_")}-${projectSlug.replace(/-/g, "_")}`;
+  const localDeployments = await getLocalDeployments(ctx);
+  const existingDeploymentForProject = localDeployments.find((d) =>
+    d.deploymentName.startsWith(prefix),
+  );
+  if (existingDeploymentForProject === undefined) {
+    return null;
+  }
+  return {
+    deploymentName: existingDeploymentForProject.deploymentName,
+    config: existingDeploymentForProject.config,
+  };
+}
+
+async function getLocalDeployments(ctx: Context): Promise<
+  Array<{
+    deploymentName: string;
+    config: LocalDeploymentConfig;
+  }>
+> {
+  const dir = rootDeploymentStateDir("local");
+  if (!ctx.fs.exists(dir)) {
+    return [];
+  }
+  const deploymentNames = ctx.fs
+    .listDir(dir)
+    .map((d) => d.name)
+    .filter((d) => d.startsWith("local-"));
+  return deploymentNames.flatMap((deploymentName) => {
+    const config = loadDeploymentConfig(ctx, "local", deploymentName);
+    if (config !== null) {
+      return [{ deploymentName, config }];
+    }
+    return [];
+  });
+}
+
+async function chooseFromExistingLocalDeployments(ctx: Context): Promise<{
+  deploymentName: string;
+  config: LocalDeploymentConfig;
+}> {
+  const localDeployments = await getLocalDeployments(ctx);
+  return promptSearch(ctx, {
+    message: "Choose from an existing local deployment?",
+    choices: localDeployments.map((d) => ({
+      name: d.deploymentName,
+      value: d,
+    })),
+  });
+}
diff --git a/synced/convex/libs/cli/lib/localDeployment/run.test.ts b/synced/convex/libs/cli/lib/localDeployment/run.test.ts
new file mode 100644
index 0000000..f1801c6
--- /dev/null
+++ b/synced/convex/libs/cli/lib/localDeployment/run.test.ts
@@ -0,0 +1,427 @@
+import { vi, test, expect } from "vitest";
+import { logFailure, oneoffContext } from "../../../bundler/context.js";
+import { findLatestVersionWithBinary } from "./download.js";
+import { components } from "@octokit/openapi-types";
+import stripAnsi from "strip-ansi";
+
+async function setupContext() {
+  const originalContext = await oneoffContext({
+    url: undefined,
+    adminKey: undefined,
+    envFile: undefined,
+  });
+  const ctx = {
+    ...originalContext,
+    crash: (args: { printedMessage: string | null }) => {
+      if (args.printedMessage !== null) {
+        logFailure(originalContext, args.printedMessage);
+      }
+      throw new Error();
+    },
+  };
+  return ctx;
+}
+test("findLatestVersionWithBinary", async () => {
+  // Make a context that throws on crashes so we can detect them.
+  const ctx = await setupContext();
+  const stderrSpy = vi.spyOn(process.stderr, "write").mockImplementation(() => {
+    // Do nothing
+    return true;
+  });
+
+  const getVersion = async (inp: GitHubRelease[]) => {
+    const fetchSpy = vi.spyOn(global, "fetch").mockImplementation(() =>
+      Promise.resolve({
+        ok: true,
+        json: () => Promise.resolve(inp),
+      } as Response),
+    );
+
+    const expected = await findLatestVersionWithBinary(ctx);
+    expect(fetchSpy).toHaveBeenCalledTimes(1);
+    expect(fetchSpy).toHaveBeenCalledWith(
+      "https://api.github.com/repos/get-convex/convex-backend/releases?per_page=30",
+    );
+    fetchSpy.mockRestore();
+    return expected;
+  };
+
+  const failToGetVersion = async (inp: GitHubRelease[]) => {
+    const fetchSpy = vi.spyOn(global, "fetch").mockImplementation(() =>
+      Promise.resolve({
+        ok: true,
+        json: () => Promise.resolve(inp),
+      } as Response),
+    );
+    stderrSpy.mockClear();
+
+    await expect(findLatestVersionWithBinary(ctx)).rejects.toThrow();
+    expect(fetchSpy).toHaveBeenCalledTimes(1);
+    expect(fetchSpy).toHaveBeenCalledWith(
+      "https://api.github.com/repos/get-convex/convex-backend/releases?per_page=30",
+    );
+    const calledWith = stderrSpy.mock.calls as string[][];
+    const err = stripAnsi(calledWith[0][0]);
+    fetchSpy.mockRestore();
+    stderrSpy.mockClear();
+    return err;
+  };
+
+  // Default: take the older version, it's not a prerelease.
+  expect(await getVersion(githubReleases())).toBe(
+    "precompiled-2025-01-31-e52353b",
+  );
+
+  // Take the newer one when they both aren't prereleases
+  {
+    const [latest, older] = githubReleases();
+    latest.prerelease = false;
+    expect(await getVersion([latest, older])).toBe(
+      "precompiled-2025-02-03-2da5268",
+    );
+  }
+
+  // Take the older one since it has the artifacts
+  {
+    const [latest, older] = githubReleases();
+    latest.prerelease = false;
+    latest.assets = [];
+    expect(await getVersion([latest, older])).toBe(
+      "precompiled-2025-01-31-e52353b",
+    );
+  }
+
+  // Fail, everything is a prerelease
+  {
+    const [latest, older] = githubReleases();
+    older.prerelease = true;
+    expect(await failToGetVersion([latest, older])).toBe(
+      " Failed to get latest convex backend releases\n",
+    );
+  }
+
+  // Fail, nothing has artifacts
+  {
+    const [latest, older] = githubReleases();
+    older.prerelease = true;
+    latest.assets = [];
+    older.assets = [];
+    expect(await failToGetVersion([latest, older])).toBe(
+      " Failed to get latest convex backend releases\n",
+    );
+  }
+});
+
+// experimentally, we get more fields than there are types for here
+type GitHubRelease = components["schemas"]["release"] & {
+  author: components["schemas"]["release"]["author"] & {
+    user_view_type: "public";
+  };
+};
+
+function githubReleases() {
+  const data: GitHubRelease[] = [
+    {
+      url: "https://api.github.com/repos/get-convex/convex-backend/releases/198003843",
+      assets_url:
+        "https://api.github.com/repos/get-convex/convex-backend/releases/198003843/assets",
+      upload_url:
+        "https://uploads.github.com/repos/get-convex/convex-backend/releases/198003843/assets{?name,label}",
+      html_url:
+        "https://github.com/get-convex/convex-backend/releases/tag/precompiled-2025-02-03-2da5268",
+      id: 198003843,
+      author: {
+        login: "github-actions[bot]",
+        id: 41898282,
+        node_id: "MDM6Qm90NDE4OTgyODI=",
+        avatar_url: "https://avatars.githubusercontent.com/in/15368?v=4",
+        gravatar_id: "",
+        url: "https://api.github.com/users/github-actions%5Bbot%5D",
+        html_url: "https://github.com/apps/github-actions",
+        followers_url:
+          "https://api.github.com/users/github-actions%5Bbot%5D/followers",
+        following_url:
+          "https://api.github.com/users/github-actions%5Bbot%5D/following{/other_user}",
+        gists_url:
+          "https://api.github.com/users/github-actions%5Bbot%5D/gists{/gist_id}",
+        starred_url:
+          "https://api.github.com/users/github-actions%5Bbot%5D/starred{/owner}{/repo}",
+        subscriptions_url:
+          "https://api.github.com/users/github-actions%5Bbot%5D/subscriptions",
+        organizations_url:
+          "https://api.github.com/users/github-actions%5Bbot%5D/orgs",
+        repos_url: "https://api.github.com/users/github-actions%5Bbot%5D/repos",
+        events_url:
+          "https://api.github.com/users/github-actions%5Bbot%5D/events{/privacy}",
+        received_events_url:
+          "https://api.github.com/users/github-actions%5Bbot%5D/received_events",
+        type: "Bot",
+        user_view_type: "public",
+        site_admin: false,
+      },
+      node_id: "RE_kwDOLdZc7c4LzUyD",
+      tag_name: "precompiled-2025-02-03-2da5268",
+      target_commitish: "main",
+      name: "Precompiled 2025-02-03-2da5268",
+      draft: false,
+      prerelease: true,
+      created_at: "2025-02-01T00:27:43Z",
+      published_at: "2025-02-03T00:54:40Z",
+      assets: [
+        {
+          url: "https://api.github.com/repos/get-convex/convex-backend/releases/assets/225737903",
+          id: 225737903,
+          node_id: "RA_kwDOLdZc7c4NdHyv",
+          name: "convex-local-backend-aarch64-apple-darwin.zip",
+          label: "",
+          uploader: null as any,
+          content_type: "application/zip",
+          state: "uploaded",
+          size: 34505055,
+          download_count: 4,
+          created_at: "2025-02-03T00:54:41Z",
+          updated_at: "2025-02-03T00:54:42Z",
+          browser_download_url:
+            "https://github.com/get-convex/convex-backend/releases/download/precompiled-2025-02-03-2da5268/convex-local-backend-aarch64-apple-darwin.zip",
+        },
+        {
+          url: "https://api.github.com/repos/get-convex/convex-backend/releases/assets/225738218",
+          id: 225738218,
+          node_id: "RA_kwDOLdZc7c4NdH3q",
+          name: "convex-local-backend-aarch64-unknown-linux-gnu.zip",
+          label: "",
+          uploader: null as any,
+          content_type: "application/zip",
+          state: "uploaded",
+          size: 45542485,
+          download_count: 0,
+          created_at: "2025-02-03T00:55:52Z",
+          updated_at: "2025-02-03T00:55:54Z",
+          browser_download_url:
+            "https://github.com/get-convex/convex-backend/releases/download/precompiled-2025-02-03-2da5268/convex-local-backend-aarch64-unknown-linux-gnu.zip",
+        },
+        {
+          url: "https://api.github.com/repos/get-convex/convex-backend/releases/assets/225738688",
+          id: 225738688,
+          node_id: "RA_kwDOLdZc7c4NdH_A",
+          name: "convex-local-backend-x86_64-apple-darwin.zip",
+          label: "",
+          uploader: null as any,
+          content_type: "application/zip",
+          state: "uploaded",
+          size: 37369137,
+          download_count: 1,
+          created_at: "2025-02-03T00:57:40Z",
+          updated_at: "2025-02-03T00:57:42Z",
+          browser_download_url:
+            "https://github.com/get-convex/convex-backend/releases/download/precompiled-2025-02-03-2da5268/convex-local-backend-x86_64-apple-darwin.zip",
+        },
+        {
+          url: "https://api.github.com/repos/get-convex/convex-backend/releases/assets/225746665",
+          id: 225746665,
+          node_id: "RA_kwDOLdZc7c4NdJ7p",
+          name: "convex-local-backend-x86_64-pc-windows-msvc.zip",
+          label: "",
+          uploader: null as any,
+          content_type: "application/zip",
+          state: "uploaded",
+          size: 34199085,
+          download_count: 2,
+          created_at: "2025-02-03T01:22:57Z",
+          updated_at: "2025-02-03T01:22:58Z",
+          browser_download_url:
+            "https://github.com/get-convex/convex-backend/releases/download/precompiled-2025-02-03-2da5268/convex-local-backend-x86_64-pc-windows-msvc.zip",
+        },
+        {
+          url: "https://api.github.com/repos/get-convex/convex-backend/releases/assets/225745550",
+          id: 225745550,
+          node_id: "RA_kwDOLdZc7c4NdJqO",
+          name: "convex-local-backend-x86_64-unknown-linux-gnu.zip",
+          label: "",
+          uploader: [Object],
+          content_type: "application/zip",
+          state: "uploaded",
+          size: 45196613,
+          download_count: 3,
+          created_at: "2025-02-03T01:19:39Z",
+          updated_at: "2025-02-03T01:19:42Z",
+          browser_download_url:
+            "https://github.com/get-convex/convex-backend/releases/download/precompiled-2025-02-03-2da5268/convex-local-backend-x86_64-unknown-linux-gnu.zip",
+        },
+        {
+          url: "https://api.github.com/repos/get-convex/convex-backend/releases/assets/225746666",
+          id: 225746666,
+          node_id: "RA_kwDOLdZc7c4NdJ7q",
+          name: "LICENSE.md",
+          label: "",
+          uploader: null as any,
+          content_type: "text/markdown",
+          state: "uploaded",
+          size: 3861,
+          download_count: 0,
+          created_at: "2025-02-03T01:22:57Z",
+          updated_at: "2025-02-03T01:22:57Z",
+          browser_download_url:
+            "https://github.com/get-convex/convex-backend/releases/download/precompiled-2025-02-03-2da5268/LICENSE.md",
+        },
+      ],
+      tarball_url:
+        "https://api.github.com/repos/get-convex/convex-backend/tarball/precompiled-2025-02-03-2da5268",
+      zipball_url:
+        "https://api.github.com/repos/get-convex/convex-backend/zipball/precompiled-2025-02-03-2da5268",
+      body: "",
+    },
+    {
+      url: "https://api.github.com/repos/get-convex/convex-backend/releases/197690907",
+      assets_url:
+        "https://api.github.com/repos/get-convex/convex-backend/releases/197690907/assets",
+      upload_url:
+        "https://uploads.github.com/repos/get-convex/convex-backend/releases/197690907/assets{?name,label}",
+      html_url:
+        "https://github.com/get-convex/convex-backend/releases/tag/precompiled-2025-01-31-e52353b",
+      id: 197690907,
+      author: {
+        login: "github-actions[bot]",
+        id: 41898282,
+        node_id: "MDM6Qm90NDE4OTgyODI=",
+        avatar_url: "https://avatars.githubusercontent.com/in/15368?v=4",
+        gravatar_id: "",
+        url: "https://api.github.com/users/github-actions%5Bbot%5D",
+        html_url: "https://github.com/apps/github-actions",
+        followers_url:
+          "https://api.github.com/users/github-actions%5Bbot%5D/followers",
+        following_url:
+          "https://api.github.com/users/github-actions%5Bbot%5D/following{/other_user}",
+        gists_url:
+          "https://api.github.com/users/github-actions%5Bbot%5D/gists{/gist_id}",
+        starred_url:
+          "https://api.github.com/users/github-actions%5Bbot%5D/starred{/owner}{/repo}",
+        subscriptions_url:
+          "https://api.github.com/users/github-actions%5Bbot%5D/subscriptions",
+        organizations_url:
+          "https://api.github.com/users/github-actions%5Bbot%5D/orgs",
+        repos_url: "https://api.github.com/users/github-actions%5Bbot%5D/repos",
+        events_url:
+          "https://api.github.com/users/github-actions%5Bbot%5D/events{/privacy}",
+        received_events_url:
+          "https://api.github.com/users/github-actions%5Bbot%5D/received_events",
+        type: "Bot",
+        user_view_type: "public",
+        site_admin: false,
+      },
+      node_id: "RE_kwDOLdZc7c4LyIYb",
+      tag_name: "precompiled-2025-01-31-e52353b",
+      target_commitish: "main",
+      name: "Precompiled 2025-01-31-e52353b",
+      draft: false,
+      prerelease: false,
+      created_at: "2025-01-31T00:41:09Z",
+      published_at: "2025-01-31T00:48:53Z",
+      assets: [
+        {
+          url: "https://api.github.com/repos/get-convex/convex-backend/releases/assets/225737903",
+          id: 225737903,
+          node_id: "RA_kwDOLdZc7c4NdHyv",
+          name: "convex-local-backend-aarch64-apple-darwin.zip",
+          label: "",
+          uploader: null as any,
+          content_type: "application/zip",
+          state: "uploaded",
+          size: 34505055,
+          download_count: 4,
+          created_at: "2025-02-03T00:54:41Z",
+          updated_at: "2025-02-03T00:54:42Z",
+          browser_download_url:
+            "https://github.com/get-convex/convex-backend/releases/download/precompiled-2025-02-03-2da5268/convex-local-backend-aarch64-apple-darwin.zip",
+        },
+        {
+          url: "https://api.github.com/repos/get-convex/convex-backend/releases/assets/225738218",
+          id: 225738218,
+          node_id: "RA_kwDOLdZc7c4NdH3q",
+          name: "convex-local-backend-aarch64-unknown-linux-gnu.zip",
+          label: "",
+          uploader: null as any,
+          content_type: "application/zip",
+          state: "uploaded",
+          size: 45542485,
+          download_count: 0,
+          created_at: "2025-02-03T00:55:52Z",
+          updated_at: "2025-02-03T00:55:54Z",
+          browser_download_url:
+            "https://github.com/get-convex/convex-backend/releases/download/precompiled-2025-02-03-2da5268/convex-local-backend-aarch64-unknown-linux-gnu.zip",
+        },
+        {
+          url: "https://api.github.com/repos/get-convex/convex-backend/releases/assets/225738688",
+          id: 225738688,
+          node_id: "RA_kwDOLdZc7c4NdH_A",
+          name: "convex-local-backend-x86_64-apple-darwin.zip",
+          label: "",
+          uploader: null as any,
+          content_type: "application/zip",
+          state: "uploaded",
+          size: 37369137,
+          download_count: 1,
+          created_at: "2025-02-03T00:57:40Z",
+          updated_at: "2025-02-03T00:57:42Z",
+          browser_download_url:
+            "https://github.com/get-convex/convex-backend/releases/download/precompiled-2025-02-03-2da5268/convex-local-backend-x86_64-apple-darwin.zip",
+        },
+        {
+          url: "https://api.github.com/repos/get-convex/convex-backend/releases/assets/225746665",
+          id: 225746665,
+          node_id: "RA_kwDOLdZc7c4NdJ7p",
+          name: "convex-local-backend-x86_64-pc-windows-msvc.zip",
+          label: "",
+          uploader: null as any,
+          content_type: "application/zip",
+          state: "uploaded",
+          size: 34199085,
+          download_count: 2,
+          created_at: "2025-02-03T01:22:57Z",
+          updated_at: "2025-02-03T01:22:58Z",
+          browser_download_url:
+            "https://github.com/get-convex/convex-backend/releases/download/precompiled-2025-02-03-2da5268/convex-local-backend-x86_64-pc-windows-msvc.zip",
+        },
+        {
+          url: "https://api.github.com/repos/get-convex/convex-backend/releases/assets/225745550",
+          id: 225745550,
+          node_id: "RA_kwDOLdZc7c4NdJqO",
+          name: "convex-local-backend-x86_64-unknown-linux-gnu.zip",
+          label: "",
+          uploader: [Object],
+          content_type: "application/zip",
+          state: "uploaded",
+          size: 45196613,
+          download_count: 3,
+          created_at: "2025-02-03T01:19:39Z",
+          updated_at: "2025-02-03T01:19:42Z",
+          browser_download_url:
+            "https://github.com/get-convex/convex-backend/releases/download/precompiled-2025-02-03-2da5268/convex-local-backend-x86_64-unknown-linux-gnu.zip",
+        },
+        {
+          url: "https://api.github.com/repos/get-convex/convex-backend/releases/assets/225746666",
+          id: 225746666,
+          node_id: "RA_kwDOLdZc7c4NdJ7q",
+          name: "LICENSE.md",
+          label: "",
+          uploader: null as any,
+          content_type: "text/markdown",
+          state: "uploaded",
+          size: 3861,
+          download_count: 0,
+          created_at: "2025-02-03T01:22:57Z",
+          updated_at: "2025-02-03T01:22:57Z",
+          browser_download_url:
+            "https://github.com/get-convex/convex-backend/releases/download/precompiled-2025-02-03-2da5268/LICENSE.md",
+        },
+      ],
+      tarball_url:
+        "https://api.github.com/repos/get-convex/convex-backend/tarball/precompiled-2025-01-31-e52353b",
+      zipball_url:
+        "https://api.github.com/repos/get-convex/convex-backend/zipball/precompiled-2025-01-31-e52353b",
+      body: "",
+    },
+  ];
+
+  return data;
+}
diff --git a/synced/convex/libs/cli/lib/localDeployment/run.ts b/synced/convex/libs/cli/lib/localDeployment/run.ts
new file mode 100644
index 0000000..5f123dd
--- /dev/null
+++ b/synced/convex/libs/cli/lib/localDeployment/run.ts
@@ -0,0 +1,297 @@
+import { Context, logVerbose, logMessage } from "../../../bundler/context.js";
+import {
+  LocalDeploymentKind,
+  deploymentStateDir,
+  loadUuidForAnonymousUser,
+} from "./filePaths.js";
+import path from "path";
+import child_process from "child_process";
+import detect from "detect-port";
+import { SENTRY_DSN } from "../utils/sentry.js";
+import { createHash } from "crypto";
+import { LocalDeploymentError } from "./errors.js";
+
+export async function runLocalBackend(
+  ctx: Context,
+  args: {
+    ports: {
+      cloud: number;
+      site: number;
+    };
+    deploymentKind: LocalDeploymentKind;
+    deploymentName: string;
+    binaryPath: string;
+    instanceSecret: string;
+    isLatestVersion: boolean;
+  },
+): Promise<{
+  cleanupHandle: string;
+}> {
+  const { ports } = args;
+  const deploymentDir = deploymentStateDir(
+    args.deploymentKind,
+    args.deploymentName,
+  );
+  ctx.fs.mkdir(deploymentDir, { recursive: true });
+  const deploymentNameSha = createHash("sha256")
+    .update(args.deploymentName)
+    .digest("hex");
+  const commandArgs = [
+    "--port",
+    ports.cloud.toString(),
+    "--site-proxy-port",
+    ports.site.toString(),
+    "--sentry-identifier",
+    deploymentNameSha,
+    "--instance-name",
+    args.deploymentName,
+    "--instance-secret",
+    args.instanceSecret,
+    "--local-storage",
+    path.join(deploymentDir, "convex_local_storage"),
+    "--beacon-tag",
+    selfHostedEventTag(args.deploymentKind),
+    path.join(deploymentDir, "convex_local_backend.sqlite3"),
+  ];
+  if (args.isLatestVersion) {
+    // CLI args that were added in later versions of backend go here instead of above
+    // since the CLI may run older versions of backend (e.g. when upgrading).
+    if (args.deploymentKind === "anonymous") {
+      const uuid = loadUuidForAnonymousUser(ctx);
+      if (uuid !== null) {
+        commandArgs.push(
+          "--beacon-fields",
+          JSON.stringify({
+            override_uuid: uuid,
+          }),
+        );
+      }
+    }
+  }
+
+  // Check that binary works by running with --help
+  try {
+    const result = child_process.spawnSync(args.binaryPath, [
+      ...commandArgs,
+      "--help",
+    ]);
+    if (result.status === 3221225781) {
+      const message =
+        "Local backend exited because shared libraries are missing. These may include libraries installed via 'Microsoft Visual C++ Redistributable for Visual Studio.'";
+      return ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage: message,
+        errForSentry: new LocalDeploymentError(
+          "Local backend exited with code 3221225781",
+        ),
+      });
+    } else if (result.status !== 0) {
+      const message = `Failed to run backend binary, exit code ${result.status}, error: ${result.stderr.toString()}`;
+      return ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage: message,
+        errForSentry: new LocalDeploymentError(message),
+      });
+    }
+  } catch (e) {
+    const message = `Failed to run backend binary: ${(e as any).toString()}`;
+    return ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: message,
+      errForSentry: new LocalDeploymentError(message),
+    });
+  }
+  const commandStr = `${args.binaryPath} ${commandArgs.join(" ")}`;
+  logVerbose(ctx, `Starting local backend: \`${commandStr}\``);
+  const p = child_process
+    .spawn(args.binaryPath, commandArgs, {
+      stdio: "ignore",
+      env: {
+        ...process.env,
+        SENTRY_DSN: SENTRY_DSN,
+      },
+    })
+    .on("exit", (code) => {
+      const why = code === null ? "from signal" : `with code ${code}`;
+      logVerbose(
+        ctx,
+        `Local backend exited ${why}, full command \`${commandStr}\``,
+      );
+    });
+  const cleanupHandle = ctx.registerCleanup(async () => {
+    logVerbose(ctx, `Stopping local backend on port ${ports.cloud}`);
+    p.kill("SIGTERM");
+  });
+
+  await ensureBackendRunning(ctx, {
+    cloudPort: ports.cloud,
+    deploymentName: args.deploymentName,
+    maxTimeSecs: 10,
+  });
+
+  return {
+    cleanupHandle,
+  };
+}
+
+/** Crash if correct local backend is not currently listening on the expected port. */
+export async function assertLocalBackendRunning(
+  ctx: Context,
+  args: {
+    url: string;
+    deploymentName: string;
+  },
+): Promise<void> {
+  logVerbose(ctx, `Checking local backend at ${args.url} is running`);
+  try {
+    const resp = await fetch(`${args.url}/instance_name`);
+    if (resp.status === 200) {
+      const text = await resp.text();
+      if (text !== args.deploymentName) {
+        return await ctx.crash({
+          exitCode: 1,
+          errorType: "fatal",
+          printedMessage: `A different local backend ${text} is running at ${args.url}`,
+        });
+      } else {
+        return;
+      }
+    } else {
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage: `Error response code received from local backend ${resp.status} ${resp.statusText}`,
+      });
+    }
+  } catch {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: `Local backend isn't running. (it's not listening at ${args.url})\nRun \`npx convex dev\` in another terminal first.`,
+    });
+  }
+}
+
+/** Wait for up to maxTimeSecs for the correct local backend to be running on the expected port. */
+export async function ensureBackendRunning(
+  ctx: Context,
+  args: {
+    cloudPort: number;
+    deploymentName: string;
+    maxTimeSecs: number;
+  },
+): Promise<void> {
+  logVerbose(
+    ctx,
+    `Ensuring backend running on port ${args.cloudPort} is running`,
+  );
+  const deploymentUrl = localDeploymentUrl(args.cloudPort);
+  let timeElapsedSecs = 0;
+  let hasShownWaiting = false;
+  while (timeElapsedSecs <= args.maxTimeSecs) {
+    if (!hasShownWaiting && timeElapsedSecs > 2) {
+      logMessage(ctx, "waiting for local backend to start...");
+      hasShownWaiting = true;
+    }
+    try {
+      const resp = await fetch(`${deploymentUrl}/instance_name`);
+      if (resp.status === 200) {
+        const text = await resp.text();
+        if (text !== args.deploymentName) {
+          return await ctx.crash({
+            exitCode: 1,
+            errorType: "fatal",
+            printedMessage: `A different local backend ${text} is running on selected port ${args.cloudPort}`,
+          });
+        } else {
+          // The backend is running!
+          return;
+        }
+      } else {
+        await new Promise((resolve) => setTimeout(resolve, 500));
+        timeElapsedSecs += 0.5;
+      }
+    } catch {
+      await new Promise((resolve) => setTimeout(resolve, 500));
+      timeElapsedSecs += 0.5;
+    }
+  }
+  const message = `Local backend did not start on port ${args.cloudPort} within ${args.maxTimeSecs} seconds.`;
+  return await ctx.crash({
+    exitCode: 1,
+    errorType: "fatal",
+    printedMessage: message,
+    errForSentry: new LocalDeploymentError(message),
+  });
+}
+
+export async function ensureBackendStopped(
+  ctx: Context,
+  args: {
+    ports: {
+      cloud: number;
+      site?: number;
+    };
+    maxTimeSecs: number;
+    deploymentName: string;
+    // Whether to allow a deployment with a different name to run on this port
+    allowOtherDeployments: boolean;
+  },
+) {
+  logVerbose(
+    ctx,
+    `Ensuring backend running on port ${args.ports.cloud} is stopped`,
+  );
+  let timeElapsedSecs = 0;
+  while (timeElapsedSecs < args.maxTimeSecs) {
+    const cloudPort = await detect(args.ports.cloud);
+    const sitePort =
+      args.ports.site === undefined ? undefined : await detect(args.ports.site);
+    // Both ports are free
+    if (cloudPort === args.ports.cloud && sitePort === args.ports.site) {
+      return;
+    }
+    try {
+      const instanceNameResp = await fetch(
+        `${localDeploymentUrl(args.ports.cloud)}/instance_name`,
+      );
+      if (instanceNameResp.ok) {
+        const instanceName = await instanceNameResp.text();
+        if (instanceName !== args.deploymentName) {
+          if (args.allowOtherDeployments) {
+            return;
+          }
+          return await ctx.crash({
+            exitCode: 1,
+            errorType: "fatal",
+            printedMessage: `A different local backend ${instanceName} is running on selected port ${args.ports.cloud}`,
+          });
+        }
+      }
+    } catch (error: any) {
+      logVerbose(ctx, `Error checking if backend is running: ${error.message}`);
+      // Backend is probably not running
+      continue;
+    }
+    await new Promise((resolve) => setTimeout(resolve, 500));
+    timeElapsedSecs += 0.5;
+  }
+  return ctx.crash({
+    exitCode: 1,
+    errorType: "fatal",
+    printedMessage: `A local backend is still running on port ${args.ports.cloud}. Please stop it and run this command again.`,
+  });
+}
+
+export function localDeploymentUrl(cloudPort: number): string {
+  return `http://127.0.0.1:${cloudPort}`;
+}
+
+export function selfHostedEventTag(
+  deploymentKind: LocalDeploymentKind,
+): string {
+  return deploymentKind === "local" ? "cli-local-dev" : "cli-anonymous-dev";
+}
diff --git a/synced/convex/libs/cli/lib/localDeployment/serve.ts b/synced/convex/libs/cli/lib/localDeployment/serve.ts
new file mode 100644
index 0000000..2d7102f
--- /dev/null
+++ b/synced/convex/libs/cli/lib/localDeployment/serve.ts
@@ -0,0 +1,77 @@
+import http from "node:http";
+import { Context } from "../../../bundler/context.js";
+import { logVerbose } from "../../../bundler/context.js";
+
+// The below is adapted from https://github.com/vercel/serve/blob/main/source/utilities/server.ts
+// MIT License -- https://github.com/vercel/serve/blob/main/license.md
+// Copyright (c) 2023 Vercel, Inc.
+//
+// Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
+//
+// The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
+//
+// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+
+// This has been pared down to only support running locally. It removed options
+// we're not using, and added Convex-CLI specific cleanup handling.
+export const startServer = async (
+  ctx: Context,
+  port: number,
+  handler: (
+    request: http.IncomingMessage,
+    response: http.ServerResponse,
+  ) => Promise<void>,
+  options: {
+    cors?: boolean;
+  },
+): Promise<{ cleanupHandle: string }> => {
+  // Define the request handler for the server.
+  const serverHandler = (request: any, response: any): void => {
+    // We can't return a promise in a HTTP request handler, so we run our code
+    // inside an async function instead.
+    const run = async () => {
+      if (options.cors) {
+        response.setHeader("Access-Control-Allow-Origin", "*");
+        response.setHeader("Access-Control-Allow-Headers", "*");
+        response.setHeader("Access-Control-Allow-Credentials", "true");
+        response.setHeader("Access-Control-Allow-Private-Network", "true");
+      }
+      // TODO -- consider adding support for compression
+      // if (!args['--no-compression'])
+      //   await compress(request as ExpressRequest, response as ExpressResponse);
+
+      await handler(request, response);
+    };
+
+    // Then we run the async function, and log any errors.
+    // TODO: consider adding a `onError` callback in case we want different error
+    // handling.
+    run().catch((error: Error) => {
+      logVerbose(
+        ctx,
+        `Failed to serve: ${error.stack?.toString() ?? error.message}`,
+      );
+    });
+  };
+
+  const server = http.createServer(serverHandler);
+  const cleanupHandle = ctx.registerCleanup(async () => {
+    logVerbose(ctx, `Stopping server on port ${port}`);
+    await server.close();
+  });
+
+  // Listen for any error that occurs while serving, and throw an error
+  // if any errors are received.
+  server.on("error", (error) => {
+    logVerbose(
+      ctx,
+      `Failed to serve: ${error.stack?.toString() ?? error.message}`,
+    );
+  });
+
+  // Finally, start the server -- this promise resolves once the server has started.
+  await new Promise((resolve, _reject) => {
+    server.listen(port, `127.0.0.1`, () => resolve(`http://127.0.0.1:${port}`));
+  });
+  return { cleanupHandle };
+};
diff --git a/synced/convex/libs/cli/lib/localDeployment/upgrade.ts b/synced/convex/libs/cli/lib/localDeployment/upgrade.ts
new file mode 100644
index 0000000..f036abf
--- /dev/null
+++ b/synced/convex/libs/cli/lib/localDeployment/upgrade.ts
@@ -0,0 +1,341 @@
+import path from "path";
+import {
+  Context,
+  logFailure,
+  logFinishedStep,
+  logVerbose,
+} from "../../../bundler/context.js";
+import { runSystemQuery } from "../run.js";
+import {
+  LocalDeploymentKind,
+  deploymentStateDir,
+  loadDeploymentConfig,
+  saveDeploymentConfig,
+} from "./filePaths.js";
+import {
+  ensureBackendStopped,
+  localDeploymentUrl,
+  runLocalBackend,
+} from "./run.js";
+import {
+  downloadSnapshotExport,
+  startSnapshotExport,
+} from "../convexExport.js";
+import { deploymentFetch, logAndHandleFetchError } from "../utils/utils.js";
+import {
+  confirmImport,
+  uploadForImport,
+  waitForStableImportState,
+} from "../convexImport.js";
+import { promptOptions, promptYesNo } from "../utils/prompts.js";
+import { recursivelyDelete } from "../fsUtils.js";
+import { LocalDeploymentError } from "./errors.js";
+import { ensureBackendBinaryDownloaded } from "./download.js";
+export async function handlePotentialUpgrade(
+  ctx: Context,
+  args: {
+    deploymentKind: LocalDeploymentKind;
+    deploymentName: string;
+    oldVersion: string | null;
+    newBinaryPath: string;
+    newVersion: string;
+    ports: {
+      cloud: number;
+      site: number;
+    };
+    adminKey: string;
+    instanceSecret: string;
+    forceUpgrade: boolean;
+  },
+): Promise<{ cleanupHandle: string }> {
+  const newConfig = {
+    ports: args.ports,
+    backendVersion: args.newVersion,
+    adminKey: args.adminKey,
+    instanceSecret: args.instanceSecret,
+  };
+  if (args.oldVersion === null || args.oldVersion === args.newVersion) {
+    // No upgrade needed. Save the current config and start running the backend.
+    saveDeploymentConfig(
+      ctx,
+      args.deploymentKind,
+      args.deploymentName,
+      newConfig,
+    );
+    return runLocalBackend(ctx, {
+      binaryPath: args.newBinaryPath,
+      deploymentKind: args.deploymentKind,
+      deploymentName: args.deploymentName,
+      ports: args.ports,
+      instanceSecret: args.instanceSecret,
+      isLatestVersion: true,
+    });
+  }
+  logVerbose(
+    ctx,
+    `Considering upgrade from ${args.oldVersion} to ${args.newVersion}`,
+  );
+  const confirmed =
+    args.forceUpgrade ||
+    (await promptYesNo(ctx, {
+      message: `This deployment is using an older version of the Convex backend. Upgrade now?`,
+      default: true,
+    }));
+  if (!confirmed) {
+    const { binaryPath: oldBinaryPath } = await ensureBackendBinaryDownloaded(
+      ctx,
+      {
+        kind: "version",
+        version: args.oldVersion,
+      },
+    );
+    // Skipping upgrade, save the config with the old version and run.
+    saveDeploymentConfig(ctx, args.deploymentKind, args.deploymentName, {
+      ...newConfig,
+      backendVersion: args.oldVersion,
+    });
+    return runLocalBackend(ctx, {
+      binaryPath: oldBinaryPath,
+      ports: args.ports,
+      deploymentKind: args.deploymentKind,
+      deploymentName: args.deploymentName,
+      instanceSecret: args.instanceSecret,
+      isLatestVersion: false,
+    });
+  }
+  const choice = args.forceUpgrade
+    ? "transfer"
+    : await promptOptions(ctx, {
+        message: "Transfer data from existing deployment?",
+        default: "transfer",
+        choices: [
+          { name: "transfer data", value: "transfer" },
+          { name: "start fresh", value: "reset" },
+        ],
+      });
+  const deploymentStatePath = deploymentStateDir(
+    args.deploymentKind,
+    args.deploymentName,
+  );
+  if (choice === "reset") {
+    recursivelyDelete(ctx, deploymentStatePath, { force: true });
+    saveDeploymentConfig(
+      ctx,
+      args.deploymentKind,
+      args.deploymentName,
+      newConfig,
+    );
+    return runLocalBackend(ctx, {
+      binaryPath: args.newBinaryPath,
+      deploymentKind: args.deploymentKind,
+      deploymentName: args.deploymentName,
+      ports: args.ports,
+      instanceSecret: args.instanceSecret,
+      isLatestVersion: true,
+    });
+  }
+  const newAdminKey = args.adminKey;
+  const oldAdminKey =
+    loadDeploymentConfig(ctx, args.deploymentKind, args.deploymentName)
+      ?.adminKey ?? args.adminKey;
+  return handleUpgrade(ctx, {
+    deploymentKind: args.deploymentKind,
+    deploymentName: args.deploymentName,
+    oldVersion: args.oldVersion!,
+    newBinaryPath: args.newBinaryPath,
+    newVersion: args.newVersion,
+    ports: args.ports,
+    oldAdminKey,
+    newAdminKey,
+    instanceSecret: args.instanceSecret,
+  });
+}
+
+async function handleUpgrade(
+  ctx: Context,
+  args: {
+    deploymentName: string;
+    deploymentKind: LocalDeploymentKind;
+    oldVersion: string;
+    newBinaryPath: string;
+    newVersion: string;
+    ports: {
+      cloud: number;
+      site: number;
+    };
+    // In most of the cases the admin key is the same for the old and new version.
+    // This is helpful when we start generating new admin key formats that might
+    // be incompatible with older backend versions.
+    oldAdminKey: string;
+    newAdminKey: string;
+    instanceSecret: string;
+  },
+): Promise<{ cleanupHandle: string }> {
+  const { binaryPath: oldBinaryPath } = await ensureBackendBinaryDownloaded(
+    ctx,
+    {
+      kind: "version",
+      version: args.oldVersion,
+    },
+  );
+
+  logVerbose(ctx, "Running backend on old version");
+  const { cleanupHandle: oldCleanupHandle } = await runLocalBackend(ctx, {
+    binaryPath: oldBinaryPath,
+    ports: args.ports,
+    deploymentKind: args.deploymentKind,
+    deploymentName: args.deploymentName,
+    instanceSecret: args.instanceSecret,
+    isLatestVersion: false,
+  });
+
+  logVerbose(ctx, "Downloading env vars");
+  const deploymentUrl = localDeploymentUrl(args.ports.cloud);
+  const envs = (await runSystemQuery(ctx, {
+    deploymentUrl,
+    adminKey: args.oldAdminKey,
+    functionName: "_system/cli/queryEnvironmentVariables",
+    componentPath: undefined,
+    args: {},
+  })) as Array<{
+    name: string;
+    value: string;
+  }>;
+
+  logVerbose(ctx, "Doing a snapshot export");
+  const exportPath = path.join(
+    deploymentStateDir(args.deploymentKind, args.deploymentName),
+    "export.zip",
+  );
+  if (ctx.fs.exists(exportPath)) {
+    ctx.fs.unlink(exportPath);
+  }
+  const snaphsotExportState = await startSnapshotExport(ctx, {
+    deploymentUrl,
+    adminKey: args.oldAdminKey,
+    includeStorage: true,
+    inputPath: exportPath,
+  });
+  if (snaphsotExportState.state !== "completed") {
+    return ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: "Failed to export snapshot",
+    });
+  }
+  await downloadSnapshotExport(ctx, {
+    snapshotExportTs: snaphsotExportState.start_ts,
+    inputPath: exportPath,
+    adminKey: args.oldAdminKey,
+    deploymentUrl,
+  });
+
+  logVerbose(ctx, "Stopping the backend on the old version");
+  const oldCleanupFunc = ctx.removeCleanup(oldCleanupHandle);
+  if (oldCleanupFunc) {
+    await oldCleanupFunc(0);
+  }
+  await ensureBackendStopped(ctx, {
+    ports: args.ports,
+    maxTimeSecs: 5,
+    deploymentName: args.deploymentName,
+    allowOtherDeployments: false,
+  });
+
+  // TODO(ENG-7078) save old artifacts to backup files
+  logVerbose(ctx, "Running backend on new version");
+  const { cleanupHandle } = await runLocalBackend(ctx, {
+    binaryPath: args.newBinaryPath,
+    ports: args.ports,
+    deploymentKind: args.deploymentKind,
+    deploymentName: args.deploymentName,
+    instanceSecret: args.instanceSecret,
+    isLatestVersion: true,
+  });
+
+  logVerbose(ctx, "Importing the env vars");
+  if (envs.length > 0) {
+    const fetch = deploymentFetch(ctx, {
+      deploymentUrl,
+      adminKey: args.newAdminKey,
+    });
+    try {
+      await fetch("/api/update_environment_variables", {
+        body: JSON.stringify({ changes: envs }),
+        method: "POST",
+      });
+    } catch (e) {
+      // TODO: this should ideally have a `LocalDeploymentError`
+      return await logAndHandleFetchError(ctx, e);
+    }
+  }
+
+  logVerbose(ctx, "Doing a snapshot import");
+  const importId = await uploadForImport(ctx, {
+    deploymentUrl,
+    adminKey: args.newAdminKey,
+    filePath: exportPath,
+    importArgs: { format: "zip", mode: "replace", tableName: undefined },
+    onImportFailed: async (e) => {
+      logFailure(ctx, `Failed to import snapshot: ${e}`);
+    },
+  });
+  logVerbose(ctx, `Snapshot import started`);
+  let status = await waitForStableImportState(ctx, {
+    importId,
+    deploymentUrl,
+    adminKey: args.newAdminKey,
+    onProgress: () => {
+      // do nothing for now
+      return 0;
+    },
+  });
+  if (status.state !== "waiting_for_confirmation") {
+    const message = "Error while transferring data: Failed to upload snapshot";
+    return ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: message,
+      errForSentry: new LocalDeploymentError(message),
+    });
+  }
+
+  await confirmImport(ctx, {
+    importId,
+    adminKey: args.newAdminKey,
+    deploymentUrl,
+    onError: async (e) => {
+      logFailure(ctx, `Failed to confirm import: ${e}`);
+    },
+  });
+  logVerbose(ctx, `Snapshot import confirmed`);
+  status = await waitForStableImportState(ctx, {
+    importId,
+    deploymentUrl,
+    adminKey: args.newAdminKey,
+    onProgress: () => {
+      // do nothing for now
+      return 0;
+    },
+  });
+  logVerbose(ctx, `Snapshot import status: ${status.state}`);
+  if (status.state !== "completed") {
+    const message = "Error while transferring data: Failed to import snapshot";
+    return ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: message,
+      errForSentry: new LocalDeploymentError(message),
+    });
+  }
+
+  logFinishedStep(ctx, "Successfully upgraded to a new backend version");
+  saveDeploymentConfig(ctx, args.deploymentKind, args.deploymentName, {
+    ports: args.ports,
+    backendVersion: args.newVersion,
+    adminKey: args.newAdminKey,
+    instanceSecret: args.instanceSecret,
+  });
+
+  return { cleanupHandle };
+}
diff --git a/synced/convex/libs/cli/lib/localDeployment/utils.ts b/synced/convex/libs/cli/lib/localDeployment/utils.ts
new file mode 100644
index 0000000..6d00574
--- /dev/null
+++ b/synced/convex/libs/cli/lib/localDeployment/utils.ts
@@ -0,0 +1,70 @@
+import { Context, logMessage } from "../../../bundler/context.js";
+import { detect } from "detect-port";
+import crypto from "crypto";
+import chalk from "chalk";
+
+export async function choosePorts(
+  ctx: Context,
+  {
+    count,
+    requestedPorts,
+    startPort,
+  }: {
+    count: number;
+    requestedPorts?: Array<number | null>;
+    startPort: number;
+  },
+): Promise<Array<number>> {
+  const ports: Array<number> = [];
+  for (let i = 0; i < count; i++) {
+    const requestedPort = requestedPorts?.[i];
+    if (requestedPort !== null) {
+      const port = await detect(requestedPort);
+      if (port !== requestedPort) {
+        return ctx.crash({
+          exitCode: 1,
+          errorType: "fatal",
+          printedMessage: "Requested port is not available",
+        });
+      }
+      ports.push(port);
+    } else {
+      const portToTry =
+        ports.length > 0 ? ports[ports.length - 1] + 1 : startPort;
+      const port = await detect(portToTry);
+      ports.push(port);
+    }
+  }
+  return ports;
+}
+
+export async function isOffline(): Promise<boolean> {
+  // TODO(ENG-7080) -- implement this for real
+  return false;
+}
+
+export function printLocalDeploymentWelcomeMessage(ctx: Context) {
+  logMessage(
+    ctx,
+    chalk.cyan("You're trying out the beta local deployment feature!"),
+  );
+  logMessage(
+    ctx,
+    chalk.cyan(
+      "To learn more, read the docs: https://docs.convex.dev/cli/local-deployments",
+    ),
+  );
+  logMessage(
+    ctx,
+    chalk.cyan(
+      "To opt out at any time, run `npx convex disable-local-deployments`",
+    ),
+  );
+}
+
+export function generateInstanceSecret(): string {
+  return crypto.randomBytes(32).toString("hex");
+}
+
+export const LOCAL_BACKEND_INSTANCE_SECRET =
+  "4361726e697461732c206c69746572616c6c79206d65616e696e6720226c6974";
diff --git a/synced/convex/libs/cli/lib/login.ts b/synced/convex/libs/cli/lib/login.ts
new file mode 100644
index 0000000..3548237
--- /dev/null
+++ b/synced/convex/libs/cli/lib/login.ts
@@ -0,0 +1,524 @@
+import { errors, BaseClient, custom } from "openid-client";
+import {
+  bigBrainAPI,
+  logAndHandleFetchError,
+  throwingFetch,
+  isWebContainer,
+} from "./utils/utils.js";
+import open from "open";
+import chalk from "chalk";
+import { provisionHost } from "./config.js";
+import { version } from "../version.js";
+import {
+  Context,
+  changeSpinner,
+  logError,
+  logFailure,
+  logFinishedStep,
+  logMessage,
+  logOutput,
+  logVerbose,
+  showSpinner,
+} from "../../bundler/context.js";
+import { Issuer } from "openid-client";
+import { hostname } from "os";
+import { execSync } from "child_process";
+import { promptString, promptYesNo } from "./utils/prompts.js";
+import {
+  formatPathForPrinting,
+  globalConfigPath,
+  modifyGlobalConfig,
+} from "./utils/globalConfig.js";
+import { updateBigBrainAuthAfterLogin } from "./deploymentSelection.js";
+
+const SCOPE = "openid email profile";
+/// This value was created long ago, and cannot be changed easily.
+/// It's just a fixed string used for identifying the Auth0 token, so it's fine
+/// and not user-facing.
+const AUDIENCE = "https://console.convex.dev/api/";
+
+// Per https://github.com/panva/node-openid-client/tree/main/docs#customizing
+custom.setHttpOptionsDefaults({
+  timeout: parseInt(process.env.OPENID_CLIENT_TIMEOUT || "10000"),
+});
+
+interface AuthorizeArgs {
+  authnToken: string;
+  deviceName: string;
+  anonymousId?: string;
+}
+
+export async function checkAuthorization(
+  ctx: Context,
+  acceptOptIns: boolean,
+): Promise<boolean> {
+  const header = ctx.bigBrainAuth()?.header ?? null;
+  if (header === null) {
+    return false;
+  }
+  try {
+    const resp = await fetch(`${provisionHost}/api/authorize`, {
+      method: "HEAD",
+      headers: {
+        Authorization: header,
+        "Convex-Client": `npm-cli-${version}`,
+      },
+    });
+    // Don't throw an error if this request returns a non-200 status.
+    // Big Brain responds with a variety of error codes -- 401 if the token is correctly-formed but not valid, and either 400 or 500 if the token is ill-formed.
+    // We only care if this check returns a 200 code (so we can skip logging in again) -- any other errors should be silently skipped and we'll run the whole login flow again.
+    if (resp.status !== 200) {
+      return false;
+    }
+  } catch (e: any) {
+    // This `catch` block should only be hit if a network error was encountered
+    logError(
+      ctx,
+      `Unexpected error when authorizing - are you connected to the internet?`,
+    );
+    return await logAndHandleFetchError(ctx, e);
+  }
+
+  // Check that we have optin as well
+  const shouldContinue = await optins(ctx, acceptOptIns);
+  if (!shouldContinue) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: null,
+    });
+  }
+  return true;
+}
+
+async function performDeviceAuthorization(
+  ctx: Context,
+  auth0Client: BaseClient,
+  shouldOpen: boolean,
+): Promise<string> {
+  // Device authorization flow follows this guide: https://github.com/auth0/auth0-device-flow-cli-sample/blob/9f0f3b76a6cd56ea8d99e76769187ea5102d519d/cli.js
+  // License: MIT License
+  // Copyright (c) 2019 Auth0 Samples
+  /*
+  The MIT License (MIT)
+
+  Copyright (c) 2019 Auth0 Samples
+
+  Permission is hereby granted, free of charge, to any person obtaining a copy
+  of this software and associated documentation files (the "Software"), to deal
+  in the Software without restriction, including without limitation the rights
+  to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+  copies of the Software, and to permit persons to whom the Software is
+  furnished to do so, subject to the following conditions:
+
+  The above copyright notice and this permission notice shall be included in all
+  copies or substantial portions of the Software.
+
+  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+  OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+  SOFTWARE.
+  */
+
+  // Device Authorization Request - https://tools.ietf.org/html/rfc8628#section-3.1
+  // Get authentication URL
+  let handle;
+  try {
+    handle = await auth0Client.deviceAuthorization({
+      scope: SCOPE,
+      audience: AUDIENCE,
+    });
+  } catch {
+    // We couldn't get verification URL from Auth0, proceed with manual auth
+    return promptString(ctx, {
+      message:
+        "Open https://dashboard.convex.dev/auth, log in and paste the token here:",
+    });
+  }
+
+  // Device Authorization Response - https://tools.ietf.org/html/rfc8628#section-3.2
+  // Open authentication URL
+  const { verification_uri_complete, user_code, expires_in } = handle;
+  logMessage(
+    ctx,
+    `Visit ${verification_uri_complete} to finish logging in.\n` +
+      `You should see the following code which expires in ${
+        expires_in % 60 === 0
+          ? `${expires_in / 60} minutes`
+          : `${expires_in} seconds`
+      }: ${user_code}`,
+  );
+  if (shouldOpen) {
+    shouldOpen = await promptYesNo(ctx, {
+      message: `Open the browser?`,
+      default: true,
+    });
+  }
+
+  if (shouldOpen) {
+    showSpinner(
+      ctx,
+      `Opening ${verification_uri_complete} in your browser to log in...\n`,
+    );
+    try {
+      const p = await open(verification_uri_complete);
+      p.once("error", () => {
+        changeSpinner(
+          ctx,
+          `Manually open ${verification_uri_complete} in your browser to log in.`,
+        );
+      });
+      changeSpinner(ctx, "Waiting for the confirmation...");
+    } catch {
+      logError(ctx, chalk.red(`Unable to open browser.`));
+      changeSpinner(
+        ctx,
+        `Manually open ${verification_uri_complete} in your browser to log in.`,
+      );
+    }
+  } else {
+    showSpinner(
+      ctx,
+      `Open ${verification_uri_complete} in your browser to log in.`,
+    );
+  }
+
+  // Device Access Token Request - https://tools.ietf.org/html/rfc8628#section-3.4
+  // Device Access Token Response - https://tools.ietf.org/html/rfc8628#section-3.5
+  try {
+    const tokens = await handle.poll();
+    if (typeof tokens.access_token === "string") {
+      return tokens.access_token;
+    } else {
+      // Unexpected error
+      // eslint-disable-next-line no-restricted-syntax
+      throw Error("Access token is missing");
+    }
+  } catch (err: any) {
+    switch (err.error) {
+      case "access_denied": // end-user declined the device confirmation prompt, consent or rules failed
+        return await ctx.crash({
+          exitCode: 1,
+          errorType: "fatal",
+          printedMessage: "Access denied.",
+          errForSentry: err,
+        });
+      case "expired_token": // end-user did not complete the interaction in time
+        return await ctx.crash({
+          exitCode: 1,
+          errorType: "fatal",
+          printedMessage: "Device flow expired.",
+          errForSentry: err,
+        });
+      default: {
+        const message =
+          err instanceof errors.OPError
+            ? `Error = ${err.error}; error_description = ${err.error_description}`
+            : `Login failed with error: ${err}`;
+        return await ctx.crash({
+          exitCode: 1,
+          errorType: "fatal",
+          printedMessage: message,
+          errForSentry: err,
+        });
+      }
+    }
+  }
+}
+
+async function performPasswordAuthentication(
+  ctx: Context,
+  issuer: string,
+  clientId: string,
+  username: string,
+  password: string,
+): Promise<string> {
+  // Unfortunately, `openid-client` doesn't support the resource owner password credentials flow so we need to manually send the requests.
+  const options: Parameters<typeof throwingFetch>[1] = {
+    method: "POST",
+    headers: { "Content-Type": "application/x-www-form-urlencoded" },
+    body: new URLSearchParams({
+      grant_type: "password",
+      username: username,
+      password: password,
+      scope: SCOPE,
+      client_id: clientId,
+      audience: AUDIENCE,
+      // Note that there is no client secret provided, as Auth0 refuses to require it for untrusted apps.
+    }),
+  };
+
+  try {
+    const response = await throwingFetch(
+      new URL("/oauth/token", issuer).href,
+      options,
+    );
+    const data = await response.json();
+    if (typeof data.access_token === "string") {
+      return data.access_token;
+    } else {
+      // Unexpected error
+      // eslint-disable-next-line no-restricted-syntax
+      throw Error("Access token is missing");
+    }
+  } catch (err: any) {
+    logFailure(ctx, `Password flow failed: ${err}`);
+    if (err.response) {
+      logError(ctx, chalk.red(`${JSON.stringify(err.response.data)}`));
+    }
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      errForSentry: err,
+      printedMessage: null,
+    });
+  }
+}
+
+export async function performLogin(
+  ctx: Context,
+  {
+    overrideAuthUrl,
+    overrideAuthClient,
+    overrideAuthUsername,
+    overrideAuthPassword,
+    overrideAccessToken,
+    loginFlow,
+    open,
+    acceptOptIns,
+    dumpAccessToken,
+    deviceName: deviceNameOverride,
+    anonymousId,
+  }: {
+    overrideAuthUrl?: string;
+    overrideAuthClient?: string;
+    overrideAuthUsername?: string;
+    overrideAuthPassword?: string;
+    overrideAccessToken?: string;
+    loginFlow?: "auto" | "paste" | "poll";
+    // default `true`
+    open?: boolean;
+    // default `false`
+    acceptOptIns?: boolean;
+    dumpAccessToken?: boolean;
+    deviceName?: string;
+    anonymousId?: string;
+  } = {},
+) {
+  loginFlow = loginFlow || "auto";
+  // Get access token from big-brain
+  // Default the device name to the hostname, but allow the user to change this if the terminal is interactive.
+  // On Macs, the `hostname()` may be a weirdly-truncated form of the computer name. Attempt to read the "real" name before falling back to hostname.
+  let deviceName = deviceNameOverride ?? "";
+  if (!deviceName && process.platform === "darwin") {
+    try {
+      deviceName = execSync("scutil --get ComputerName").toString().trim();
+    } catch {
+      // Just fall back to the hostname default below.
+    }
+  }
+  if (!deviceName) {
+    deviceName = hostname();
+  }
+  if (!deviceNameOverride) {
+    logMessage(
+      ctx,
+      chalk.bold(`Welcome to developing with Convex, let's get you logged in.`),
+    );
+    deviceName = await promptString(ctx, {
+      message: "Device name:",
+      default: deviceName,
+    });
+  }
+
+  const issuer = overrideAuthUrl ?? "https://auth.convex.dev";
+  let auth0;
+  let accessToken: string;
+
+  if (loginFlow === "paste" || (loginFlow === "auto" && isWebContainer())) {
+    accessToken = await promptString(ctx, {
+      message:
+        "Open https://dashboard.convex.dev/auth, log in and paste the token here:",
+    });
+  } else {
+    try {
+      auth0 = await Issuer.discover(issuer);
+    } catch {
+      // Couldn't contact https://auth.convex.dev/.well-known/openid-configuration,
+      // proceed with manual auth.
+      accessToken = await promptString(ctx, {
+        message:
+          "Open https://dashboard.convex.dev/auth, log in and paste the token here:",
+      });
+    }
+  }
+
+  // typical path
+  if (auth0) {
+    const clientId = overrideAuthClient ?? "HFtA247jp9iNs08NTLIB7JsNPMmRIyfi";
+    const auth0Client = new auth0.Client({
+      client_id: clientId,
+      token_endpoint_auth_method: "none",
+      id_token_signed_response_alg: "RS256",
+    });
+
+    if (overrideAccessToken) {
+      accessToken = overrideAccessToken;
+    } else if (overrideAuthUsername && overrideAuthPassword) {
+      accessToken = await performPasswordAuthentication(
+        ctx,
+        issuer,
+        clientId,
+        overrideAuthUsername,
+        overrideAuthPassword,
+      );
+    } else {
+      accessToken = await performDeviceAuthorization(
+        ctx,
+        auth0Client,
+        open ?? true,
+      );
+    }
+  }
+
+  if (dumpAccessToken) {
+    logOutput(ctx, `${accessToken!}`);
+    return await ctx.crash({
+      exitCode: 0,
+      errorType: "fatal",
+      printedMessage: null,
+    });
+  }
+
+  const authorizeArgs: AuthorizeArgs = {
+    authnToken: accessToken!,
+    deviceName: deviceName,
+    anonymousId: anonymousId,
+  };
+  const data = await bigBrainAPI({
+    ctx,
+    method: "POST",
+    url: "authorize",
+    data: authorizeArgs,
+  });
+  const globalConfig = { accessToken: data.accessToken };
+  try {
+    await modifyGlobalConfig(ctx, globalConfig);
+    const path = globalConfigPath();
+    logFinishedStep(ctx, `Saved credentials to ${formatPathForPrinting(path)}`);
+  } catch (err: unknown) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "invalid filesystem data",
+      errForSentry: err,
+      printedMessage: null,
+    });
+  }
+
+  logVerbose(ctx, `performLogin: updating big brain auth after login`);
+  await updateBigBrainAuthAfterLogin(ctx, data.accessToken);
+
+  logVerbose(
+    ctx,
+    `performLogin: checking opt ins, acceptOptIns: ${acceptOptIns}`,
+  );
+  // Do opt in to TOS and Privacy Policy stuff
+  const shouldContinue = await optins(ctx, acceptOptIns ?? false);
+  if (!shouldContinue) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: null,
+    });
+  }
+}
+
+/// There are fields like version, but we keep them opaque
+type OptIn = Record<string, unknown>;
+
+type OptInToAccept = {
+  optIn: OptIn;
+  message: string;
+};
+
+type AcceptOptInsArgs = {
+  optInsAccepted: OptIn[];
+};
+
+// Returns whether we can proceed or not.
+async function optins(ctx: Context, acceptOptIns: boolean): Promise<boolean> {
+  const bbAuth = ctx.bigBrainAuth();
+  if (bbAuth === null) {
+    // This should never happen, but if we're not even logged in, we can't proceed.
+    return false;
+  }
+  switch (bbAuth.kind) {
+    case "accessToken":
+      break;
+    case "projectKey":
+    case "previewDeployKey":
+      // If we have a key configured as auth, we do not need to check opt ins.
+      return true;
+    default: {
+      const _exhaustivenessCheck: never = bbAuth;
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        errForSentry: `Unexpected auth kind ${(bbAuth as any).kind}`,
+        printedMessage: "Hit an unexpected error while logging in.",
+      });
+    }
+  }
+  const data = await bigBrainAPI({
+    ctx,
+    method: "POST",
+    url: "check_opt_ins",
+  });
+  if (data.optInsToAccept.length === 0) {
+    return true;
+  }
+  for (const optInToAccept of data.optInsToAccept) {
+    const confirmed =
+      acceptOptIns ||
+      (await promptYesNo(ctx, {
+        message: optInToAccept.message,
+      }));
+    if (!confirmed) {
+      logFailure(ctx, "Please accept the Terms of Service to use Convex.");
+      return Promise.resolve(false);
+    }
+  }
+
+  const optInsAccepted = data.optInsToAccept.map((o: OptInToAccept) => o.optIn);
+  const args: AcceptOptInsArgs = { optInsAccepted };
+  await bigBrainAPI({ ctx, method: "POST", url: "accept_opt_ins", data: args });
+  return true;
+}
+
+export async function ensureLoggedIn(
+  ctx: Context,
+  options?: {
+    message?: string;
+    overrideAuthUrl?: string;
+    overrideAuthClient?: string;
+    overrideAuthUsername?: string;
+    overrideAuthPassword?: string;
+  },
+) {
+  const isLoggedIn = await checkAuthorization(ctx, false);
+  if (!isLoggedIn) {
+    if (options?.message) {
+      logMessage(ctx, options.message);
+    }
+    await performLogin(ctx, {
+      acceptOptIns: false,
+      overrideAuthUrl: options?.overrideAuthUrl,
+      overrideAuthClient: options?.overrideAuthClient,
+      overrideAuthUsername: options?.overrideAuthUsername,
+      overrideAuthPassword: options?.overrideAuthPassword,
+    });
+  }
+}
diff --git a/synced/convex/libs/cli/lib/logs.ts b/synced/convex/libs/cli/lib/logs.ts
new file mode 100644
index 0000000..b781b2f
--- /dev/null
+++ b/synced/convex/libs/cli/lib/logs.ts
@@ -0,0 +1,302 @@
+import {
+  Context,
+  logMessage,
+  logOutput,
+  logWarning,
+} from "../../bundler/context.js";
+import { nextBackoff } from "./dev.js";
+import chalk from "chalk";
+import { deploymentFetch } from "./utils/utils.js";
+
+export type LogMode = "always" | "pause-on-deploy" | "disable";
+
+export class LogManager {
+  private paused: boolean = false;
+
+  constructor(private mode: LogMode) {}
+
+  async waitForUnpaused() {
+    while (this.paused) {
+      await new Promise((resolve) => setTimeout(resolve, 100));
+    }
+  }
+
+  beginDeploy() {
+    if (this.mode === "pause-on-deploy") {
+      this.paused = true;
+    }
+  }
+
+  endDeploy() {
+    if (this.mode === "pause-on-deploy") {
+      this.paused = false;
+    }
+  }
+}
+
+const MAX_UDF_STREAM_FAILURE_COUNT = 5;
+
+type LogDestination = "stdout" | "stderr";
+
+export async function logsForDeployment(
+  ctx: Context,
+  credentials: {
+    url: string;
+    adminKey: string;
+  },
+  options: {
+    success: boolean;
+    history: number;
+    deploymentNotice: string;
+  },
+) {
+  logMessage(ctx, chalk.yellow(`Watching logs${options.deploymentNotice}...`));
+  await watchLogs(ctx, credentials.url, credentials.adminKey, "stdout", {
+    history: options.history,
+    success: options.success,
+  });
+}
+
+export async function watchLogs(
+  ctx: Context,
+  url: string,
+  adminKey: string,
+  dest: LogDestination,
+  options?: {
+    success: boolean;
+    history?: number | boolean;
+    logManager?: LogManager;
+  },
+) {
+  let numFailures = 0;
+  let isFirst = true;
+  let cursorMs = 0;
+
+  for (;;) {
+    try {
+      const { entries, newCursor } = await pollUdfLog(
+        ctx,
+        cursorMs,
+        url,
+        adminKey,
+      );
+      cursorMs = newCursor;
+      numFailures = 0;
+
+      // Delay printing logs until the log manager is unpaused.
+      await options?.logManager?.waitForUnpaused();
+
+      // The first execution, we just want to fetch the current head cursor so we don't send stale
+      // logs to the client.
+      if (isFirst) {
+        isFirst = false;
+        if (
+          options?.history === true ||
+          (typeof options?.history === "number" && options?.history > 0)
+        ) {
+          const entriesSlice =
+            options?.history === true
+              ? entries
+              : entries.slice(entries.length - options?.history);
+          processLogs(ctx, entriesSlice, dest, options?.success);
+        }
+      } else {
+        processLogs(ctx, entries, dest, options?.success === true);
+      }
+    } catch {
+      numFailures += 1;
+    }
+    // Handle backoff
+    if (numFailures > 0) {
+      const backoff = nextBackoff(numFailures);
+
+      // If we exceed a threshold number of failures, warn the user and display backoff.
+      if (numFailures > MAX_UDF_STREAM_FAILURE_COUNT) {
+        logWarning(
+          ctx,
+          `Convex [WARN] Failed to fetch logs. Waiting ${backoff}ms before next retry.`,
+        );
+      }
+      await new Promise((resolve) => {
+        setTimeout(() => resolve(null), backoff);
+      });
+    }
+  }
+}
+
+type UdfType = "Query" | "Mutation" | "Action" | "HttpAction";
+
+type StructuredLogLine = {
+  messages: string[];
+  level: "LOG" | "DEBUG" | "INFO" | "WARN" | "ERROR";
+  timestamp: number;
+  isTruncated: boolean;
+};
+type LogLine = string | StructuredLogLine;
+
+type UdfExecutionResponse = {
+  identifier: string;
+  udfType: UdfType;
+  logLines: LogLine[];
+  // Unix timestamp (in seconds)
+  timestamp: number;
+  // UDF execution duration (in seconds)
+  executionTime: number;
+  error: string | null;
+  kind: "Completion" | "Progress";
+};
+
+async function pollUdfLog(
+  ctx: Context,
+  cursor: number,
+  url: string,
+  adminKey: string,
+): Promise<{ entries: UdfExecutionResponse[]; newCursor: number }> {
+  const fetch = deploymentFetch(ctx, {
+    deploymentUrl: url,
+    adminKey,
+  });
+  const response = await fetch(`/api/stream_function_logs?cursor=${cursor}`, {
+    method: "GET",
+  });
+  return await response.json();
+}
+
+const prefixForSource = (udfType: UdfType): string => {
+  return udfType.charAt(0);
+};
+
+function processLogs(
+  ctx: Context,
+  rawLogs: UdfExecutionResponse[],
+  dest: LogDestination,
+  shouldShowSuccessLogs: boolean,
+) {
+  for (let i = 0; i < rawLogs.length; i++) {
+    const log = rawLogs[i];
+    if (log.logLines) {
+      const id = log.identifier;
+      const udfType = log.udfType;
+      const timestampMs = log.timestamp * 1000;
+      const executionTimeMs = log.executionTime * 1000;
+
+      for (let j = 0; j < log.logLines.length; j++) {
+        logToTerminal(
+          ctx,
+          "info",
+          timestampMs,
+          udfType,
+          id,
+          log.logLines[j],
+          dest,
+        );
+      }
+
+      if (log.error) {
+        logToTerminal(ctx, "error", timestampMs, udfType, id, log.error!, dest);
+      } else if (log.kind === "Completion" && shouldShowSuccessLogs) {
+        logFunctionExecution(
+          ctx,
+          timestampMs,
+          log.udfType,
+          id,
+          executionTimeMs,
+          dest,
+        );
+      }
+    }
+  }
+}
+
+function logFunctionExecution(
+  ctx: Context,
+  timestampMs: number,
+  udfType: UdfType,
+  udfPath: string,
+  executionTimeMs: number,
+  dest: LogDestination,
+) {
+  logToDestination(
+    ctx,
+    dest,
+    chalk.green(
+      `${prefixLog(
+        timestampMs,
+        udfType,
+        udfPath,
+      )} Function executed in ${Math.ceil(executionTimeMs)} ms`,
+    ),
+  );
+}
+
+function logToTerminal(
+  ctx: Context,
+  type: "info" | "error",
+  timestampMs: number,
+  udfType: UdfType,
+  udfPath: string,
+  message: LogLine,
+  dest: LogDestination,
+) {
+  const prefix = prefixForSource(udfType);
+  if (typeof message === "string") {
+    if (type === "info") {
+      const match = message.match(/^\[.*?\] /);
+      if (match === null) {
+        logToDestination(
+          ctx,
+          dest,
+          chalk.red(
+            `[CONVEX ${prefix}(${udfPath})] Could not parse console.log`,
+          ),
+        );
+        return;
+      }
+      const level = message.slice(1, match[0].length - 2);
+      const args = message.slice(match[0].length);
+
+      logToDestination(
+        ctx,
+        dest,
+        chalk.cyan(`${prefixLog(timestampMs, udfType, udfPath)} [${level}]`),
+        args,
+      );
+    } else {
+      logToDestination(
+        ctx,
+        dest,
+        chalk.red(`${prefixLog(timestampMs, udfType, udfPath)} ${message}`),
+      );
+    }
+  } else {
+    const level = message.level;
+    const formattedMessage = `${message.messages.join(" ")}${message.isTruncated ? " (truncated due to length)" : ""}`;
+    logToDestination(
+      ctx,
+      dest,
+      chalk.cyan(
+        // timestamp is in ms since epoch
+        `${prefixLog(message.timestamp, udfType, udfPath)} [${level}]`,
+      ),
+      formattedMessage,
+    );
+  }
+}
+
+function logToDestination(ctx: Context, dest: LogDestination, ...logged: any) {
+  switch (dest) {
+    case "stdout":
+      logOutput(ctx, ...logged);
+      break;
+    case "stderr":
+      logMessage(ctx, ...logged);
+      break;
+  }
+}
+
+function prefixLog(timestampMs: number, udfType: UdfType, udfPath: string) {
+  const prefix = prefixForSource(udfType);
+  const localizedTimestamp = new Date(timestampMs).toLocaleString();
+
+  return `${localizedTimestamp} [CONVEX ${prefix}(${udfPath})]`;
+}
diff --git a/synced/convex/libs/cli/lib/mcp/requestContext.ts b/synced/convex/libs/cli/lib/mcp/requestContext.ts
new file mode 100644
index 0000000..ff2b8cb
--- /dev/null
+++ b/synced/convex/libs/cli/lib/mcp/requestContext.ts
@@ -0,0 +1,124 @@
+import { BigBrainAuth, Context, ErrorType } from "../../../bundler/context.js";
+import { Filesystem, nodeFs } from "../../../bundler/fs.js";
+import { Ora } from "ora";
+import {
+  DeploymentSelectionWithinProject,
+  deploymentSelectionWithinProjectSchema,
+  DeploymentSelectionOptions,
+} from "../api.js";
+import { z } from "zod";
+
+export interface McpOptions extends DeploymentSelectionOptions {
+  projectDir?: string;
+  disableTools?: string;
+  disableProductionDeployments?: boolean;
+}
+
+export class RequestContext implements Context {
+  fs: Filesystem;
+  deprecationMessagePrinted = false;
+  spinner: Ora | undefined;
+  _cleanupFns: Record<string, (exitCode: number, err?: any) => Promise<void>> =
+    {};
+  _bigBrainAuth: BigBrainAuth | null = null;
+  constructor(public options: McpOptions) {
+    this.fs = nodeFs;
+    this.deprecationMessagePrinted = false;
+  }
+
+  async crash(args: {
+    exitCode: number;
+    errorType?: ErrorType;
+    errForSentry?: any;
+    printedMessage: string | null;
+  }): Promise<never> {
+    const cleanupFns = this._cleanupFns;
+    this._cleanupFns = {};
+    for (const fn of Object.values(cleanupFns)) {
+      await fn(args.exitCode, args.errForSentry);
+    }
+    // eslint-disable-next-line no-restricted-syntax
+    throw new RequestCrash(args.exitCode, args.errorType, args.printedMessage);
+  }
+
+  flushAndExit() {
+    // eslint-disable-next-line no-restricted-syntax
+    throw new Error("Not implemented");
+  }
+
+  registerCleanup(fn: (exitCode: number, err?: any) => Promise<void>): string {
+    const handle = crypto.randomUUID();
+    this._cleanupFns[handle] = fn;
+    return handle;
+  }
+
+  removeCleanup(handle: string) {
+    const value = this._cleanupFns[handle];
+    delete this._cleanupFns[handle];
+    return value ?? null;
+  }
+
+  bigBrainAuth(): BigBrainAuth | null {
+    return this._bigBrainAuth;
+  }
+
+  _updateBigBrainAuth(auth: BigBrainAuth | null): void {
+    this._bigBrainAuth = auth;
+  }
+
+  async decodeDeploymentSelector(encoded: string) {
+    const { projectDir, deployment } = decodeDeploymentSelector(encoded);
+    if (
+      deployment.kind === "prod" &&
+      this.options.disableProductionDeployments
+    ) {
+      return await this.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage:
+          "Production deployments are disabled due to the --disable-production-deployments flag.",
+      });
+    }
+    return { projectDir, deployment };
+  }
+
+  get productionDeploymentsDisabled() {
+    return !!this.options.disableProductionDeployments;
+  }
+}
+
+export class RequestCrash {
+  printedMessage: string;
+  constructor(
+    private exitCode: number,
+    private errorType: ErrorType | undefined,
+    printedMessage: string | null,
+  ) {
+    this.printedMessage = printedMessage ?? "Unknown error";
+  }
+}
+
+// Unfortunately, MCP clients don't seem to handle nested JSON objects very
+// well (even though this is within spec). To work around this, encode the
+// deployment selectors as an obfuscated string that the MCP client can
+// opaquely pass around.
+export function encodeDeploymentSelector(
+  projectDir: string,
+  deployment: DeploymentSelectionWithinProject,
+) {
+  const payload = {
+    projectDir,
+    deployment,
+  };
+  return `${deployment.kind}:${btoa(JSON.stringify(payload))}`;
+}
+
+const payloadSchema = z.object({
+  projectDir: z.string(),
+  deployment: deploymentSelectionWithinProjectSchema,
+});
+
+function decodeDeploymentSelector(encoded: string) {
+  const [_, serializedPayload] = encoded.split(":");
+  return payloadSchema.parse(JSON.parse(atob(serializedPayload)));
+}
diff --git a/synced/convex/libs/cli/lib/mcp/tools/data.ts b/synced/convex/libs/cli/lib/mcp/tools/data.ts
new file mode 100644
index 0000000..3f727ab
--- /dev/null
+++ b/synced/convex/libs/cli/lib/mcp/tools/data.ts
@@ -0,0 +1,73 @@
+import { z } from "zod";
+import { runSystemQuery } from "../../run.js";
+import { ConvexTool } from "./index.js";
+import { PaginationResult } from "../../../../server/pagination.js";
+import { loadSelectedDeploymentCredentials } from "../../api.js";
+import { getDeploymentSelection } from "../../deploymentSelection.js";
+
+const inputSchema = z.object({
+  deploymentSelector: z
+    .string()
+    .describe("Deployment selector (from the status tool) to read data from."),
+  tableName: z.string().describe("The name of the table to read from."),
+  order: z.enum(["asc", "desc"]).describe("The order to sort the results in."),
+  cursor: z.string().optional().describe("The cursor to start reading from."),
+  limit: z
+    .number()
+    .max(1000)
+    .optional()
+    .describe("The maximum number of results to return, defaults to 100."),
+});
+
+const outputSchema = z.object({
+  page: z.array(z.any()),
+  isDone: z.boolean(),
+  continueCursor: z.string(),
+});
+
+const description = `
+Read a page of data from a table in the project's Convex deployment.
+
+Output:
+- page: A page of results from the table.
+- isDone: Whether there are more results to read.
+- continueCursor: The cursor to use to read the next page of results.
+`.trim();
+
+export const DataTool: ConvexTool<typeof inputSchema, typeof outputSchema> = {
+  name: "data",
+  description,
+  inputSchema,
+  outputSchema,
+  handler: async (ctx, args) => {
+    const { projectDir, deployment } = await ctx.decodeDeploymentSelector(
+      args.deploymentSelector,
+    );
+    process.chdir(projectDir);
+    const deploymentSelection = await getDeploymentSelection(ctx, ctx.options);
+    const credentials = await loadSelectedDeploymentCredentials(
+      ctx,
+      deploymentSelection,
+      deployment,
+    );
+    const paginationResult = (await runSystemQuery(ctx, {
+      deploymentUrl: credentials.url,
+      adminKey: credentials.adminKey,
+      functionName: "_system/cli/tableData",
+      componentPath: undefined,
+      args: {
+        table: args.tableName,
+        order: args.order,
+        paginationOpts: {
+          numItems: args.limit ?? 100,
+          cursor: args.cursor ?? null,
+        },
+      },
+    })) as unknown as PaginationResult<any>;
+    return {
+      page: paginationResult.page,
+      isDone: paginationResult.isDone,
+      continueCursor: paginationResult.continueCursor,
+    };
+  },
+};
diff --git a/synced/convex/libs/cli/lib/mcp/tools/env.ts b/synced/convex/libs/cli/lib/mcp/tools/env.ts
new file mode 100644
index 0000000..9f11a09
--- /dev/null
+++ b/synced/convex/libs/cli/lib/mcp/tools/env.ts
@@ -0,0 +1,192 @@
+import { z } from "zod";
+import { ConvexTool } from "./index.js";
+import { loadSelectedDeploymentCredentials } from "../../api.js";
+import {
+  envSetInDeployment,
+  envRemoveInDeployment,
+  EnvVar,
+} from "../../env.js";
+import { runSystemQuery } from "../../run.js";
+import { getDeploymentSelection } from "../../deploymentSelection.js";
+
+// List Environment Variables
+const envListInputSchema = z.object({
+  deploymentSelector: z
+    .string()
+    .describe(
+      "Deployment selector (from the status tool) to list environment variables from.",
+    ),
+});
+
+const envListOutputSchema = z.object({
+  variables: z.array(
+    z.object({
+      name: z.string(),
+      value: z.string(),
+    }),
+  ),
+});
+
+export const EnvListTool: ConvexTool<
+  typeof envListInputSchema,
+  typeof envListOutputSchema
+> = {
+  name: "envList",
+  description: "List all environment variables in your Convex deployment.",
+  inputSchema: envListInputSchema,
+  outputSchema: envListOutputSchema,
+  handler: async (ctx, args) => {
+    const { projectDir, deployment } = await ctx.decodeDeploymentSelector(
+      args.deploymentSelector,
+    );
+    process.chdir(projectDir);
+    const deploymentSelection = await getDeploymentSelection(ctx, ctx.options);
+    const credentials = await loadSelectedDeploymentCredentials(
+      ctx,
+      deploymentSelection,
+      deployment,
+    );
+    const variables = (await runSystemQuery(ctx, {
+      deploymentUrl: credentials.url,
+      adminKey: credentials.adminKey,
+      functionName: "_system/cli/queryEnvironmentVariables",
+      componentPath: undefined,
+      args: {},
+    })) as EnvVar[];
+    return { variables };
+  },
+};
+
+// Get Environment Variable
+const envGetInputSchema = z.object({
+  deploymentSelector: z
+    .string()
+    .describe(
+      "Deployment selector (from the status tool) to get environment variable from.",
+    ),
+  name: z
+    .string()
+    .describe("The name of the environment variable to retrieve."),
+});
+
+const envGetOutputSchema = z.object({
+  value: z.union([z.string(), z.null()]),
+});
+
+export const EnvGetTool: ConvexTool<
+  typeof envGetInputSchema,
+  typeof envGetOutputSchema
+> = {
+  name: "envGet",
+  description:
+    "Get a specific environment variable from your Convex deployment.",
+  inputSchema: envGetInputSchema,
+  outputSchema: envGetOutputSchema,
+  handler: async (ctx, args) => {
+    const { projectDir, deployment } = await ctx.decodeDeploymentSelector(
+      args.deploymentSelector,
+    );
+    process.chdir(projectDir);
+    const deploymentSelection = await getDeploymentSelection(ctx, ctx.options);
+    const credentials = await loadSelectedDeploymentCredentials(
+      ctx,
+      deploymentSelection,
+      deployment,
+    );
+    const envVar = (await runSystemQuery(ctx, {
+      deploymentUrl: credentials.url,
+      adminKey: credentials.adminKey,
+      functionName: "_system/cli/queryEnvironmentVariables:get",
+      componentPath: undefined,
+      args: { name: args.name },
+    })) as { name: string; value: string } | null;
+    return { value: envVar?.value ?? null };
+  },
+};
+
+// Set Environment Variable
+const envSetInputSchema = z.object({
+  deploymentSelector: z
+    .string()
+    .describe(
+      "Deployment selector (from the status tool) to set environment variable on.",
+    ),
+  name: z.string().describe("The name of the environment variable to set."),
+  value: z.string().describe("The value to set for the environment variable."),
+});
+
+const envSetOutputSchema = z.object({
+  success: z.boolean(),
+});
+
+export const EnvSetTool: ConvexTool<
+  typeof envSetInputSchema,
+  typeof envSetOutputSchema
+> = {
+  name: "envSet",
+  description: "Set an environment variable in your Convex deployment.",
+  inputSchema: envSetInputSchema,
+  outputSchema: envSetOutputSchema,
+  handler: async (ctx, args) => {
+    const { projectDir, deployment } = await ctx.decodeDeploymentSelector(
+      args.deploymentSelector,
+    );
+    process.chdir(projectDir);
+    const deploymentSelection = await getDeploymentSelection(ctx, ctx.options);
+    const credentials = await loadSelectedDeploymentCredentials(
+      ctx,
+      deploymentSelection,
+      deployment,
+    );
+    const deploymentInfo = {
+      deploymentUrl: credentials.url,
+      adminKey: credentials.adminKey,
+      deploymentNotice: "",
+    };
+    await envSetInDeployment(ctx, deploymentInfo, args.name, args.value);
+    return { success: true };
+  },
+};
+
+// Remove Environment Variable
+const envRemoveInputSchema = z.object({
+  deploymentSelector: z
+    .string()
+    .describe(
+      "Deployment selector (from the status tool) to remove environment variable from.",
+    ),
+  name: z.string().describe("The name of the environment variable to remove."),
+});
+
+const envRemoveOutputSchema = z.object({
+  success: z.boolean(),
+});
+
+export const EnvRemoveTool: ConvexTool<
+  typeof envRemoveInputSchema,
+  typeof envRemoveOutputSchema
+> = {
+  name: "envRemove",
+  description: "Remove an environment variable from your Convex deployment.",
+  inputSchema: envRemoveInputSchema,
+  outputSchema: envRemoveOutputSchema,
+  handler: async (ctx, args) => {
+    const { projectDir, deployment } = await ctx.decodeDeploymentSelector(
+      args.deploymentSelector,
+    );
+    process.chdir(projectDir);
+    const deploymentSelection = await getDeploymentSelection(ctx, ctx.options);
+    const credentials = await loadSelectedDeploymentCredentials(
+      ctx,
+      deploymentSelection,
+      deployment,
+    );
+    const deploymentInfo = {
+      deploymentUrl: credentials.url,
+      adminKey: credentials.adminKey,
+      deploymentNotice: "",
+    };
+    await envRemoveInDeployment(ctx, deploymentInfo, args.name);
+    return { success: true };
+  },
+};
diff --git a/synced/convex/libs/cli/lib/mcp/tools/functionSpec.ts b/synced/convex/libs/cli/lib/mcp/tools/functionSpec.ts
new file mode 100644
index 0000000..6ae33d6
--- /dev/null
+++ b/synced/convex/libs/cli/lib/mcp/tools/functionSpec.ts
@@ -0,0 +1,57 @@
+import { z } from "zod";
+import { ConvexTool } from "./index.js";
+import { loadSelectedDeploymentCredentials } from "../../api.js";
+import { runSystemQuery } from "../../run.js";
+import { getDeploymentSelection } from "../../deploymentSelection.js";
+
+const inputSchema = z.object({
+  deploymentSelector: z
+    .string()
+    .describe(
+      "Deployment selector (from the status tool) to get function metadata from.",
+    ),
+});
+
+const outputSchema = z
+  .any()
+  .describe("Function metadata including arguments and return values");
+
+const description = `
+Get the function metadata from a Convex deployment.
+
+Returns an array of structured objects for each function the deployment. Each function's
+metadata contains its identifier (which is its path within the convex/ folder joined
+with its exported name), its argument validator, its return value validator, its type
+(i.e. is it a query, mutation, or action), and its visibility (i.e. is it public or
+internal).
+`.trim();
+
+export const FunctionSpecTool: ConvexTool<
+  typeof inputSchema,
+  typeof outputSchema
+> = {
+  name: "functionSpec",
+  description,
+  inputSchema,
+  outputSchema,
+  handler: async (ctx, args) => {
+    const { projectDir, deployment } = await ctx.decodeDeploymentSelector(
+      args.deploymentSelector,
+    );
+    process.chdir(projectDir);
+    const deploymentSelection = await getDeploymentSelection(ctx, ctx.options);
+    const credentials = await loadSelectedDeploymentCredentials(
+      ctx,
+      deploymentSelection,
+      deployment,
+    );
+    const functions = await runSystemQuery(ctx, {
+      deploymentUrl: credentials.url,
+      adminKey: credentials.adminKey,
+      functionName: "_system/cli/modules:apiSpec",
+      componentPath: undefined,
+      args: {},
+    });
+    return functions;
+  },
+};
diff --git a/synced/convex/libs/cli/lib/mcp/tools/index.ts b/synced/convex/libs/cli/lib/mcp/tools/index.ts
new file mode 100644
index 0000000..1774b82
--- /dev/null
+++ b/synced/convex/libs/cli/lib/mcp/tools/index.ts
@@ -0,0 +1,46 @@
+import { ToolSchema } from "@modelcontextprotocol/sdk/types";
+import { Tool } from "@modelcontextprotocol/sdk/types";
+import { RequestContext } from "../requestContext.js";
+import { ZodTypeAny, z } from "zod";
+import zodToJsonSchema from "zod-to-json-schema";
+import { TablesTool } from "./tables.js";
+import { DataTool } from "./data.js";
+import { StatusTool } from "./status.js";
+import { FunctionSpecTool } from "./functionSpec.js";
+import { RunTool } from "./run.js";
+import { EnvListTool, EnvGetTool, EnvSetTool, EnvRemoveTool } from "./env.js";
+import { RunOneoffQueryTool } from "./runOneoffQuery.js";
+
+export type ConvexTool<Input extends ZodTypeAny, Output extends ZodTypeAny> = {
+  name: string;
+  description: string;
+  inputSchema: Input;
+  outputSchema: Output;
+  handler: (
+    ctx: RequestContext,
+    input: z.infer<Input>,
+  ) => Promise<z.infer<Output>>;
+};
+
+type ToolInput = z.infer<(typeof ToolSchema)["shape"]["inputSchema"]>;
+
+export function mcpTool(tool: ConvexTool<ZodTypeAny, ZodTypeAny>): Tool {
+  return {
+    name: tool.name,
+    description: tool.description,
+    inputSchema: zodToJsonSchema(tool.inputSchema) as ToolInput,
+  };
+}
+
+export const convexTools: ConvexTool<any, any>[] = [
+  StatusTool,
+  DataTool,
+  TablesTool,
+  FunctionSpecTool,
+  RunTool,
+  EnvListTool,
+  EnvGetTool,
+  EnvSetTool,
+  EnvRemoveTool,
+  RunOneoffQueryTool,
+];
diff --git a/synced/convex/libs/cli/lib/mcp/tools/run.ts b/synced/convex/libs/cli/lib/mcp/tools/run.ts
new file mode 100644
index 0000000..cb560e1
--- /dev/null
+++ b/synced/convex/libs/cli/lib/mcp/tools/run.ts
@@ -0,0 +1,88 @@
+import { z } from "zod";
+import { ConvexTool } from "./index.js";
+import { loadSelectedDeploymentCredentials } from "../../api.js";
+import { parseArgs, parseFunctionName } from "../../run.js";
+import { readProjectConfig } from "../../config.js";
+import { ConvexHttpClient } from "../../../../browser/index.js";
+import { Value } from "../../../../values/index.js";
+import { Logger } from "../../../../browser/logging.js";
+import { getDeploymentSelection } from "../../deploymentSelection.js";
+const inputSchema = z.object({
+  deploymentSelector: z
+    .string()
+    .describe(
+      "Deployment selector (from the status tool) to run the function on.",
+    ),
+  functionName: z
+    .string()
+    .describe(
+      "The name of the function to run (e.g. 'path/to/my/module.js:myFunction').",
+    ),
+  args: z
+    .string()
+    .describe(
+      "The argument object to pass to the function, JSON-encoded as a string.",
+    ),
+});
+
+const outputSchema = z.object({
+  result: z.any().describe("The result returned by the function"),
+  logLines: z
+    .array(z.string())
+    .describe("The log lines generated by the function"),
+});
+
+const description = `
+Run a Convex function (query, mutation, or action) on your deployment.
+
+Returns the result and any log lines generated by the function.
+`.trim();
+
+export const RunTool: ConvexTool<typeof inputSchema, typeof outputSchema> = {
+  name: "run",
+  description,
+  inputSchema,
+  outputSchema,
+  handler: async (ctx, args) => {
+    const { projectDir, deployment } = await ctx.decodeDeploymentSelector(
+      args.deploymentSelector,
+    );
+    process.chdir(projectDir);
+    const metadata = await getDeploymentSelection(ctx, ctx.options);
+    const credentials = await loadSelectedDeploymentCredentials(
+      ctx,
+      metadata,
+      deployment,
+    );
+    const parsedArgs = await parseArgs(ctx, args.args);
+    const { projectConfig } = await readProjectConfig(ctx);
+    const parsedFunctionName = await parseFunctionName(
+      ctx,
+      args.functionName,
+      projectConfig.functions,
+    );
+    const logger = new Logger({ verbose: true });
+    const logLines: string[] = [];
+    logger.addLogLineListener((level, ...args) => {
+      logLines.push(`${level}: ${args.join(" ")}`);
+    });
+    const client = new ConvexHttpClient(credentials.url, {
+      logger: logger,
+    });
+    client.setAdminAuth(credentials.adminKey);
+    let result: Value;
+    try {
+      result = await client.function(parsedFunctionName, undefined, parsedArgs);
+    } catch (err) {
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "invalid filesystem or env vars",
+        printedMessage: `Failed to run function "${args.functionName}":\n${(err as Error).toString().trim()}`,
+      });
+    }
+    return {
+      result,
+      logLines,
+    };
+  },
+};
diff --git a/synced/convex/libs/cli/lib/mcp/tools/runOneoffQuery.ts b/synced/convex/libs/cli/lib/mcp/tools/runOneoffQuery.ts
new file mode 100644
index 0000000..dbc0dac
--- /dev/null
+++ b/synced/convex/libs/cli/lib/mcp/tools/runOneoffQuery.ts
@@ -0,0 +1,114 @@
+import { z } from "zod";
+import { ConvexTool } from "./index.js";
+import { loadSelectedDeploymentCredentials } from "../../api.js";
+import { getDeploymentSelection } from "../../deploymentSelection.js";
+
+const inputSchema = z.object({
+  deploymentSelector: z
+    .string()
+    .describe(
+      "Deployment selector (from the status tool) to run the query on.",
+    ),
+  query: z
+    .string()
+    .describe(
+      "The query to run. This should be valid JavaScript code that returns a value.",
+    ),
+});
+
+const outputSchema = z.object({
+  result: z.any().describe("The result returned by the query"),
+  logLines: z
+    .array(z.string())
+    .describe("The log lines generated by the query"),
+});
+
+const description = `
+Run a one-off readonly query on your Convex deployment.
+
+This tool executes a JavaScript string as a query in your Convex deployment.
+The query should follow Convex guidelines and use the following setup:
+
+\`\`\`js
+import { query, internalQuery } from "convex:/_system/repl/wrappers.js";
+
+export default query({
+  handler: async (ctx) => {
+    console.log("Write and test your query function here!");
+  },
+});
+\`\`\`
+
+Note that there are no imports available in this environment. The only import
+you can use is the built-in "convex:/_system/repl/wrappers.js" module in the
+template.
+
+The function call is also completely sandboxed, so it can only read data and
+cannot modify the database or access the network.
+
+Returns the result and any log lines generated by the query.
+`.trim();
+
+export const RunOneoffQueryTool: ConvexTool<
+  typeof inputSchema,
+  typeof outputSchema
+> = {
+  name: "runOneoffQuery",
+  description,
+  inputSchema,
+  outputSchema,
+  handler: async (ctx, args) => {
+    const { projectDir, deployment } = await ctx.decodeDeploymentSelector(
+      args.deploymentSelector,
+    );
+    process.chdir(projectDir);
+    const deploymentSelection = await getDeploymentSelection(ctx, ctx.options);
+    const credentials = await loadSelectedDeploymentCredentials(
+      ctx,
+      deploymentSelection,
+      deployment,
+    );
+    try {
+      const response = await fetch(`${credentials.url}/api/run_test_function`, {
+        method: "POST",
+        headers: {
+          "Content-Type": "application/json",
+        },
+        body: JSON.stringify({
+          adminKey: credentials.adminKey,
+          args: {},
+          bundle: {
+            path: "testQuery.js",
+            source: args.query,
+          },
+          format: "convex_encoded_json",
+        }),
+      });
+      if (!response.ok) {
+        return await ctx.crash({
+          exitCode: 1,
+          errorType: "fatal",
+          printedMessage: `HTTP error ${response.status}: ${await response.text()}`,
+        });
+      }
+      const result = await response.json();
+      if (result.status !== "success") {
+        return await ctx.crash({
+          exitCode: 1,
+          errorType: "fatal",
+          printedMessage: `Query failed: ${JSON.stringify(result)}`,
+        });
+      }
+      return {
+        result: result.value,
+        logLines: result.logLines,
+      };
+    } catch (err) {
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage: `Failed to run query: ${(err as Error).toString().trim()}`,
+      });
+    }
+  },
+};
diff --git a/synced/convex/libs/cli/lib/mcp/tools/status.ts b/synced/convex/libs/cli/lib/mcp/tools/status.ts
new file mode 100644
index 0000000..b72dbc2
--- /dev/null
+++ b/synced/convex/libs/cli/lib/mcp/tools/status.ts
@@ -0,0 +1,126 @@
+import { encodeDeploymentSelector, RequestContext } from "../requestContext.js";
+import {
+  DeploymentSelectionWithinProject,
+  deploymentSelectionWithinProjectFromOptions,
+  loadSelectedDeploymentCredentials,
+} from "../../api.js";
+import { z } from "zod";
+import { ConvexTool } from "./index.js";
+import { deploymentDashboardUrlPage } from "../../../lib/dashboard.js";
+import { getDeploymentSelection } from "../../../lib/deploymentSelection.js";
+
+const projectDirDescription = `
+The root directory of the Convex project. This is usually the editor's workspace directory
+and often includes the 'package.json' file and the 'convex/' folder.
+
+Pass this option unless explicitly instructed not to.
+`;
+
+const inputSchema = z.object({
+  projectDir: z.string().optional().describe(projectDirDescription),
+});
+const outputSchema = z.object({
+  availableDeployments: z.array(
+    z.object({
+      kind: z.string(),
+      deploymentSelector: z.string(),
+      url: z.string(),
+      dashboardUrl: z.string().optional(),
+    }),
+  ),
+});
+
+const description = `
+Get all available deployments for a given Convex project directory.
+
+Use this tool to find the deployment selector, URL, and dashboard URL for each
+deployment associated with the project. Pass the deployment selector to other
+tools to target a specific deployment.
+
+When deployed to Convex Cloud, projects have a development ({"kind": "ownDev"}) and
+production ({"kind": "prod"}) deployment. Generally default to using the development
+deployment unless you'd specifically like to debug issues in production.
+
+When running locally, there will be a single "urlWithAdminKey" deployment.
+`.trim();
+
+export const StatusTool: ConvexTool<typeof inputSchema, typeof outputSchema> = {
+  name: "status",
+  description,
+  inputSchema,
+  outputSchema,
+  handler: async (ctx: RequestContext, input) => {
+    const projectDir = input.projectDir ?? ctx.options.projectDir;
+    if (projectDir === undefined) {
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage:
+          "No project directory provided. Either provide the `projectDir` argument or configure the MCP server with the `--project-dir` flag.",
+      });
+    }
+    process.chdir(projectDir);
+    const selectionWithinProject =
+      await deploymentSelectionWithinProjectFromOptions(ctx, ctx.options);
+    const deploymentSelection = await getDeploymentSelection(ctx, ctx.options);
+    const credentials = await loadSelectedDeploymentCredentials(
+      ctx,
+      deploymentSelection,
+      selectionWithinProject,
+    );
+    let availableDeployments = [
+      {
+        kind: selectionWithinProject.kind,
+        deploymentSelector: encodeDeploymentSelector(
+          projectDir,
+          selectionWithinProject,
+        ),
+        url: credentials.url,
+        dashboardUrl:
+          credentials.deploymentFields?.deploymentName &&
+          deploymentDashboardUrlPage(
+            credentials.deploymentFields.deploymentName,
+            "",
+          ),
+      },
+    ];
+    // Also get the prod cloud deployment if we're using a cloud-hosted dev-deployment
+    if (
+      selectionWithinProject.kind === "ownDev" &&
+      !(
+        deploymentSelection.kind === "existingDeployment" &&
+        deploymentSelection.deploymentToActOn.deploymentFields === null
+      )
+    ) {
+      const prodDeployment: DeploymentSelectionWithinProject = { kind: "prod" };
+      const prodCredentials = await loadSelectedDeploymentCredentials(
+        ctx,
+        deploymentSelection,
+        prodDeployment,
+      );
+      if (
+        prodCredentials.deploymentFields?.deploymentName &&
+        prodCredentials.deploymentFields.deploymentType
+      ) {
+        availableDeployments.push({
+          kind: prodDeployment.kind,
+          deploymentSelector: encodeDeploymentSelector(
+            projectDir,
+            prodDeployment,
+          ),
+          url: prodCredentials.url,
+          dashboardUrl: deploymentDashboardUrlPage(
+            prodCredentials.deploymentFields.deploymentName,
+            "",
+          ),
+        });
+      }
+    }
+    if (ctx.productionDeploymentsDisabled) {
+      availableDeployments = availableDeployments.filter(
+        (d) => d.kind !== "prod",
+      );
+    }
+    return { availableDeployments };
+  },
+};
diff --git a/synced/convex/libs/cli/lib/mcp/tools/tables.ts b/synced/convex/libs/cli/lib/mcp/tools/tables.ts
new file mode 100644
index 0000000..c9a5977
--- /dev/null
+++ b/synced/convex/libs/cli/lib/mcp/tools/tables.ts
@@ -0,0 +1,90 @@
+import { z } from "zod";
+import { ConvexTool } from "./index.js";
+import { loadSelectedDeploymentCredentials } from "../../api.js";
+import { runSystemQuery } from "../../run.js";
+import { deploymentFetch } from "../../utils/utils.js";
+import { getDeploymentSelection } from "../../deploymentSelection.js";
+
+const inputSchema = z.object({
+  deploymentSelector: z
+    .string()
+    .describe(
+      "Deployment selector (from the status tool) to read tables from.",
+    ),
+});
+
+const outputSchema = z.object({
+  tables: z.record(
+    z.string(),
+    z.object({
+      schema: z.any().optional(),
+      inferredSchema: z.any().optional(),
+    }),
+  ),
+});
+
+export const TablesTool: ConvexTool<typeof inputSchema, typeof outputSchema> = {
+  name: "tables",
+  description:
+    "List all tables in a particular Convex deployment and their inferred and declared schema.",
+  inputSchema,
+  outputSchema,
+  handler: async (ctx, args) => {
+    const { projectDir, deployment } = await ctx.decodeDeploymentSelector(
+      args.deploymentSelector,
+    );
+    process.chdir(projectDir);
+    const deploymentSelection = await getDeploymentSelection(ctx, ctx.options);
+    const credentials = await loadSelectedDeploymentCredentials(
+      ctx,
+      deploymentSelection,
+      deployment,
+    );
+    const schemaResponse: any = await runSystemQuery(ctx, {
+      deploymentUrl: credentials.url,
+      adminKey: credentials.adminKey,
+      functionName: "_system/frontend/getSchemas",
+      componentPath: undefined,
+      args: {},
+    });
+    const schema: Record<string, z.infer<typeof activeSchemaEntry>> = {};
+    if (schemaResponse.active) {
+      const parsed = activeSchema.parse(JSON.parse(schemaResponse.active));
+      for (const table of parsed.tables) {
+        schema[table.tableName] = table;
+      }
+    }
+    const fetch = deploymentFetch(ctx, {
+      deploymentUrl: credentials.url,
+      adminKey: credentials.adminKey,
+    });
+    const response = await fetch("/api/shapes2", {});
+    const shapesResult: Record<string, any> = await response.json();
+
+    const allTablesSet = new Set([
+      ...Object.keys(shapesResult),
+      ...Object.keys(schema),
+    ]);
+    const allTables = Array.from(allTablesSet);
+    allTables.sort();
+
+    const result: z.infer<typeof outputSchema>["tables"] = {};
+    for (const table of allTables) {
+      result[table] = {
+        schema: schema[table],
+        inferredSchema: shapesResult[table],
+      };
+    }
+    return { tables: result };
+  },
+};
+
+const activeSchemaEntry = z.object({
+  tableName: z.string(),
+  indexes: z.array(z.any()),
+  searchIndexes: z.array(z.any()),
+  vectorIndexes: z.array(z.any()),
+  documentType: z.any(),
+});
+
+const activeSchema = z.object({ tables: z.array(activeSchemaEntry) });
diff --git a/synced/convex/libs/cli/lib/networkTest.ts b/synced/convex/libs/cli/lib/networkTest.ts
new file mode 100644
index 0000000..810a556
--- /dev/null
+++ b/synced/convex/libs/cli/lib/networkTest.ts
@@ -0,0 +1,350 @@
+import {
+  Context,
+  logFailure,
+  logFinishedStep,
+  logMessage,
+  logVerbose,
+  logWarning,
+} from "../../bundler/context.js";
+import chalk from "chalk";
+import * as net from "net";
+import * as dns from "dns";
+import * as crypto from "crypto";
+import {
+  bareDeploymentFetch,
+  formatDuration,
+  formatSize,
+  ThrowingFetchError,
+} from "./utils/utils.js";
+import ws from "ws";
+import { BaseConvexClient } from "../../browser/index.js";
+import { Logger } from "../../browser/logging.js";
+const ipFamilyNumbers = { ipv4: 4, ipv6: 6, auto: 0 } as const;
+const ipFamilyNames = { 4: "ipv4", 6: "ipv6", 0: "auto" } as const;
+
+export async function runNetworkTestOnUrl(
+  ctx: Context,
+  { url, adminKey }: { url: string; adminKey: string | null },
+  options: {
+    ipFamily?: string;
+    speedTest?: boolean;
+  },
+) {
+  // First, check DNS to see if we can resolve the URL's hostname.
+  await checkDns(ctx, url);
+
+  // Second, check to see if we can open a TCP connection to the hostname.
+  await checkTcp(ctx, url, options.ipFamily ?? "auto");
+
+  // Third, do a simple HTTPS request and check that we receive a 200.
+  await checkHttp(ctx, url);
+
+  // Fourth, check that we can open a WebSocket connection to the hostname.
+  await checkWs(ctx, { url, adminKey });
+
+  // Fifth, check a small echo request, much smaller than most networks' MTU.
+  await checkEcho(ctx, url, 128);
+
+  // Finally, try a large echo request, much larger than most networks' MTU.
+  await checkEcho(ctx, url, 4 * 1024 * 1024);
+  // Also do a 64MiB echo test if the user has requested a speed test.
+  if (options.speedTest) {
+    await checkEcho(ctx, url, 64 * 1024 * 1024);
+  }
+
+  logFinishedStep(ctx, "Network test passed.");
+}
+
+async function checkDns(ctx: Context, url: string) {
+  try {
+    const hostname = new URL("/", url).hostname;
+    const start = performance.now();
+    type DnsResult = { duration: number; address: string; family: number };
+    const result = await new Promise<DnsResult>((resolve, reject) => {
+      dns.lookup(hostname, (err, address, family) => {
+        if (err) {
+          reject(err);
+        } else {
+          resolve({ duration: performance.now() - start, address, family });
+        }
+      });
+    });
+    logMessage(
+      ctx,
+      `${chalk.green(``)} OK: DNS lookup => ${result.address}:${
+        ipFamilyNames[result.family as keyof typeof ipFamilyNames]
+      } (${formatDuration(result.duration)})`,
+    );
+  } catch (e: any) {
+    return ctx.crash({
+      exitCode: 1,
+      errorType: "transient",
+      printedMessage: `FAIL: DNS lookup (${e})`,
+    });
+  }
+}
+
+async function checkTcp(ctx: Context, urlString: string, ipFamilyOpt: string) {
+  const url = new URL(urlString);
+  if (url.protocol === "http:") {
+    const port = Number.parseInt(url.port || "80");
+    await checkTcpHostPort(ctx, url.hostname, port, ipFamilyOpt);
+  } else if (url.protocol === "https:") {
+    const port = Number.parseInt(url.port || "443");
+    await checkTcpHostPort(ctx, url.hostname, port, ipFamilyOpt);
+    // If we didn't specify a port, also try port 80.
+    if (!url.port) {
+      await checkTcpHostPort(ctx, url.hostname, 80, ipFamilyOpt);
+    }
+  } else {
+    // eslint-disable-next-line no-restricted-syntax
+    throw new Error(`Unknown protocol: ${url.protocol}`);
+  }
+}
+
+async function checkTcpHostPort(
+  ctx: Context,
+  host: string,
+  port: number,
+  ipFamilyOpt: string,
+) {
+  const ipFamily = ipFamilyNumbers[ipFamilyOpt as keyof typeof ipFamilyNumbers];
+  const tcpString =
+    `TCP` + (ipFamilyOpt === "auto" ? "" : `/${ipFamilyOpt} ${host}:${port}`);
+  try {
+    const start = performance.now();
+    const duration = await new Promise<number>((resolve, reject) => {
+      const socket = net.connect(
+        {
+          host,
+          port,
+          noDelay: true,
+          family: ipFamily,
+        },
+        () => resolve(performance.now() - start),
+      );
+      socket.on("error", (e) => reject(e));
+    });
+    logMessage(
+      ctx,
+      `${chalk.green(``)} OK: ${tcpString} connect (${formatDuration(
+        duration,
+      )})`,
+    );
+  } catch (e: any) {
+    return ctx.crash({
+      exitCode: 1,
+      errorType: "transient",
+      printedMessage: `FAIL: ${tcpString} connect (${e})`,
+    });
+  }
+}
+
+async function checkHttp(ctx: Context, urlString: string) {
+  const url = new URL(urlString);
+  const isHttps = url.protocol === "https:";
+  if (isHttps) {
+    url.protocol = "http:";
+    url.port = "80";
+    await checkHttpOnce(ctx, "HTTP", url.toString(), false);
+  }
+  await checkHttpOnce(ctx, isHttps ? "HTTPS" : "HTTP", urlString, true);
+}
+
+// Be sure to test this function against *prod* (with both HTTP & HTTPS) when
+// making changes.
+async function checkHttpOnce(
+  ctx: Context,
+  name: string,
+  url: string,
+  allowRedirects: boolean,
+) {
+  const start = performance.now();
+  try {
+    // Be sure to use the same `deploymentFetch` we use elsewhere so we're actually
+    // getting coverage of our network stack.
+    const fetch = bareDeploymentFetch(ctx, { deploymentUrl: url });
+    const instanceNameUrl = new URL("/instance_name", url);
+    const resp = await fetch(instanceNameUrl.toString(), {
+      redirect: allowRedirects ? "follow" : "manual",
+    });
+    if (resp.status !== 200) {
+      // eslint-disable-next-line no-restricted-syntax
+      throw new Error(`Unexpected status code: ${resp.status}`);
+    }
+  } catch (e: any) {
+    // Redirects return a 301, which causes `bareDeploymentFetch` to throw an
+    // ThrowingFetchError. Catch that here and succeed if we're not following
+    // redirects.
+    const isOkayRedirect =
+      !allowRedirects &&
+      e instanceof ThrowingFetchError &&
+      e.response.status === 301;
+    if (!isOkayRedirect) {
+      return ctx.crash({
+        exitCode: 1,
+        errorType: "transient",
+        printedMessage: `FAIL: ${name} check (${e})`,
+      });
+    }
+  }
+  const duration = performance.now() - start;
+  logMessage(
+    ctx,
+    `${chalk.green(``)} OK: ${name} check (${formatDuration(duration)})`,
+  );
+}
+
+async function checkWs(
+  ctx: Context,
+  { url, adminKey }: { url: string; adminKey: string | null },
+) {
+  if (adminKey === null) {
+    logWarning(
+      ctx,
+      "Skipping WebSocket check because no admin key was provided.",
+    );
+    return;
+  }
+  let queryPromiseResolver: ((value: string) => void) | null = null;
+  const queryPromise = new Promise<string | null>((resolve) => {
+    queryPromiseResolver = resolve;
+  });
+  const logger = new Logger({
+    verbose: process.env.CONVEX_VERBOSE !== undefined,
+  });
+  logger.addLogLineListener((level, ...args) => {
+    switch (level) {
+      case "debug":
+        logVerbose(ctx, ...args);
+        break;
+      case "info":
+        logVerbose(ctx, ...args);
+        break;
+      case "warn":
+        logWarning(ctx, ...args);
+        break;
+      case "error":
+        // TODO: logFailure is a little hard to use here because it also interacts
+        // with the spinner and requires a string.
+        logWarning(ctx, ...args);
+        break;
+    }
+  });
+  const convexClient = new BaseConvexClient(
+    url,
+    (updatedQueries) => {
+      for (const queryToken of updatedQueries) {
+        const result = convexClient.localQueryResultByToken(queryToken);
+        if (typeof result === "string" && queryPromiseResolver !== null) {
+          queryPromiseResolver(result);
+          queryPromiseResolver = null;
+        }
+      }
+    },
+    {
+      webSocketConstructor: ws as unknown as typeof WebSocket,
+      unsavedChangesWarning: false,
+      logger,
+    },
+  );
+  convexClient.setAdminAuth(adminKey);
+  convexClient.subscribe("_system/cli/convexUrl:cloudUrl", {});
+  const racePromise = Promise.race([
+    queryPromise,
+    new Promise((resolve) => setTimeout(() => resolve(null), 10000)),
+  ]);
+  const cloudUrl = await racePromise;
+  if (cloudUrl === null) {
+    return ctx.crash({
+      exitCode: 1,
+      errorType: "transient",
+      printedMessage: "FAIL: Failed to connect to deployment over WebSocket.",
+    });
+  } else {
+    logMessage(
+      ctx,
+      `${chalk.green(``)} OK: WebSocket connection established.`,
+    );
+  }
+}
+
+async function checkEcho(ctx: Context, url: string, size: number) {
+  try {
+    const start = performance.now();
+    const fetch = bareDeploymentFetch(ctx, {
+      deploymentUrl: url,
+      onError: (err) => {
+        logFailure(
+          ctx,
+          chalk.red(`FAIL: echo ${formatSize(size)} (${err}), retrying...`),
+        );
+      },
+    });
+    const echoUrl = new URL(`/echo`, url);
+    const data = crypto.randomBytes(size);
+    const resp = await fetch(echoUrl.toString(), {
+      body: data,
+      method: "POST",
+    });
+    if (resp.status !== 200) {
+      // eslint-disable-next-line no-restricted-syntax
+      throw new Error(`Unexpected status code: ${resp.status}`);
+    }
+    const respData = await resp.arrayBuffer();
+    if (!data.equals(Buffer.from(respData))) {
+      // eslint-disable-next-line no-restricted-syntax
+      throw new Error(`Response data mismatch`);
+    }
+    const duration = performance.now() - start;
+    const bytesPerSecond = size / (duration / 1000);
+    logMessage(
+      ctx,
+      `${chalk.green(``)} OK: echo ${formatSize(size)} (${formatDuration(
+        duration,
+      )}, ${formatSize(bytesPerSecond)}/s)`,
+    );
+  } catch (e: any) {
+    return ctx.crash({
+      exitCode: 1,
+      errorType: "transient",
+      printedMessage: `FAIL: echo ${formatSize(size)} (${e})`,
+    });
+  }
+}
+
+export async function withTimeout<T>(
+  ctx: Context,
+  name: string,
+  timeoutMs: number,
+  f: Promise<T>,
+) {
+  let timer: NodeJS.Timeout | null = null;
+  try {
+    type TimeoutPromise = { kind: "ok"; result: T } | { kind: "timeout" };
+    const result = await Promise.race<TimeoutPromise>([
+      f.then((r) => {
+        return { kind: "ok", result: r };
+      }),
+      new Promise((resolve) => {
+        timer = setTimeout(() => {
+          resolve({ kind: "timeout" as const });
+          timer = null;
+        }, timeoutMs);
+      }),
+    ]);
+    if (result.kind === "ok") {
+      return result.result;
+    } else {
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "transient",
+        printedMessage: `FAIL: ${name} timed out after ${formatDuration(timeoutMs)}.`,
+      });
+    }
+  } finally {
+    if (timer !== null) {
+      clearTimeout(timer);
+    }
+  }
+}
diff --git a/synced/convex/libs/cli/lib/push.ts b/synced/convex/libs/cli/lib/push.ts
new file mode 100644
index 0000000..25e2f6a
--- /dev/null
+++ b/synced/convex/libs/cli/lib/push.ts
@@ -0,0 +1,167 @@
+import chalk from "chalk";
+import { Context, changeSpinner, logMessage } from "../../bundler/context.js";
+import { doCodegen } from "./codegen.js";
+import {
+  ProjectConfig,
+  configFromProjectConfig,
+  diffConfig,
+  pullConfig,
+  pushConfig,
+} from "./config.js";
+import { pushSchema } from "./indexes.js";
+import { typeCheckFunctionsInMode } from "./typecheck.js";
+import { ensureHasConvexDependency, functionsDir } from "./utils/utils.js";
+import { handleDebugBundlePath } from "./debugBundlePath.js";
+
+import { LogManager } from "./logs.js";
+
+export type PushOptions = {
+  adminKey: string;
+  verbose: boolean;
+  dryRun: boolean;
+  typecheck: "enable" | "try" | "disable";
+  typecheckComponents: boolean;
+  debug: boolean;
+  debugBundlePath?: string;
+  codegen: boolean;
+  url: string;
+  deploymentName: string | null;
+  writePushRequest?: string;
+  liveComponentSources: boolean;
+  logManager?: LogManager;
+};
+
+export async function runNonComponentsPush(
+  ctx: Context,
+  options: PushOptions,
+  configPath: string,
+  projectConfig: ProjectConfig,
+) {
+  if (options.writePushRequest) {
+    logMessage(
+      ctx,
+      "Skipping push because --write-push-request is set, but we are on the non-components path so there is nothing to write.",
+    );
+    return;
+  }
+  const timeRunPushStarts = performance.now();
+  const origin = options.url;
+  const verbose = options.verbose || options.dryRun;
+  if (verbose) {
+    process.env["CONVEX_VERBOSE"] = "1";
+  }
+  await ensureHasConvexDependency(ctx, "push");
+
+  if (!options.codegen) {
+    logMessage(
+      ctx,
+      chalk.gray("Skipping codegen. Remove --codegen=disable to enable."),
+    );
+    // Codegen includes typechecking, so if we're skipping it, run the type
+    // check manually on the query and mutation functions
+    const funcDir = functionsDir(configPath, projectConfig);
+    await typeCheckFunctionsInMode(ctx, options.typecheck, funcDir);
+  } else {
+    await doCodegen(
+      ctx,
+      functionsDir(configPath, projectConfig),
+      options.typecheck,
+      options,
+    );
+    if (verbose) {
+      logMessage(ctx, chalk.green("Codegen finished."));
+    }
+  }
+
+  const timeBundleStarts = performance.now();
+  const { config: localConfig, bundledModuleInfos } =
+    await configFromProjectConfig(ctx, projectConfig, configPath, verbose);
+
+  if (options.debugBundlePath) {
+    await handleDebugBundlePath(ctx, options.debugBundlePath, localConfig);
+    logMessage(
+      ctx,
+      `Wrote bundle and metadata to ${options.debugBundlePath}. Skipping rest of push.`,
+    );
+    return;
+  }
+
+  const timeSchemaPushStarts = performance.now();
+  const { schemaId, schemaState } = await pushSchema(
+    ctx,
+    origin,
+    options.adminKey,
+    functionsDir(configPath, localConfig.projectConfig),
+    options.dryRun,
+  );
+
+  const timeConfigPullStarts = performance.now();
+  const remoteConfigWithModuleHashes = await pullConfig(
+    ctx,
+    undefined,
+    undefined,
+    origin,
+    options.adminKey,
+  );
+
+  changeSpinner(ctx, "Diffing local code and deployment state");
+  const { diffString, stats } = diffConfig(
+    remoteConfigWithModuleHashes,
+    localConfig,
+  );
+  if (diffString === "" && schemaState?.state === "active") {
+    if (verbose) {
+      const msg =
+        localConfig.modules.length === 0
+          ? `No functions found in ${localConfig.projectConfig.functions}`
+          : "Config already synced";
+      logMessage(
+        ctx,
+        chalk.gray(
+          `${
+            options.dryRun
+              ? "Command would skip function push"
+              : "Function push skipped"
+          }: ${msg}.`,
+        ),
+      );
+    }
+    return;
+  }
+
+  if (verbose) {
+    logMessage(
+      ctx,
+      chalk.bold(
+        `Remote config ${
+          options.dryRun ? "would" : "will"
+        } be overwritten with the following changes:`,
+      ),
+    );
+    logMessage(ctx, diffString);
+  }
+
+  if (options.dryRun) {
+    return;
+  }
+
+  // Note that this is not quite a user pain metric: we're missing any time
+  // spent making and retrying this network request and receiving the response.
+  const timePushStarts = performance.now();
+  const timing = {
+    typecheck: (timeBundleStarts - timeRunPushStarts) / 1000,
+    bundle: (timeSchemaPushStarts - timeBundleStarts) / 1000,
+    schemaPush: (timeConfigPullStarts - timeSchemaPushStarts) / 1000,
+    codePull: (timePushStarts - timeConfigPullStarts) / 1000,
+    totalBeforePush: (timePushStarts - timeRunPushStarts) / 1000,
+    moduleDiffStats: stats,
+  };
+  await pushConfig(ctx, localConfig, {
+    adminKey: options.adminKey,
+    url: options.url,
+    deploymentName: options.deploymentName,
+    pushMetrics: timing,
+    schemaId,
+    bundledModuleInfos,
+  });
+}
diff --git a/synced/convex/libs/cli/lib/run.test.ts b/synced/convex/libs/cli/lib/run.test.ts
new file mode 100644
index 0000000..483fda0
--- /dev/null
+++ b/synced/convex/libs/cli/lib/run.test.ts
@@ -0,0 +1,54 @@
+import { test, expect } from "vitest";
+import { parseFunctionName } from "./run.js";
+import { oneoffContext } from "../../bundler/context.js";
+
+test("parseFunctionName", async () => {
+  const originalContext = await oneoffContext({
+    url: undefined,
+    adminKey: undefined,
+    envFile: undefined,
+  });
+  const files = new Set<string>();
+  const ctx = {
+    ...originalContext,
+    fs: {
+      ...originalContext.fs,
+      exists: (file: string) => files.has(file),
+    },
+  };
+
+  files.add("convex/foo/bar.ts");
+  files.add("convex/convex/bar/baz.ts");
+  files.add("src/convex/foo/bar.ts");
+
+  expect(await parseFunctionName(ctx, "api.foo.bar", "convex/")).toEqual(
+    "foo:bar",
+  );
+  expect(await parseFunctionName(ctx, "internal.foo.bar", "convex/")).toEqual(
+    "foo:bar",
+  );
+  expect(await parseFunctionName(ctx, "foo/bar", "convex/")).toEqual(
+    "foo/bar:default",
+  );
+  expect(await parseFunctionName(ctx, "foo/bar:baz", "convex/")).toEqual(
+    "foo/bar:baz",
+  );
+  expect(await parseFunctionName(ctx, "convex/foo/bar", "convex/")).toEqual(
+    "foo/bar:default",
+  );
+  expect(await parseFunctionName(ctx, "convex/foo/bar.ts", "convex/")).toEqual(
+    "foo/bar:default",
+  );
+  expect(
+    await parseFunctionName(ctx, "convex/foo/bar.ts:baz", "convex/"),
+  ).toEqual("foo/bar:baz");
+  expect(await parseFunctionName(ctx, "convex/bar/baz", "convex/")).toEqual(
+    "convex/bar/baz:default",
+  );
+  expect(
+    await parseFunctionName(ctx, "src/convex/foo/bar", "src/convex/"),
+  ).toEqual("foo/bar:default");
+  expect(await parseFunctionName(ctx, "foo/bar", "src/convex/")).toEqual(
+    "foo/bar:default",
+  );
+});
diff --git a/synced/convex/libs/cli/lib/run.ts b/synced/convex/libs/cli/lib/run.ts
new file mode 100644
index 0000000..f1b00b8
--- /dev/null
+++ b/synced/convex/libs/cli/lib/run.ts
@@ -0,0 +1,494 @@
+import chalk from "chalk";
+import util from "util";
+import ws from "ws";
+import { ConvexHttpClient } from "../../browser/http_client.js";
+import { BaseConvexClient } from "../../browser/index.js";
+import {
+  PaginationResult,
+  UserIdentityAttributes,
+  makeFunctionReference,
+} from "../../server/index.js";
+import { Value, convexToJson, jsonToConvex } from "../../values/value.js";
+import {
+  Context,
+  logFinishedStep,
+  logMessage,
+  logOutput,
+  OneoffCtx,
+} from "../../bundler/context.js";
+import { waitForever, waitUntilCalled } from "./utils/utils.js";
+import JSON5 from "json5";
+import path from "path";
+import { readProjectConfig } from "./config.js";
+import { watchAndPush } from "./dev.js";
+
+export async function runFunctionAndLog(
+  ctx: Context,
+  args: {
+    deploymentUrl: string;
+    adminKey: string;
+    functionName: string;
+    argsString: string;
+    identityString?: string;
+    componentPath?: string;
+    callbacks?: {
+      onSuccess?: () => void;
+    };
+  },
+) {
+  const client = new ConvexHttpClient(args.deploymentUrl);
+  const identity = args.identityString
+    ? await getFakeIdentity(ctx, args.identityString)
+    : undefined;
+  client.setAdminAuth(args.adminKey, identity);
+
+  const functionArgs = await parseArgs(ctx, args.argsString);
+  const { projectConfig } = await readProjectConfig(ctx);
+  const parsedFunctionName = await parseFunctionName(
+    ctx,
+    args.functionName,
+    projectConfig.functions,
+  );
+  let result: Value;
+  try {
+    result = await client.function(
+      makeFunctionReference(parsedFunctionName),
+      args.componentPath,
+      functionArgs,
+    );
+  } catch (err) {
+    const errorMessage = (err as Error).toString().trim();
+
+    if (errorMessage.includes("Could not find function")) {
+      const functions = (await runSystemQuery(ctx, {
+        deploymentUrl: args.deploymentUrl,
+        adminKey: args.adminKey,
+        functionName: "_system/cli/modules:apiSpec",
+        componentPath: args.componentPath,
+        args: {},
+      })) as (
+        | {
+            functionType: "Query" | "Mutation" | "Action";
+            identifier: string;
+          }
+        | {
+            functionType: "HttpAction";
+          }
+      )[];
+
+      const functionNames = functions
+        .filter(
+          (
+            fn,
+          ): fn is {
+            functionType: "Query" | "Mutation" | "Action";
+            identifier: string;
+          } => fn.functionType !== "HttpAction",
+        )
+        .map(({ identifier }) => {
+          const separatorPos = identifier.indexOf(":");
+
+          const path =
+            separatorPos === -1
+              ? ""
+              : identifier.substring(0, separatorPos + 1);
+          const name =
+            separatorPos === -1
+              ? identifier
+              : identifier.substring(separatorPos + 1);
+
+          return ` ${chalk.gray(path)}${name}`;
+        });
+
+      const availableFunctionsMessage =
+        functionNames.length > 0
+          ? `Available functions:\n${functionNames.join("\n")}`
+          : "No functions found.";
+
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "invalid filesystem data",
+        printedMessage: `Failed to run function "${args.functionName}":\n${chalk.red(errorMessage)}\n\n${availableFunctionsMessage}`,
+      });
+    }
+
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "invalid filesystem or env vars",
+      printedMessage: `Failed to run function "${args.functionName}":\n${chalk.red(errorMessage)}`,
+    });
+  }
+
+  args.callbacks?.onSuccess?.();
+
+  // `null` is the default return type
+  if (result !== null) {
+    logOutput(ctx, formatValue(result));
+  }
+}
+
+async function getFakeIdentity(ctx: Context, identityString: string) {
+  let identity: UserIdentityAttributes;
+  try {
+    identity = JSON5.parse(identityString);
+  } catch (err) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: `Failed to parse identity as JSON: "${identityString}"\n${chalk.red((err as Error).toString().trim())}`,
+    });
+  }
+  const subject = identity.subject ?? "" + simpleHash(JSON.stringify(identity));
+  const issuer = identity.issuer ?? "https://convex.test";
+  const tokenIdentifier =
+    identity.tokenIdentifier ?? `${issuer.toString()}|${subject.toString()}`;
+  return {
+    ...identity,
+    subject,
+    issuer,
+    tokenIdentifier,
+  };
+}
+
+export async function parseArgs(ctx: Context, argsString: string) {
+  try {
+    const argsJson = JSON5.parse(argsString);
+    return jsonToConvex(argsJson) as Record<string, Value>;
+  } catch (err) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "invalid filesystem or env vars",
+      printedMessage: `Failed to parse arguments as JSON: "${argsString}"\n${chalk.red((err as Error).toString().trim())}`,
+    });
+  }
+}
+
+export async function parseFunctionName(
+  ctx: Context,
+  functionName: string,
+  // Usually `convex/` -- should contain trailing slash
+  functionDirName: string,
+) {
+  // api.foo.bar -> foo:bar
+  // foo/bar -> foo/bar:default
+  // foo/bar:baz -> foo/bar:baz
+  // convex/foo/bar -> foo/bar:default
+
+  // This is the `api.foo.bar` format
+  if (functionName.startsWith("api.") || functionName.startsWith("internal.")) {
+    const parts = functionName.split(".");
+    if (parts.length < 3) {
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage: `Function name has too few parts: "${functionName}"`,
+      });
+    }
+    const exportName = parts.pop();
+    const parsedName = `${parts.slice(1).join("/")}:${exportName}`;
+    return parsedName;
+  }
+
+  // This is the `foo/bar:baz` format
+
+  // This is something like `convex/foo/bar`, which could either be addressing `foo/bar:default` or `convex/foo/bar:default`
+  // if there's a directory with the same name as the functions directory nested directly underneath.
+  // We'll prefer the `convex/foo/bar:default` version, and check if the file exists, and otherwise treat this as a relative path from the project root.
+  const filePath = functionName.split(":")[0];
+  const possibleExtensions = [
+    ".ts",
+    ".js",
+    ".tsx",
+    ".jsx",
+    ".mts",
+    ".mjs",
+    ".cts",
+    ".cjs",
+  ];
+  let hasExtension = false;
+  let normalizedFilePath: string = filePath;
+  for (const extension of possibleExtensions) {
+    if (filePath.endsWith(extension)) {
+      normalizedFilePath = filePath.slice(0, -extension.length);
+      hasExtension = true;
+      break;
+    }
+  }
+
+  const exportName = functionName.split(":")[1] ?? "default";
+  const normalizedName = `${normalizedFilePath}:${exportName}`;
+
+  // This isn't a relative path from the project root
+  if (!filePath.startsWith(functionDirName)) {
+    return normalizedName;
+  }
+
+  const filePathWithoutPrefix = normalizedFilePath.slice(
+    functionDirName.length,
+  );
+  const functionNameWithoutPrefix = `${filePathWithoutPrefix}:${exportName}`;
+
+  if (hasExtension) {
+    if (ctx.fs.exists(path.join(functionDirName, filePath))) {
+      return normalizedName;
+    } else {
+      return functionNameWithoutPrefix;
+    }
+  } else {
+    const exists = possibleExtensions.some((extension) =>
+      ctx.fs.exists(path.join(functionDirName, filePath + extension)),
+    );
+    if (exists) {
+      return normalizedName;
+    } else {
+      return functionNameWithoutPrefix;
+    }
+  }
+}
+
+function simpleHash(string: string) {
+  let hash = 0;
+  for (let i = 0; i < string.length; i++) {
+    const char = string.charCodeAt(i);
+    hash = (hash << 5) - hash + char;
+    hash = hash & hash; // Convert to 32bit integer
+  }
+  return hash;
+}
+
+export async function runSystemPaginatedQuery(
+  ctx: Context,
+  args: {
+    deploymentUrl: string;
+    adminKey: string;
+    functionName: string;
+    componentPath: string | undefined;
+    args: Record<string, Value>;
+    limit?: number;
+  },
+) {
+  const results = [];
+  let cursor = null;
+  let isDone = false;
+  while (!isDone && (args.limit === undefined || results.length < args.limit)) {
+    const paginationResult = (await runSystemQuery(ctx, {
+      ...args,
+      args: {
+        ...args.args,
+        paginationOpts: {
+          cursor,
+          numItems:
+            args.limit === undefined ? 10000 : args.limit - results.length,
+        },
+      },
+    })) as unknown as PaginationResult<Record<string, Value>>;
+    isDone = paginationResult.isDone;
+    cursor = paginationResult.continueCursor;
+    results.push(...paginationResult.page);
+  }
+  return results;
+}
+
+export async function runSystemQuery(
+  ctx: Context,
+  args: {
+    deploymentUrl: string;
+    adminKey: string;
+    functionName: string;
+    componentPath: string | undefined;
+    args: Record<string, Value>;
+  },
+): Promise<Value> {
+  let onResult: (result: Value) => void;
+  const resultPromise = new Promise<Value>((resolve) => {
+    onResult = resolve;
+  });
+  const [donePromise, onDone] = waitUntilCalled();
+  await subscribe(ctx, {
+    ...args,
+    parsedFunctionName: args.functionName,
+    parsedFunctionArgs: args.args,
+    until: donePromise,
+    callbacks: {
+      onChange: (result) => {
+        onDone();
+        onResult(result);
+      },
+    },
+  });
+  return resultPromise;
+}
+
+export function formatValue(value: Value) {
+  const json = convexToJson(value);
+  if (process.stdout.isTTY) {
+    // TODO (Tom) add JSON syntax highlighting like https://stackoverflow.com/a/51319962/398212
+    // until then, just spit out something that isn't quite JSON because it's easy
+    return util.inspect(value, { colors: true, depth: null });
+  } else {
+    return JSON.stringify(json, null, 2);
+  }
+}
+
+export async function subscribeAndLog(
+  ctx: Context,
+  args: {
+    deploymentUrl: string;
+    adminKey: string;
+    functionName: string;
+    argsString: string;
+    identityString?: string;
+    componentPath: string | undefined;
+  },
+) {
+  const { projectConfig } = await readProjectConfig(ctx);
+
+  const parsedFunctionName = await parseFunctionName(
+    ctx,
+    args.functionName,
+    projectConfig.functions,
+  );
+  const identity = args.identityString
+    ? await getFakeIdentity(ctx, args.identityString)
+    : undefined;
+  const functionArgs = await parseArgs(ctx, args.argsString);
+  return subscribe(ctx, {
+    deploymentUrl: args.deploymentUrl,
+    adminKey: args.adminKey,
+    identity,
+    parsedFunctionName,
+    parsedFunctionArgs: functionArgs,
+    componentPath: args.componentPath,
+    until: waitForever(),
+    callbacks: {
+      onStart() {
+        logFinishedStep(
+          ctx,
+          `Watching query ${args.functionName} on ${args.deploymentUrl}...`,
+        );
+      },
+      onChange(result) {
+        logOutput(ctx, formatValue(result));
+      },
+      onStop() {
+        logMessage(ctx, `Closing connection to ${args.deploymentUrl}...`);
+      },
+    },
+  });
+}
+
+export async function subscribe(
+  ctx: Context,
+  args: {
+    deploymentUrl: string;
+    adminKey: string;
+    identity?: UserIdentityAttributes;
+    parsedFunctionName: string;
+    parsedFunctionArgs: Record<string, Value>;
+    componentPath: string | undefined;
+    until: Promise<unknown>;
+    callbacks?: {
+      onStart?: () => void;
+      onChange?: (result: Value) => void;
+      onStop?: () => void;
+    };
+  },
+) {
+  const client = new BaseConvexClient(
+    args.deploymentUrl,
+    (updatedQueries) => {
+      for (const queryToken of updatedQueries) {
+        args.callbacks?.onChange?.(client.localQueryResultByToken(queryToken)!);
+      }
+    },
+    {
+      // pretend that a Node.js 'ws' library WebSocket is a browser WebSocket
+      webSocketConstructor: ws as unknown as typeof WebSocket,
+      unsavedChangesWarning: false,
+    },
+  );
+  client.setAdminAuth(args.adminKey, args.identity);
+  const { unsubscribe } = client.subscribe(
+    args.parsedFunctionName,
+    args.parsedFunctionArgs,
+    {
+      componentPath: args.componentPath,
+    },
+  );
+
+  args.callbacks?.onStart?.();
+
+  let done = false;
+  const [donePromise, onDone] = waitUntilCalled();
+  const stopWatching = () => {
+    if (done) {
+      return;
+    }
+    done = true;
+    unsubscribe();
+    void client.close();
+    process.off("SIGINT", sigintListener);
+    onDone();
+    args.callbacks?.onStop?.();
+  };
+  function sigintListener() {
+    stopWatching();
+  }
+  process.on("SIGINT", sigintListener);
+  void args.until.finally(stopWatching);
+  while (!done) {
+    // loops once per day (any large value < 2**31 would work)
+    const oneDay = 24 * 60 * 60 * 1000;
+    await Promise.race([
+      donePromise,
+      new Promise((resolve) => setTimeout(resolve, oneDay)),
+    ]);
+  }
+}
+
+export async function runInDeployment(
+  ctx: OneoffCtx,
+  args: {
+    deploymentUrl: string;
+    adminKey: string;
+    deploymentName: string | null;
+    functionName: string;
+    argsString: string;
+    identityString?: string;
+    push: boolean;
+    watch: boolean;
+    typecheck: "enable" | "try" | "disable";
+    typecheckComponents: boolean;
+    codegen: boolean;
+    componentPath: string | undefined;
+    liveComponentSources: boolean;
+  },
+) {
+  if (args.push) {
+    await watchAndPush(
+      ctx,
+      {
+        url: args.deploymentUrl,
+        adminKey: args.adminKey,
+        deploymentName: args.deploymentName,
+        verbose: false,
+        dryRun: false,
+        typecheck: args.typecheck,
+        typecheckComponents: args.typecheckComponents,
+        debug: false,
+        codegen: args.codegen,
+        liveComponentSources: args.liveComponentSources,
+      },
+      {
+        once: true,
+        traceEvents: false,
+        untilSuccess: true,
+      },
+    );
+  }
+
+  if (args.watch) {
+    return await subscribeAndLog(ctx, args);
+  }
+  return await runFunctionAndLog(ctx, args);
+}
diff --git a/synced/convex/libs/cli/lib/tracing.ts b/synced/convex/libs/cli/lib/tracing.ts
new file mode 100644
index 0000000..f8332e6
--- /dev/null
+++ b/synced/convex/libs/cli/lib/tracing.ts
@@ -0,0 +1,179 @@
+import crypto from "node:crypto";
+
+type TraceId = string; // u128
+type SpanId = string; // u64
+
+type Nanoseconds = bigint;
+
+// base64 URL encoded little endian
+type SerializedNanoseconds = string;
+
+export class Reporter {
+  spans: CompletedSpan[] = [];
+
+  emit(span: CompletedSpan) {
+    this.spans.push(span);
+  }
+}
+
+type EventRecord = {
+  name: string;
+  timestampUnixNs: Nanoseconds;
+  properties: Record<string, string>;
+};
+
+export class Span {
+  private properties: Record<string, string> = {};
+  private events: EventRecord[] = [];
+
+  private constructor(
+    private reporter: Reporter | undefined,
+    private traceId: TraceId,
+    private parentId: SpanId,
+    private spanId: SpanId,
+    private beginTimeUnixNs: Nanoseconds,
+    private name: string,
+  ) {}
+
+  static noop() {
+    return new Span(
+      undefined,
+      randomTraceId(),
+      randomSpanId(),
+      randomSpanId(),
+      unixTimeNs(),
+      "",
+    );
+  }
+
+  static root(reporter: Reporter, name: string) {
+    const traceId = randomTraceId();
+    const parentId = emptySpanId();
+    const spanId = randomSpanId();
+    const beginTimeUnixNs = unixTimeNs();
+    return new Span(reporter, traceId, parentId, spanId, beginTimeUnixNs, name);
+  }
+
+  setProperty(key: string, value: string) {
+    this.properties[key] = value;
+  }
+
+  childSpan(name: string): Span {
+    const spanId = randomSpanId();
+    const beginTimeUnixNs = unixTimeNs();
+    return new Span(
+      this.reporter,
+      this.traceId,
+      this.spanId,
+      spanId,
+      beginTimeUnixNs,
+      name,
+    );
+  }
+
+  enter<T>(name: string, f: (span: Span) => T): T {
+    const childSpan = this.childSpan(name);
+    try {
+      const result = f(childSpan);
+      childSpan.end();
+      return result;
+    } finally {
+      childSpan.end();
+    }
+  }
+
+  async enterAsync<T>(name: string, f: (span: Span) => Promise<T>): Promise<T> {
+    const childSpan = this.childSpan(name);
+    try {
+      return await f(childSpan);
+    } finally {
+      childSpan.end();
+    }
+  }
+
+  end() {
+    const endTimeUnixNs = unixTimeNs();
+    const durationNs = endTimeUnixNs - this.beginTimeUnixNs;
+    const span = {
+      traceId: this.traceId,
+      parentId: this.parentId,
+      spanId: this.spanId,
+      beginTimeUnixNs: serializeNanoseconds(this.beginTimeUnixNs),
+      durationNs: serializeNanoseconds(durationNs),
+      name: this.name,
+      properties: this.properties,
+      events: this.events.map((event) => ({
+        name: event.name,
+        timestampUnixNs: serializeNanoseconds(event.timestampUnixNs),
+        properties: event.properties,
+      })),
+    };
+    if (this.reporter) {
+      this.reporter.emit(span);
+    }
+  }
+
+  encodeW3CTraceparent() {
+    // Encode traceId and spanId as a big-endian hex strings.
+    const traceIdBytes = Buffer.from(this.traceId, "base64url");
+    const traceIdBigInt =
+      traceIdBytes.readBigUInt64LE(0) |
+      (traceIdBytes.readBigUInt64LE(8) << 64n);
+    const traceIdHex = traceIdBigInt.toString(16).padStart(32, "0");
+
+    const spanIdBytes = Buffer.from(this.spanId, "base64url");
+    const spanIdBigInt = spanIdBytes.readBigUInt64LE(0);
+    const spanIdHex = spanIdBigInt.toString(16).padStart(16, "0");
+
+    return `00-${traceIdHex}-${spanIdHex}-01`;
+  }
+}
+
+function randomTraceId() {
+  return Buffer.from(crypto.getRandomValues(new Uint8Array(16))).toString(
+    "base64url",
+  );
+}
+
+function emptySpanId() {
+  return Buffer.from(new Uint8Array(8)).toString("base64url");
+}
+
+function randomSpanId() {
+  return Buffer.from(crypto.getRandomValues(new Uint8Array(8))).toString(
+    "base64url",
+  );
+}
+
+function unixTimeNs() {
+  // Note that as a unix nanosecond timestamp, performance.timeOrigin * 1000 is less than
+  // Number.MAX_SAFE_INTEGER, so multiply by 1000 to convert to microseconds, round, convert
+  // to bigint, and then multiply again to convert to nanoseconds.
+  return (
+    BigInt(Math.floor(performance.timeOrigin * 1000)) * 1000n +
+    BigInt(Math.floor(performance.now() * 1000)) * 1000n
+  );
+}
+
+function serializeNanoseconds(ns: Nanoseconds): SerializedNanoseconds {
+  const buffer = Buffer.alloc(8);
+  buffer.writeBigUInt64LE(ns, 0);
+  return buffer.toString("base64url");
+}
+
+type CompletedSpan = {
+  traceId: TraceId;
+  parentId: SpanId;
+  spanId: SpanId;
+  beginTimeUnixNs: SerializedNanoseconds;
+  durationNs: SerializedNanoseconds;
+  name: string;
+  properties: Record<string, string>;
+  events: SerializedEventRecord[];
+};
+
+type SerializedEventRecord = {
+  name: string;
+  timestampUnixNs: SerializedNanoseconds;
+  properties: Record<string, string>;
+};
diff --git a/synced/convex/libs/cli/lib/typecheck.ts b/synced/convex/libs/cli/lib/typecheck.ts
new file mode 100644
index 0000000..cf56fb2
--- /dev/null
+++ b/synced/convex/libs/cli/lib/typecheck.ts
@@ -0,0 +1,217 @@
+import chalk from "chalk";
+import path from "path";
+import {
+  Context,
+  logError,
+  logFailure,
+  showSpinner,
+} from "../../bundler/context.js";
+import * as Sentry from "@sentry/node";
+import * as semver from "semver";
+import { spawnAsync } from "./utils/utils.js";
+
+export type TypecheckResult = "cantTypeCheck" | "success" | "typecheckFailed";
+
+export type TypeCheckMode = "enable" | "try" | "disable";
+
+type TypecheckResultHandler = (
+  result: TypecheckResult,
+  logSpecificError?: () => void,
+  // If given, we run it to print out errors.
+  // We expect it to throw or resolve to "success"
+  // if a concurrent change invalidated the error result.
+  runOnError?: () => Promise<"success">,
+) => Promise<void>;
+
+/**
+ * Conditionally run a typecheck function and interpret the result.
+ *
+ * If typeCheckMode === "disable", never run the typecheck function.
+ * If typeCheckMode === "enable", run the typecheck and crash if typechecking
+ * fails or we can't find tsc.
+ * If typeCheckMode === "try", try and run the typecheck. crash if typechecking
+ * fails but don't worry if tsc is missing and we can't run it.
+ */
+export async function typeCheckFunctionsInMode(
+  ctx: Context,
+  typeCheckMode: TypeCheckMode,
+  functionsDir: string,
+): Promise<void> {
+  if (typeCheckMode === "disable") {
+    return;
+  }
+  await typeCheckFunctions(
+    ctx,
+    functionsDir,
+    async (result, logSpecificError, runOnError) => {
+      if (
+        (result === "cantTypeCheck" && typeCheckMode === "enable") ||
+        result === "typecheckFailed"
+      ) {
+        logSpecificError?.();
+        logError(
+          ctx,
+          chalk.gray("To ignore failing typecheck, use `--typecheck=disable`."),
+        );
+        try {
+          const result = await runOnError?.();
+          // Concurrent change invalidated the error, don't fail
+          if (result === "success") {
+            return;
+          }
+        } catch {
+          // As expected, `runOnError` threw
+        }
+        await ctx.crash({
+          exitCode: 1,
+          errorType: "invalid filesystem data",
+          printedMessage: null,
+        });
+      }
+    },
+  );
+}
+
+// Runs TypeScript compiler to typecheck Convex query and mutation functions.
+export async function typeCheckFunctions(
+  ctx: Context,
+  functionsDir: string,
+  handleResult: TypecheckResultHandler,
+): Promise<void> {
+  const tsconfig = path.join(functionsDir, "tsconfig.json");
+  if (!ctx.fs.exists(tsconfig)) {
+    return handleResult("cantTypeCheck", () => {
+      logError(
+        ctx,
+        "Found no convex/tsconfig.json to use to typecheck Convex functions, so skipping typecheck.",
+      );
+      logError(ctx, "Run `npx convex codegen --init` to create one.");
+    });
+  }
+  await runTsc(ctx, ["--project", functionsDir], handleResult);
+}
+
+async function runTsc(
+  ctx: Context,
+  tscArgs: string[],
+  handleResult: TypecheckResultHandler,
+): Promise<void> {
+  // Check if tsc is even installed
+  const tscPath = path.join("node_modules", "typescript", "bin", "tsc");
+  if (!ctx.fs.exists(tscPath)) {
+    return handleResult("cantTypeCheck", () => {
+      logError(
+        ctx,
+        chalk.gray("No TypeScript binary found, so skipping typecheck."),
+      );
+    });
+  }
+
+  // Check the TypeScript version matches the recommendation from Convex
+  const versionResult = await spawnAsync(ctx, process.execPath, [
+    tscPath,
+    "--version",
+  ]);
+
+  const version = versionResult.stdout.match(/Version (.*)/)?.[1] ?? null;
+  const hasOlderTypeScriptVersion = version && semver.lt(version, "4.8.4");
+
+  await runTscInner(ctx, tscPath, tscArgs, handleResult);
+
+  // Print this warning after any logs from running `tsc`
+  if (hasOlderTypeScriptVersion) {
+    logError(
+      ctx,
+      chalk.yellow(
+        "Convex works best with TypeScript version 4.8.4 or newer -- npm i --save-dev typescript@latest to update.",
+      ),
+    );
+  }
+}
+
+async function runTscInner(
+  ctx: Context,
+  tscPath: string,
+  tscArgs: string[],
+  handleResult: TypecheckResultHandler,
+) {
+  // Run `tsc` once and have it print out the files it touched. This output won't
+  // be very useful if there's an error, but we'll run it again to get a nice
+  // user-facing error in this exceptional case.
+  // The `--listFiles` command prints out files touched on success or error.
+  const result = await spawnAsync(ctx, process.execPath, [
+    tscPath,
+    ...tscArgs,
+    "--listFiles",
+  ]);
+  if (result.status === null) {
+    return handleResult("typecheckFailed", () => {
+      logFailure(ctx, `TypeScript typecheck timed out.`);
+      if (result.error) {
+        logError(ctx, chalk.red(`${result.error.toString()}`));
+      }
+    });
+  }
+  // Okay, we may have failed `tsc` but at least it returned. Try to parse its
+  // output to discover which files it touched.
+  const filesTouched = result.stdout
+    .split("\n")
+    .map((s) => s.trim())
+    .filter((s) => s.length > 0);
+  let anyPathsFound = false;
+  for (const fileTouched of filesTouched) {
+    const absPath = path.resolve(fileTouched);
+    let st;
+    try {
+      st = ctx.fs.stat(absPath);
+      anyPathsFound = true;
+    } catch {
+      // Just move on if we have a bogus path from `tsc`. We'll log below if
+      // we fail to stat *any* of the paths emitted by `tsc`.
+      // TODO: Switch to using their JS API so we can get machine readable output.
+      continue;
+    }
+    ctx.fs.registerPath(absPath, st);
+  }
+  if (filesTouched.length > 0 && !anyPathsFound) {
+    const err = new Error(
+      `Failed to stat any files emitted by tsc (received ${filesTouched.length})`,
+    );
+    Sentry.captureException(err);
+  }
+
+  if (!result.error && result.status === 0) {
+    return handleResult("success");
+  }
+
+  // This is the "No inputs were found", which is fine and we shouldn't
+  // report it to the user.
+  if (result.stdout.startsWith("error TS18003")) {
+    return handleResult("success");
+  }
+
+  // At this point we know that `tsc` failed. Rerun it without `--listFiles`
+  // and with stderr redirected to have it print out a nice error.
+  return handleResult(
+    "typecheckFailed",
+    () => {
+      logFailure(ctx, "TypeScript typecheck via `tsc` failed.");
+    },
+    async () => {
+      showSpinner(ctx, "Collecting TypeScript errors");
+      await spawnAsync(
+        ctx,
+        process.execPath,
+        [tscPath, ...tscArgs, "--pretty", "true"],
+        {
+          stdio: "inherit",
+        },
+      );
+      // If this passes, we had a concurrent file change that'll overlap with
+      // our observations in the first run. Invalidate our context's filesystem
+      // but allow the rest of the system to observe the success.
+      ctx.fs.invalidate();
+      return "success";
+    },
+  );
+}
diff --git a/synced/convex/libs/cli/lib/usage.ts b/synced/convex/libs/cli/lib/usage.ts
new file mode 100644
index 0000000..164220a
--- /dev/null
+++ b/synced/convex/libs/cli/lib/usage.ts
@@ -0,0 +1,95 @@
+import chalk from "chalk";
+import { Context, logWarning } from "../../bundler/context.js";
+import { teamDashboardUrl } from "./dashboard.js";
+import { fetchTeamAndProject } from "./api.js";
+import { bigBrainAPI } from "./utils/utils.js";
+
+async function warn(
+  ctx: Context,
+  options: { title: string; subtitle: string; teamSlug: string },
+) {
+  const { title, subtitle, teamSlug } = options;
+  logWarning(ctx, chalk.bold.yellow(title));
+  logWarning(ctx, chalk.yellow(subtitle));
+  logWarning(
+    ctx,
+    chalk.yellow(`Visit ${teamDashboardUrl(teamSlug)} to learn more.`),
+  );
+}
+
+async function teamUsageState(ctx: Context, teamId: number) {
+  const { usageState } = (await bigBrainAPI({
+    ctx,
+    method: "GET",
+    url: "dashboard/teams/" + teamId + "/usage/team_usage_state",
+  })) as {
+    usageState: "Default" | "Approaching" | "Exceeded" | "Disabled" | "Paused";
+  };
+
+  return usageState;
+}
+
+async function teamSpendingLimitsState(ctx: Context, teamId: number) {
+  const response = (await bigBrainAPI({
+    ctx,
+    method: "GET",
+    url: "dashboard/teams/" + teamId + "/get_spending_limits",
+  })) as {
+    disableThresholdCents: number | null;
+    state: null | "Running" | "Disabled" | "Warning";
+  };
+
+  return response.state;
+}
+
+export async function usageStateWarning(
+  ctx: Context,
+  targetDeployment: string,
+) {
+  // Skip the warning if the user doesnt have an auth token
+  // (which can happen for instance when using a deploy key)
+  const auth = ctx.bigBrainAuth();
+  if (auth === null || auth.kind === "projectKey") {
+    return;
+  }
+  const { teamId, team } = await fetchTeamAndProject(ctx, targetDeployment);
+
+  const [usageState, spendingLimitsState] = await Promise.all([
+    teamUsageState(ctx, teamId),
+    teamSpendingLimitsState(ctx, teamId),
+  ]);
+  if (spendingLimitsState === "Disabled") {
+    await warn(ctx, {
+      title:
+        "Your projects are disabled because you exceeded your spending limit.",
+      subtitle: "Increase it from the dashboard to re-enable your projects.",
+      teamSlug: team,
+    });
+  } else if (usageState === "Approaching") {
+    await warn(ctx, {
+      title: "Your projects are approaching the Starter plan limits.",
+      subtitle: "Consider upgrading to avoid service interruption.",
+      teamSlug: team,
+    });
+  } else if (usageState === "Exceeded") {
+    await warn(ctx, {
+      title: "Your projects are above the Starter plan limits.",
+      subtitle: "Decrease your usage or upgrade to avoid service interruption.",
+      teamSlug: team,
+    });
+  } else if (usageState === "Disabled") {
+    await warn(ctx, {
+      title:
+        "Your projects are disabled because the team exceeded Starter plan limits.",
+      subtitle: "Decrease your usage or upgrade to reenable your projects.",
+      teamSlug: team,
+    });
+  } else if (usageState === "Paused") {
+    await warn(ctx, {
+      title:
+        "Your projects are disabled because the team previously exceeded Starter plan limits.",
+      subtitle: "Restore your projects by going to the dashboard.",
+      teamSlug: team,
+    });
+  }
+}
diff --git a/synced/convex/libs/cli/lib/utils/globalConfig.ts b/synced/convex/libs/cli/lib/utils/globalConfig.ts
new file mode 100644
index 0000000..8cc4571
--- /dev/null
+++ b/synced/convex/libs/cli/lib/utils/globalConfig.ts
@@ -0,0 +1,109 @@
+import chalk from "chalk";
+import os from "os";
+import path from "path";
+import { rootDirectory } from "./utils.js";
+import { Context, logError, logVerbose } from "../../../bundler/context.js";
+import { z } from "zod";
+
+export function globalConfigPath(): string {
+  return path.join(rootDirectory(), "config.json");
+}
+
+// GlobalConfig is stored in a file that very old versions of Convex also need to access.
+// Everything besides accessToken must be optional forever.
+// GlobalConfig is deleted on logout. It is primarily used for the accessToken.
+export type GlobalConfig = {
+  accessToken: string;
+  // Means "Don't use local dev unless CLI version is at least 1.19" (actual version TBD)
+  optOutOfLocalDevDeploymentsUntilBetaOver?: boolean;
+};
+
+const schema = z.object({
+  accessToken: z.string().min(1),
+  optOutOfLocalDevDeploymentsUntilBetaOver: z.boolean().optional(),
+});
+
+export function readGlobalConfig(ctx: Context): GlobalConfig | null {
+  const configPath = globalConfigPath();
+  let configFile;
+  try {
+    configFile = ctx.fs.readUtf8File(configPath);
+  } catch {
+    return null;
+  }
+  try {
+    const storedConfig = JSON.parse(configFile);
+    const config: GlobalConfig = schema.parse(storedConfig);
+    return config;
+  } catch (err) {
+    // Print an error and act as if the file does not exist.
+    logError(
+      ctx,
+      chalk.red(
+        `Failed to parse global config in ${configPath} with error ${
+          err as any
+        }.`,
+      ),
+    );
+    return null;
+  }
+}
+
+/** Write the global config, preserving existing properties we don't understand. */
+export async function modifyGlobalConfig(ctx: Context, config: GlobalConfig) {
+  const configPath = globalConfigPath();
+  let configFile;
+  try {
+    configFile = ctx.fs.readUtf8File(configPath);
+    // totally fine for it not to exist
+    // eslint-disable-next-line no-empty
+  } catch {}
+  // storedConfig may contain properties this version of the CLI doesn't understand.
+  let storedConfig = {};
+  if (configFile) {
+    try {
+      storedConfig = JSON.parse(configFile);
+      schema.parse(storedConfig);
+    } catch (err) {
+      logError(
+        ctx,
+        chalk.red(
+          `Failed to parse global config in ${configPath} with error ${
+            err as any
+          }.`,
+        ),
+      );
+      storedConfig = {};
+    }
+  }
+  const newConfig: GlobalConfig = { ...storedConfig, ...config };
+  await overrwriteGlobalConfig(ctx, newConfig);
+}
+
+/** Write global config, overwriting any existing settings. */
+async function overrwriteGlobalConfig(ctx: Context, config: GlobalConfig) {
+  const dirName = rootDirectory();
+  ctx.fs.mkdir(dirName, { allowExisting: true });
+  const path = globalConfigPath();
+  try {
+    ctx.fs.writeUtf8File(path, JSON.stringify(config, null, 2));
+  } catch (err) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "invalid filesystem data",
+      errForSentry: err,
+      printedMessage: chalk.red(
+        `Failed to write auth config to ${path} with error: ${err as any}`,
+      ),
+    });
+  }
+  logVerbose(ctx, `Saved credentials to ${formatPathForPrinting(path)}`);
+}
+
+export function formatPathForPrinting(path: string) {
+  const homedir = os.homedir();
+  if (process.platform === "darwin" && path.startsWith(homedir)) {
+    return path.replace(homedir, "~");
+  }
+  return path;
+}
diff --git a/synced/convex/libs/cli/lib/utils/mutex.ts b/synced/convex/libs/cli/lib/utils/mutex.ts
new file mode 100644
index 0000000..e170f20
--- /dev/null
+++ b/synced/convex/libs/cli/lib/utils/mutex.ts
@@ -0,0 +1,32 @@
+export class Mutex {
+  currentlyRunning: Promise<void> | null = null;
+  waiting: Array<() => Promise<void>> = [];
+
+  async runExclusive<T>(fn: () => Promise<T>): Promise<T> {
+    const outerPromise = new Promise<T>((resolve, reject) => {
+      const wrappedCallback: () => Promise<void> = () => {
+        return fn()
+          .then((v: T) => resolve(v))
+          .catch((e: any) => reject(e));
+      };
+      this.enqueueCallbackForMutex(wrappedCallback);
+    });
+    return outerPromise;
+  }
+
+  private enqueueCallbackForMutex(callback: () => Promise<void>) {
+    if (this.currentlyRunning === null) {
+      this.currentlyRunning = callback().finally(() => {
+        const nextCb = this.waiting.shift();
+        if (nextCb === undefined) {
+          this.currentlyRunning = null;
+        } else {
+          this.enqueueCallbackForMutex(nextCb);
+        }
+      });
+      this.waiting.length = 0;
+    } else {
+      this.waiting.push(callback);
+    }
+  }
+}
diff --git a/synced/convex/libs/cli/lib/utils/prompts.ts b/synced/convex/libs/cli/lib/utils/prompts.ts
new file mode 100644
index 0000000..5f0f3c6
--- /dev/null
+++ b/synced/convex/libs/cli/lib/utils/prompts.ts
@@ -0,0 +1,118 @@
+import inquirer from "inquirer";
+import { Context, logOutput } from "../../../bundler/context.js";
+
+export const promptString = async (
+  ctx: Context,
+  options: {
+    message: string;
+    default?: string;
+  },
+): Promise<string> => {
+  if (process.stdin.isTTY) {
+    const result = (
+      await inquirer.prompt([
+        {
+          type: "input",
+          name: "result",
+          message: options.message,
+          default: options.default,
+        },
+      ])
+    ).result;
+    return result;
+  } else {
+    return ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: "Cannot prompt for input in non-interactive terminals.",
+    });
+  }
+};
+
+export const promptOptions = async <V>(
+  ctx: Context,
+  options: {
+    message: string;
+    choices: Array<{ name: string; value: V }>;
+    default?: V;
+  },
+): Promise<V> => {
+  if (process.stdin.isTTY) {
+    const result = (
+      await inquirer.prompt([
+        {
+          // In the Convex mono-repo, `list` seems to cause the command to not
+          // respond to CTRL+C while `search-list` does not.
+          type: process.env.CONVEX_RUNNING_LIVE_IN_MONOREPO
+            ? "search-list"
+            : "list",
+          name: "result",
+          message: options.message,
+          choices: options.choices,
+          default: options.default,
+        },
+      ])
+    ).result;
+    return result;
+  } else {
+    return ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: "Cannot prompt for input in non-interactive terminals.",
+    });
+  }
+};
+
+export const promptSearch = async <V>(
+  ctx: Context,
+  options: {
+    message: string;
+    choices: Array<{ name: string; value: V }>;
+    default?: V;
+  },
+): Promise<V> => {
+  if (process.stdin.isTTY) {
+    const result = (
+      await inquirer.prompt([
+        {
+          type: "search-list",
+          name: "result",
+          message: options.message,
+          choices: options.choices,
+          default: options.default,
+        },
+      ])
+    ).result;
+    return result;
+  } else {
+    return ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: "Cannot prompt for input in non-interactive terminals.",
+    });
+  }
+};
+
+export const promptYesNo = async (
+  ctx: Context,
+  options: { message: string; default?: boolean },
+): Promise<boolean> => {
+  if (process.stdin.isTTY) {
+    const { result } = await inquirer.prompt([
+      {
+        type: "confirm",
+        name: "result",
+        message: options.message,
+        default: options.default,
+      },
+    ]);
+    return result;
+  } else {
+    logOutput(ctx, options.message);
+    return ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: "Cannot prompt for input in non-interactive terminals.",
+    });
+  }
+};
diff --git a/synced/convex/libs/cli/lib/utils/sentry.ts b/synced/convex/libs/cli/lib/utils/sentry.ts
new file mode 100644
index 0000000..e97abdf
--- /dev/null
+++ b/synced/convex/libs/cli/lib/utils/sentry.ts
@@ -0,0 +1,28 @@
+import "@sentry/tracing";
+import { productionProvisionHost, provisionHost } from "../config.js";
+import stripAnsi from "strip-ansi";
+import * as Sentry from "@sentry/node";
+import { version } from "../../../index.js";
+
+export const SENTRY_DSN =
+  "https://f9fa0306e3d540079cf40ce8c2ad9644@o1192621.ingest.sentry.io/6390839";
+
+export function initSentry() {
+  if (
+    (!process.env.CI || process.env.VERCEL === "1") &&
+    provisionHost === productionProvisionHost
+  ) {
+    Sentry.init({
+      dsn: SENTRY_DSN,
+      release: "cli@" + version,
+      tracesSampleRate: 0.2,
+      beforeBreadcrumb: (breadcrumb) => {
+        // Strip ANSI color codes from log lines that are sent as breadcrumbs.
+        if (breadcrumb.message) {
+          breadcrumb.message = stripAnsi(breadcrumb.message);
+        }
+        return breadcrumb;
+      },
+    });
+  }
+}
diff --git a/synced/convex/libs/cli/lib/utils/utils.ts b/synced/convex/libs/cli/lib/utils/utils.ts
new file mode 100644
index 0000000..b19693f
--- /dev/null
+++ b/synced/convex/libs/cli/lib/utils/utils.ts
@@ -0,0 +1,1117 @@
+import chalk from "chalk";
+import os from "os";
+import path from "path";
+
+import { ProjectConfig } from "../config.js";
+
+import { spawn } from "child_process";
+import { InvalidArgumentError } from "commander";
+import fetchRetryFactory, { RequestInitRetryParams } from "fetch-retry";
+import {
+  Context,
+  ErrorType,
+  logError,
+  logMessage,
+  logWarning,
+} from "../../../bundler/context.js";
+import { version } from "../../version.js";
+import { Project } from "../api.js";
+import { promptOptions, promptSearch, promptYesNo } from "./prompts.js";
+import {
+  bigBrainEnableFeatureMetadata,
+  projectHasExistingCloudDev,
+} from "../localDeployment/bigBrain.js";
+
+const retryingFetch = fetchRetryFactory(fetch);
+
+export const productionProvisionHost = "https://api.convex.dev";
+export const provisionHost =
+  process.env.CONVEX_PROVISION_HOST || productionProvisionHost;
+const BIG_BRAIN_URL = `${provisionHost}/api/`;
+export const ENV_VAR_FILE_PATH = ".env.local";
+export const CONVEX_DEPLOY_KEY_ENV_VAR_NAME = "CONVEX_DEPLOY_KEY";
+export const CONVEX_DEPLOYMENT_ENV_VAR_NAME = "CONVEX_DEPLOYMENT";
+export const CONVEX_SELF_HOSTED_URL_VAR_NAME = "CONVEX_SELF_HOSTED_URL";
+export const CONVEX_SELF_HOSTED_ADMIN_KEY_VAR_NAME =
+  "CONVEX_SELF_HOSTED_ADMIN_KEY";
+const MAX_RETRIES = 6;
+// After 3 retries, log a progress message that we're retrying the request
+const RETRY_LOG_THRESHOLD = 3;
+
+export function parsePositiveInteger(value: string) {
+  const parsedValue = parseInteger(value);
+  if (parsedValue <= 0) {
+    // eslint-disable-next-line no-restricted-syntax
+    throw new InvalidArgumentError("Not a positive number.");
+  }
+  return parsedValue;
+}
+
+export function parseInteger(value: string) {
+  const parsedValue = +value;
+  if (isNaN(parsedValue)) {
+    // eslint-disable-next-line no-restricted-syntax
+    throw new InvalidArgumentError("Not a number.");
+  }
+  return parsedValue;
+}
+
+export type ErrorData = {
+  code: string;
+  message: string;
+};
+
+/**
+ * Error thrown on non-2XX reponse codes to make most `fetch()` error handling
+ * follow a single code path.
+ */
+export class ThrowingFetchError extends Error {
+  response: Response;
+  serverErrorData?: ErrorData;
+
+  constructor(
+    msg: string,
+    {
+      code,
+      message,
+      response,
+    }: { cause?: Error; code?: string; message?: string; response: Response },
+  ) {
+    if (code !== undefined && message !== undefined) {
+      super(`${msg}: ${code}: ${message}`);
+      this.serverErrorData = { code, message };
+    } else {
+      super(msg);
+    }
+
+    Object.setPrototypeOf(this, ThrowingFetchError.prototype);
+
+    this.response = response;
+  }
+
+  public static async fromResponse(
+    response: Response,
+    msg?: string,
+  ): Promise<ThrowingFetchError> {
+    msg = `${msg ? `${msg} ` : ""}${response.status} ${response.statusText}`;
+    let code, message;
+    try {
+      ({ code, message } = await response.json());
+    } catch {
+      // Do nothing because the non-2XX response code is the primary error here.
+    }
+    return new ThrowingFetchError(msg, { code, message, response });
+  }
+
+  async handle(ctx: Context): Promise<never> {
+    let error_type: ErrorType = "transient";
+    await checkFetchErrorForDeprecation(ctx, this.response);
+
+    let msg = this.message;
+
+    if (this.response.status === 400) {
+      error_type = "invalid filesystem or env vars";
+    } else if (this.response.status === 401) {
+      error_type = "fatal";
+      msg = `${msg}\nAuthenticate with \`npx convex dev\``;
+    } else if (this.response.status === 404) {
+      error_type = "fatal";
+      msg = `${msg}: ${this.response.url}`;
+    }
+
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: error_type,
+      errForSentry: this,
+      printedMessage: chalk.red(msg.trim()),
+    });
+  }
+}
+
+/**
+ * Thin wrapper around `fetch()` which throws a FetchDataError on non-2XX
+ * responses which includes error code and message from the response JSON.
+ * (Axios-style)
+ *
+ * It also accepts retry options from fetch-retry.
+ */
+export async function throwingFetch(
+  resource: RequestInfo | URL,
+  options: (RequestInit & RequestInitRetryParams<typeof fetch>) | undefined,
+): Promise<Response> {
+  const Headers = globalThis.Headers;
+  const headers = new Headers((options || {})["headers"]);
+  if (options?.body) {
+    if (!headers.has("Content-Type")) {
+      headers.set("Content-Type", "application/json");
+    }
+  }
+  const response = await retryingFetch(resource, options);
+  if (!response.ok) {
+    // This error must always be handled manually.
+    // eslint-disable-next-line no-restricted-syntax
+    throw await ThrowingFetchError.fromResponse(
+      response,
+      `Error fetching ${options?.method ? options.method + " " : ""} ${
+        typeof resource === "string"
+          ? resource
+          : "url" in resource
+            ? resource.url
+            : resource.toString()
+      }`,
+    );
+  }
+  return response;
+}
+
+/**
+ * Handle an error a fetch error or non-2xx response.
+ */
+export async function logAndHandleFetchError(
+  ctx: Context,
+  err: unknown,
+): Promise<never> {
+  if (ctx.spinner) {
+    // Fail the spinner so the stderr lines appear
+    ctx.spinner.fail();
+  }
+  if (err instanceof ThrowingFetchError) {
+    return await err.handle(ctx);
+  } else {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "transient",
+      errForSentry: err,
+      printedMessage: chalk.red(err),
+    });
+  }
+}
+
+function logDeprecationWarning(ctx: Context, deprecationMessage: string) {
+  if (ctx.deprecationMessagePrinted) {
+    return;
+  }
+  ctx.deprecationMessagePrinted = true;
+  logWarning(ctx, chalk.yellow(deprecationMessage));
+}
+
+async function checkFetchErrorForDeprecation(ctx: Context, resp: Response) {
+  const headers = resp.headers;
+  if (headers) {
+    const deprecationState = headers.get("x-convex-deprecation-state");
+    const deprecationMessage = headers.get("x-convex-deprecation-message");
+    switch (deprecationState) {
+      case null:
+        break;
+      case "Deprecated":
+        // This version is deprecated. Print a warning and crash.
+
+        // Gotcha:
+        // 1. Don't use `logDeprecationWarning` because we should always print
+        // why this we crashed (even if we printed a warning earlier).
+        return await ctx.crash({
+          exitCode: 1,
+          errorType: "fatal",
+          printedMessage: chalk.red(deprecationMessage),
+        });
+      default:
+        // The error included a deprecation warning. Print, but handle the
+        // error normally (it was for another reason).
+        logDeprecationWarning(
+          ctx,
+          deprecationMessage || "(no deprecation message included)",
+        );
+        break;
+    }
+  }
+}
+
+/// Call this method after a successful API response to conditionally print the
+/// "please upgrade" message.
+export function deprecationCheckWarning(ctx: Context, resp: Response) {
+  const headers = resp.headers;
+  if (headers) {
+    const deprecationState = headers.get("x-convex-deprecation-state");
+    const deprecationMessage = headers.get("x-convex-deprecation-message");
+    switch (deprecationState) {
+      case null:
+        break;
+      case "Deprecated":
+        // This should never happen because such states are errors, not warnings.
+        // eslint-disable-next-line no-restricted-syntax
+        throw new Error(
+          "Called deprecationCheckWarning on a fatal error. This is a bug.",
+        );
+      default:
+        logDeprecationWarning(
+          ctx,
+          deprecationMessage || "(no deprecation message included)",
+        );
+        break;
+    }
+  }
+}
+
+type Team = {
+  id: number;
+  name: string;
+  slug: string;
+};
+
+export async function hasTeam(ctx: Context, teamSlug: string) {
+  const teams: Team[] = await bigBrainAPI({ ctx, method: "GET", url: "teams" });
+  return teams.some((team) => team.slug === teamSlug);
+}
+
+export async function validateOrSelectTeam(
+  ctx: Context,
+  teamSlug: string | undefined,
+  promptMessage: string,
+): Promise<{ teamSlug: string; chosen: boolean }> {
+  const teams: Team[] = await bigBrainAPI({ ctx, method: "GET", url: "teams" });
+  if (teams.length === 0) {
+    await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      errForSentry: "No teams found",
+      printedMessage: chalk.red("Error: No teams found"),
+    });
+  }
+  if (!teamSlug) {
+    // Prompt the user to select if they belong to more than one team.
+    switch (teams.length) {
+      case 1:
+        return { teamSlug: teams[0].slug, chosen: false };
+      default:
+        return {
+          teamSlug: await promptSearch(ctx, {
+            message: promptMessage,
+            choices: teams.map((team: Team) => ({
+              name: `${team.name} (${team.slug})`,
+              value: team.slug,
+            })),
+          }),
+          chosen: true,
+        };
+    }
+  } else {
+    // Validate the chosen team.
+    if (!teams.find((team) => team.slug === teamSlug)) {
+      await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage: `Error: Team ${teamSlug} not found, fix the --team option or remove it`,
+      });
+    }
+    return { teamSlug, chosen: false };
+  }
+}
+
+export async function selectDevDeploymentType(
+  ctx: Context,
+  {
+    chosenConfiguration,
+    newOrExisting,
+    teamSlug,
+    projectSlug,
+    userHasChosenSomethingInteractively,
+    // from `--configure --dev-deployment local|cloud`
+    devDeploymentFromFlag,
+    // from `--cloud or --local`
+    forceDevDeployment,
+  }:
+    | {
+        chosenConfiguration: "new" | "existing" | "ask" | null;
+        newOrExisting: "existing";
+        teamSlug: string;
+        projectSlug: string;
+        userHasChosenSomethingInteractively: boolean;
+        devDeploymentFromFlag: "cloud" | "local" | undefined;
+        forceDevDeployment: "cloud" | "local" | undefined;
+      }
+    | {
+        chosenConfiguration: "new" | "existing" | "ask" | null;
+        newOrExisting: "new";
+        teamSlug: string;
+        // For new projects we don't know the project slug yet.
+        projectSlug: undefined;
+        userHasChosenSomethingInteractively: boolean;
+        devDeploymentFromFlag: "cloud" | "local" | undefined;
+        forceDevDeployment: "cloud" | "local" | undefined;
+      },
+): Promise<{ devDeployment: "cloud" | "local" }> {
+  if (forceDevDeployment) return { devDeployment: forceDevDeployment };
+  if (devDeploymentFromFlag) return { devDeployment: devDeploymentFromFlag };
+
+  if (newOrExisting === "existing" && chosenConfiguration === null) {
+    // Don't suggest local dev if developer already has a cloud deployment.
+    if (await projectHasExistingCloudDev(ctx, { projectSlug, teamSlug })) {
+      // TODO Expand rollout to offer local dev in this case. ENG-8307
+      return { devDeployment: "cloud" };
+    }
+  }
+
+  // To avoid breaking previously non-interactive flows, don't prompt if enough
+  // flags were specified for configure not to already have needed input.
+  if (chosenConfiguration !== "ask" && !userHasChosenSomethingInteractively) {
+    return { devDeployment: "cloud" };
+  }
+
+  // For creating a first project (no projects exist) or joining a first project
+  // (one project exists), always use cloud since it's a smoother experience.
+  const isFirstProject =
+    (await bigBrainEnableFeatureMetadata(ctx)).totalProjects.kind !==
+    "multiple";
+  if (isFirstProject) {
+    return { devDeployment: "cloud" };
+  }
+
+  // For now default is always cloud.
+  const devDeployment: "cloud" | "local" = await promptOptions(ctx, {
+    message:
+      "Use cloud or local dev deployment? For more see https://docs.convex.dev/cli/local-deployments",
+    default: "cloud",
+    choices: [
+      { name: "cloud deployment", value: "cloud" },
+      { name: "local deployment (BETA)", value: "local" },
+    ],
+  });
+  return { devDeployment };
+}
+
+export async function hasProject(
+  ctx: Context,
+  teamSlug: string,
+  projectSlug: string,
+) {
+  try {
+    const projects: Project[] = await bigBrainAPIMaybeThrows({
+      ctx,
+      method: "GET",
+      url: `teams/${teamSlug}/projects`,
+    });
+    return !!projects.find((project) => project.slug === projectSlug);
+  } catch {
+    return false;
+  }
+}
+
+export async function hasProjects(ctx: Context) {
+  return !!(await bigBrainAPI({ ctx, method: "GET", url: `has_projects` }));
+}
+
+export async function validateOrSelectProject(
+  ctx: Context,
+  projectSlug: string | undefined,
+  teamSlug: string,
+  singleProjectPrompt: string,
+  multiProjectPrompt: string,
+): Promise<string | null> {
+  const projects: Project[] = await bigBrainAPI({
+    ctx,
+    method: "GET",
+    url: `teams/${teamSlug}/projects`,
+  });
+  if (projects.length === 0) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "fatal",
+      printedMessage: `No existing projects! Run this command again and choose "create a new project."`,
+    });
+  }
+  if (!projectSlug) {
+    const nonDemoProjects = projects.filter((project) => !project.isDemo);
+    if (nonDemoProjects.length === 0) {
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage: `No existing non-demo projects! Run this command again and choose "create a new project."`,
+      });
+    }
+    // Prompt the user to select project.
+    switch (nonDemoProjects.length) {
+      case 1: {
+        const project = nonDemoProjects[0];
+        const confirmed = await promptYesNo(ctx, {
+          message: `${singleProjectPrompt} ${project.name} (${project.slug})?`,
+        });
+
+        if (!confirmed) {
+          return null;
+        }
+        return nonDemoProjects[0].slug;
+      }
+      default:
+        return await promptSearch(ctx, {
+          message: multiProjectPrompt,
+          choices: nonDemoProjects.map((project: Project) => ({
+            name: `${project.name} (${project.slug})`,
+            value: project.slug,
+          })),
+        });
+    }
+  } else {
+    // Validate the chosen project.
+    if (!projects.find((project) => project.slug === projectSlug)) {
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage: `Error: Project ${projectSlug} not found, fix the --project option or remove it`,
+      });
+    }
+    return projectSlug;
+  }
+}
+
+/**
+ * @param ctx
+ * @returns a Record of dependency name to dependency version for dependencies
+ * and devDependencies
+ */
+export async function loadPackageJson(
+  ctx: Context,
+  includePeerDeps = false,
+): Promise<Record<string, string>> {
+  let packageJson;
+  try {
+    packageJson = ctx.fs.readUtf8File("package.json");
+  } catch (err) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "invalid filesystem data",
+      printedMessage: `Unable to read your package.json: ${
+        err as any
+      }. Make sure you're running this command from the root directory of a Convex app that contains the package.json`,
+    });
+  }
+  let obj;
+  try {
+    obj = JSON.parse(packageJson);
+  } catch (err) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "invalid filesystem data",
+      errForSentry: err,
+      printedMessage: `Unable to parse package.json: ${err as any}`,
+    });
+  }
+  if (typeof obj !== "object") {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "invalid filesystem data",
+      printedMessage: "Expected to parse an object from package.json",
+    });
+  }
+  const packages = {
+    ...(includePeerDeps ? (obj.peerDependencies ?? {}) : {}),
+    ...(obj.dependencies ?? {}),
+    ...(obj.devDependencies ?? {}),
+  };
+  return packages;
+}
+
+export async function ensureHasConvexDependency(ctx: Context, cmd: string) {
+  const packages = await loadPackageJson(ctx, true);
+  const hasConvexDependency = "convex" in packages;
+  if (!hasConvexDependency) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "invalid filesystem data",
+      printedMessage: `In order to ${cmd}, add \`convex\` to your package.json dependencies.`,
+    });
+  }
+}
+
+/** Return a new array with elements of the passed in array sorted by a key lambda */
+export const sorted = <T>(arr: T[], key: (el: T) => any): T[] => {
+  const newArr = [...arr];
+  const cmp = (a: T, b: T) => {
+    if (key(a) < key(b)) return -1;
+    if (key(a) > key(b)) return 1;
+    return 0;
+  };
+  return newArr.sort(cmp);
+};
+
+export function functionsDir(
+  configPath: string,
+  projectConfig: ProjectConfig,
+): string {
+  return path.join(path.dirname(configPath), projectConfig.functions);
+}
+
+function convexName() {
+  // Use a different directory for config files generated for tests
+  if (process.env.CONVEX_PROVISION_HOST) {
+    const port = process.env.CONVEX_PROVISION_HOST.split(":")[2];
+    if (port === undefined || port === "8050") {
+      return `convex-test`;
+    } else {
+      return `convex-test-${port}`;
+    }
+  }
+  return "convex";
+}
+
+export function rootDirectory(): string {
+  return path.join(os.homedir(), `.${convexName()}`);
+}
+
+export function cacheDir() {
+  const name = convexName();
+  const platform = process.platform;
+  if (platform === "win32") {
+    // On Windows, `LOCALAPPDATA` is usually set, but fall back to
+    // `USERPROFILE` if not, and fall back to homedir if all else fails.
+    if (process.env.LOCALAPPDATA) {
+      return path.join(process.env.LOCALAPPDATA, name);
+    }
+    if (process.env.USERPROFILE) {
+      return path.join(process.env.USERPROFILE, "AppData", "Local", name);
+    }
+    return path.join(os.homedir(), "AppData", "Local", name);
+  }
+  return path.join(os.homedir(), ".cache", name);
+}
+
+export async function bigBrainFetch(ctx: Context): Promise<typeof fetch> {
+  const authHeader = await ctx.bigBrainAuth()?.header;
+  const bigBrainHeaders: Record<string, string> = authHeader
+    ? {
+        Authorization: authHeader,
+        "Convex-Client": `npm-cli-${version}`,
+      }
+    : {
+        "Convex-Client": `npm-cli-${version}`,
+      };
+  return (resource: RequestInfo | URL, options: RequestInit | undefined) => {
+    const { headers: optionsHeaders, ...rest } = options || {};
+    const headers = {
+      ...bigBrainHeaders,
+      ...(optionsHeaders || {}),
+    };
+    const opts = {
+      retries: MAX_RETRIES,
+      retryDelay,
+      headers,
+      ...rest,
+    };
+
+    const url =
+      resource instanceof URL
+        ? resource.pathname
+        : typeof resource === "string"
+          ? new URL(resource, BIG_BRAIN_URL)
+          : new URL(resource.url, BIG_BRAIN_URL);
+    return throwingFetch(url, opts);
+  };
+}
+
+export async function bigBrainAPI<T = any>({
+  ctx,
+  method,
+  url,
+  data,
+}: {
+  ctx: Context;
+  method: string;
+  url: string;
+  data?: any;
+}): Promise<T> {
+  const dataString =
+    data === undefined
+      ? undefined
+      : typeof data === "string"
+        ? data
+        : JSON.stringify(data);
+  try {
+    return await bigBrainAPIMaybeThrows({
+      ctx,
+      method,
+      url,
+      data: dataString,
+    });
+  } catch (err: unknown) {
+    return await logAndHandleFetchError(ctx, err);
+  }
+}
+
+export async function bigBrainAPIMaybeThrows({
+  ctx,
+  method,
+  url,
+  data,
+}: {
+  ctx: Context;
+  method: string;
+  url: string;
+  data?: any;
+}): Promise<any> {
+  const fetch = await bigBrainFetch(ctx);
+  const dataString =
+    data === undefined
+      ? method === "POST" || method === "post"
+        ? JSON.stringify({})
+        : undefined
+      : typeof data === "string"
+        ? data
+        : JSON.stringify(data);
+  const res = await fetch(url, {
+    method,
+    ...(dataString ? { body: dataString } : {}),
+    headers:
+      method === "POST" || method === "post"
+        ? {
+            "Content-Type": "application/json",
+          }
+        : {},
+  });
+  deprecationCheckWarning(ctx, res);
+  if (res.status === 200) {
+    return await res.json();
+  }
+}
+
+/**
+ * Polls an arbitrary function until a condition is met.
+ *
+ * @param fetch Function performing a fetch, returning resulting data.
+ * @param condition This function will terminate polling when it returns `true`.
+ * @param waitMs How long to wait in between fetches.
+ * @returns The resulting data from `fetch`.
+ */
+export const poll = async function <Result>(
+  fetch: () => Promise<Result>,
+  condition: (data: Result) => boolean,
+  waitMs = 1000,
+) {
+  let result = await fetch();
+  while (!condition(result)) {
+    await wait(waitMs);
+    result = await fetch();
+  }
+  return result;
+};
+
+const wait = function (waitMs: number) {
+  return new Promise((resolve) => {
+    setTimeout(resolve, waitMs);
+  });
+};
+
+export function waitForever() {
+  // This never resolves
+  return new Promise((_) => {
+    // ignore
+  });
+}
+
+// Returns a promise and a function that resolves the promise.
+export function waitUntilCalled(): [Promise<unknown>, () => void] {
+  let onCalled: (v: unknown) => void;
+  const waitPromise = new Promise((resolve) => (onCalled = resolve));
+  return [waitPromise, () => onCalled(null)];
+}
+
+// We can eventually switch to something like `filesize` for i18n and
+// more robust formatting, but let's keep our CLI bundle small for now.
+export function formatSize(n: number): string {
+  if (n < 1024) {
+    return `${n} B`;
+  }
+  if (n < 1024 * 1024) {
+    return `${(n / 1024).toFixed(1)} KB`;
+  }
+  if (n < 1024 * 1024 * 1024) {
+    return `${(n / 1024 / 1024).toFixed(1)} MB`;
+  }
+  return `${(n / 1024 / 1024 / 1024).toFixed(2)} GB`;
+}
+
+export function formatDuration(ms: number): string {
+  const twoDigits = (n: number, unit: string) =>
+    `${n.toLocaleString("en-US", { maximumFractionDigits: 2 })}${unit}`;
+
+  if (ms < 1e-3) {
+    return twoDigits(ms * 1e9, "ns");
+  }
+  if (ms < 1) {
+    return twoDigits(ms * 1e3, "s");
+  }
+  if (ms < 1e3) {
+    return twoDigits(ms, "ms");
+  }
+  const s = ms / 1e3;
+  if (s < 60) {
+    return twoDigits(ms / 1e3, "s");
+  }
+  return twoDigits(s / 60, "m");
+}
+
+export function getCurrentTimeString() {
+  const now = new Date();
+  const hours = String(now.getHours()).padStart(2, "0");
+  const minutes = String(now.getMinutes()).padStart(2, "0");
+  const seconds = String(now.getSeconds()).padStart(2, "0");
+  return `${hours}:${minutes}:${seconds}`;
+}
+
+// We don't allow running commands in project subdirectories yet,
+// but we can provide better errors if we look around.
+export async function findParentConfigs(ctx: Context): Promise<{
+  parentPackageJson: string;
+  parentConvexJson?: string;
+}> {
+  const parentPackageJson = findUp(ctx, "package.json");
+  if (!parentPackageJson) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "invalid filesystem data",
+      printedMessage:
+        "No package.json found. To create a new project using Convex, see https://docs.convex.dev/home#quickstarts",
+    });
+  }
+  const candidateConvexJson =
+    parentPackageJson &&
+    path.join(path.dirname(parentPackageJson), "convex.json");
+  const parentConvexJson =
+    candidateConvexJson && ctx.fs.exists(candidateConvexJson)
+      ? candidateConvexJson
+      : undefined;
+  return {
+    parentPackageJson,
+    parentConvexJson,
+  };
+}
+
+/**
+ * Finds a file in the current working directory or a parent.
+ *
+ * @returns The absolute path of the first file found or undefined.
+ */
+function findUp(ctx: Context, filename: string): string | undefined {
+  let curDir = path.resolve(".");
+  let parentDir = curDir;
+  do {
+    const candidate = path.join(curDir, filename);
+    if (ctx.fs.exists(candidate)) {
+      return candidate;
+    }
+    curDir = parentDir;
+    parentDir = path.dirname(curDir);
+  } while (parentDir !== curDir);
+  return;
+}
+
+/**
+ * Returns whether there's an existing project config. Throws
+ * if this is not a valid directory for a project config.
+ */
+export async function isInExistingProject(ctx: Context) {
+  const { parentPackageJson, parentConvexJson } = await findParentConfigs(ctx);
+  if (parentPackageJson !== path.resolve("package.json")) {
+    return await ctx.crash({
+      exitCode: 1,
+      errorType: "invalid filesystem data",
+      printedMessage: "Run this command from the root directory of a project.",
+    });
+  }
+  return !!parentConvexJson;
+}
+
+// `spawnAsync` is the async version of Node's `spawnSync` (and `spawn`).
+//
+// By default, this returns the produced `stdout` and `stderror` and
+// an error if one was encountered (to mirror `spawnSync`).
+//
+// If `stdio` is set to `"inherit"`, pipes `stdout` and `stderror` (
+// pausing the spinner if one is running) and rejects the promise
+// on errors (to mirror `execFileSync`).
+export function spawnAsync(
+  ctx: Context,
+  command: string,
+  args: ReadonlyArray<string>,
+): Promise<{
+  stdout: string;
+  stderr: string;
+  status: null | number;
+  error?: Error | undefined;
+}>;
+export function spawnAsync(
+  ctx: Context,
+  command: string,
+  args: ReadonlyArray<string>,
+  options: { stdio: "inherit"; shell?: boolean },
+): Promise<void>;
+export function spawnAsync(
+  ctx: Context,
+  command: string,
+  args: ReadonlyArray<string>,
+  options?: { stdio: "inherit"; shell?: boolean },
+) {
+  return new Promise((resolve, reject) => {
+    const child = spawn(command, args, { shell: options?.shell });
+    let stdout = "";
+    let stderr = "";
+
+    const pipeOutput = options?.stdio === "inherit";
+
+    if (pipeOutput) {
+      child.stdout.on("data", (text) =>
+        logMessage(ctx, text.toString("utf-8").trimEnd()),
+      );
+      child.stderr.on("data", (text) =>
+        logError(ctx, text.toString("utf-8").trimEnd()),
+      );
+    } else {
+      child.stdout.on("data", (data) => {
+        stdout += data.toString("utf-8");
+      });
+
+      child.stderr.on("data", (data) => {
+        stderr += data.toString("utf-8");
+      });
+    }
+
+    const completionListener = (code: number | null) => {
+      child.removeListener("error", errorListener);
+      const result = pipeOutput
+        ? { status: code }
+        : { stdout, stderr, status: code };
+      if (code !== 0) {
+        const argumentString =
+          args && args.length > 0 ? ` ${args.join(" ")}` : "";
+        const error = new Error(
+          `\`${command}${argumentString}\` exited with non-zero code: ${code}`,
+        );
+        if (pipeOutput) {
+          reject({ ...result, error });
+        } else {
+          resolve({ ...result, error });
+        }
+      } else {
+        resolve(result);
+      }
+    };
+
+    const errorListener = (error: Error) => {
+      child.removeListener("exit", completionListener);
+      child.removeListener("close", completionListener);
+      if (pipeOutput) {
+        reject({ error, status: null });
+      } else {
+        resolve({ error, status: null });
+      }
+    };
+
+    if (pipeOutput) {
+      child.once("exit", completionListener);
+    } else {
+      child.once("close", completionListener);
+    }
+    child.once("error", errorListener);
+  });
+}
+
+const IDEMPOTENT_METHODS = ["GET", "HEAD", "PUT", "DELETE", "OPTIONS", "TRACE"];
+
+function retryDelay(
+  attempt: number,
+  _error: Error | null,
+  _response: Response | null,
+): number {
+  // immediate, 1s delay, 2s delay, 4s delay, etc.
+  const delay = attempt === 0 ? 1 : 2 ** (attempt - 1) * 1000;
+  const randomSum = delay * 0.2 * Math.random();
+  return delay + randomSum;
+}
+
+function deploymentFetchRetryOn(
+  onError?: (err: any, attempt: number) => void,
+  method?: string,
+) {
+  const shouldRetry = function (
+    attempt: number,
+    error: Error | null,
+    response: Response | null,
+  ): { kind: "retry"; error: any } | { kind: "stop" } {
+    // Retry on network errors.
+    if (error !== null) {
+      // TODO filter out all SSL errors
+      // https://github.com/nodejs/node/blob/8a41d9b636be86350cd32847c3f89d327c4f6ff7/src/crypto/crypto_common.cc#L218-L245
+      return { kind: "retry", error: error };
+    }
+    // Retry on 404s since these can sometimes happen with newly created
+    // deployments for POSTs.
+    if (response?.status === 404) {
+      return {
+        kind: "retry",
+        error: `Received response with status ${response.status}`,
+      };
+    }
+
+    // Whatever the error code it doesn't hurt to retry idempotent requests.
+    if (
+      response &&
+      !response.ok &&
+      method &&
+      IDEMPOTENT_METHODS.includes(method.toUpperCase())
+    ) {
+      // ...but it's a bit annoying to wait for things we know won't succced
+      if (
+        [
+          400, // Bad Request
+          401, // Unauthorized
+          402, // PaymentRequired
+          403, // Forbidden
+          405, // Method Not Allowed
+          406, // Not Acceptable
+          412, // Precondition Failed
+          413, // Payload Too Large
+          414, // URI Too Long
+          415, // Unsupported Media Type
+          416, // Range Not Satisfiable
+        ].includes(response.status)
+      ) {
+        return {
+          kind: "stop",
+        };
+      }
+      return {
+        kind: "retry",
+        error: `Received response with status ${response.status}`,
+      };
+    }
+
+    return { kind: "stop" };
+  };
+
+  return function (
+    attempt: number,
+    error: Error | null,
+    response: Response | null,
+  ) {
+    const result = shouldRetry(attempt, error, response);
+    if (result.kind === "retry") {
+      onError?.(result.error, attempt);
+    }
+    if (attempt >= MAX_RETRIES) {
+      // Stop retrying if we've exhausted all retries, but do this after we've
+      // called `onError` so that the caller can still log the error.
+      return false;
+    }
+    return result.kind === "retry";
+  };
+}
+
+/**
+ * Unlike `deploymentFetch`, this does not add on any headers, so the caller
+ * must supply any headers.
+ */
+export function bareDeploymentFetch(
+  ctx: Context,
+  options: {
+    deploymentUrl: string;
+    onError?: (err: any) => void;
+  },
+): typeof throwingFetch {
+  const { deploymentUrl, onError } = options;
+  const onErrorWithAttempt = (err: any, attempt: number) => {
+    onError?.(err);
+    if (attempt >= RETRY_LOG_THRESHOLD) {
+      logMessage(
+        ctx,
+        chalk.gray(`Retrying request (attempt ${attempt}/${MAX_RETRIES})...`),
+      );
+    }
+  };
+  return (resource: RequestInfo | URL, options: RequestInit | undefined) => {
+    const url =
+      resource instanceof URL
+        ? resource.pathname
+        : typeof resource === "string"
+          ? new URL(resource, deploymentUrl)
+          : new URL(resource.url, deploymentUrl);
+    const func = throwingFetch(url, {
+      retryDelay,
+      retryOn: deploymentFetchRetryOn(onErrorWithAttempt, options?.method),
+      ...options,
+    });
+    return func;
+  };
+}
+
+/**
+ * This returns a `fetch` function that will fetch against `deploymentUrl`.
+ *
+ * It will also set the `Authorization` header, `Content-Type` header, and
+ * the `Convex-Client` header if they are not set in the `fetch`.
+ */
+export function deploymentFetch(
+  ctx: Context,
+  options: {
+    deploymentUrl: string;
+    adminKey: string;
+    onError?: (err: any) => void;
+  },
+): typeof throwingFetch {
+  const { deploymentUrl, adminKey, onError } = options;
+  const onErrorWithAttempt = (err: any, attempt: number) => {
+    onError?.(err);
+    if (attempt >= RETRY_LOG_THRESHOLD) {
+      logMessage(
+        ctx,
+        chalk.gray(`Retrying request (attempt ${attempt}/${MAX_RETRIES})...`),
+      );
+    }
+  };
+  return (resource: RequestInfo | URL, options: RequestInit | undefined) => {
+    const url =
+      resource instanceof URL
+        ? resource.pathname
+        : typeof resource === "string"
+          ? new URL(resource, deploymentUrl)
+          : new URL(resource.url, deploymentUrl);
+
+    const headers = new Headers(options?.headers || {});
+    if (!headers.has("Authorization")) {
+      headers.set("Authorization", `Convex ${adminKey}`);
+    }
+    if (!headers.has("Content-Type")) {
+      headers.set("Content-Type", "application/json");
+    }
+    if (!headers.has("Convex-Client")) {
+      headers.set("Convex-Client", `npm-cli-${version}`);
+    }
+    const func = throwingFetch(url, {
+      retryDelay,
+      retryOn: deploymentFetchRetryOn(onErrorWithAttempt, options?.method),
+      ...options,
+      headers,
+    });
+    return func;
+  };
+}
+
+/**
+ * Whether this is likely to be a WebContainer,
+ * WebContainers can't complete the Auth0 login but where that login flow
+ * fails has changed with the environment.
+ */
+export function isWebContainer(): boolean {
+  // Dynamic require as used here doesn't work with tsx
+  if (process.env.CONVEX_RUNNING_LIVE_IN_MONOREPO) {
+    return false;
+  }
+  const dynamicRequire = require;
+  if (process.versions.webcontainer === undefined) {
+    return false;
+  }
+  let blitzInternalEnv: unknown;
+  try {
+    blitzInternalEnv = dynamicRequire("@blitz/internal/env");
+    // totally fine for this require to fail
+    // eslint-disable-next-line no-empty
+  } catch {}
+  return blitzInternalEnv !== null && blitzInternalEnv !== undefined;
+}
diff --git a/synced/convex/libs/cli/lib/watch.ts b/synced/convex/libs/cli/lib/watch.ts
new file mode 100644
index 0000000..fec2610
--- /dev/null
+++ b/synced/convex/libs/cli/lib/watch.ts
@@ -0,0 +1,157 @@
+import chokidar from "chokidar";
+import path from "path";
+import { Observations, RecordingFs, WatchEvent } from "../../bundler/fs.js";
+import {
+  BigBrainAuth,
+  Context,
+  ErrorType,
+  logFailure,
+} from "../../bundler/context.js";
+import * as Sentry from "@sentry/node";
+import { Ora } from "ora";
+
+export class Watcher {
+  private watch: chokidar.FSWatcher;
+  private readyCb: Promise<void>;
+
+  private bufferedEvents: WatchEvent[];
+  private waiters: (() => void)[];
+
+  constructor(observations: Observations) {
+    this.bufferedEvents = [];
+    this.waiters = [];
+
+    const watch = chokidar.watch(observations.paths(), { persistent: true });
+    watch.on("all", (eventName, eventPath) => {
+      const absPath = path.resolve(eventPath);
+      this.bufferedEvents.push({ name: eventName, absPath });
+      for (const waiter of drain(this.waiters)) {
+        waiter();
+      }
+    });
+    this.readyCb = new Promise<void>((resolve) => {
+      watch.on("ready", () => resolve());
+    });
+    this.watch = watch;
+  }
+
+  update(observations: Observations) {
+    const watchedDirs = new Set(Object.keys(this.watch.getWatched()));
+    for (const newPath of observations.paths()) {
+      if (!this.isWatched(watchedDirs, newPath)) {
+        this.watch.add(newPath);
+      }
+    }
+  }
+
+  isWatched(watchedDirs: Set<string>, observedPath: string) {
+    // Walk over all of path's parents (inclusively) to see if any of them are in the watch set.
+    // This function assumes that Chokidar recursively watches all directories, which is
+    // definitely true on Mac with its FSEvents-based watcher.
+    // TODO (CX-2151): Verify this condition on Windows and Linux.
+    let curPath = observedPath;
+    while (true) {
+      const parsed = path.parse(curPath);
+
+      // TODO(CX-2152): Check to see if this condition for walking parents works on Windows.
+      if (parsed.dir === curPath) {
+        break;
+      }
+      if (watchedDirs.has(curPath)) {
+        return true;
+      }
+      curPath = parsed.dir;
+    }
+    return false;
+  }
+
+  async ready(): Promise<void> {
+    await this.readyCb;
+  }
+
+  async waitForEvent(): Promise<void> {
+    while (this.bufferedEvents.length === 0) {
+      const newEvent = new Promise<void>((resolve) => {
+        this.waiters.push(resolve);
+      });
+      await newEvent;
+    }
+  }
+
+  drainEvents(): WatchEvent[] {
+    return drain(this.bufferedEvents);
+  }
+
+  async close() {
+    await this.watch.close();
+  }
+}
+function drain<T>(l: T[]): T[] {
+  return l.splice(0, l.length);
+}
+
+export class Crash extends Error {
+  errorType?: ErrorType;
+
+  constructor(errorType?: ErrorType, err?: any) {
+    super(err?.message);
+    this.errorType = errorType;
+  }
+}
+
+export class WatchContext implements Context {
+  private _cleanupFns: Record<
+    string,
+    (exitCode: number, err?: any) => Promise<void>
+  > = {};
+  fs: RecordingFs;
+  deprecationMessagePrinted: boolean;
+  spinner: Ora | undefined;
+  private _bigBrainAuth: BigBrainAuth | null;
+
+  constructor(traceEvents: boolean, bigBrainAuth: BigBrainAuth | null) {
+    this.fs = new RecordingFs(traceEvents);
+    this.deprecationMessagePrinted = false;
+    this._bigBrainAuth = bigBrainAuth;
+  }
+
+  async crash(args: {
+    exitCode: number;
+    errorType?: ErrorType;
+    errForSentry?: any;
+    printedMessage: string | null;
+  }): Promise<never> {
+    if (args.errForSentry) {
+      Sentry.captureException(args.errForSentry);
+    }
+    if (args.printedMessage !== null) {
+      logFailure(this, args.printedMessage);
+    }
+    for (const fn of Object.values(this._cleanupFns)) {
+      await fn(args.exitCode, args.errForSentry);
+    }
+    // Okay to throw here. We've wrapped it in a Crash that we'll catch later.
+    // eslint-disable-next-line no-restricted-syntax
+    throw new Crash(args.errorType, args.errForSentry);
+  }
+
+  registerCleanup(fn: (exitCode: number, err?: any) => Promise<void>): string {
+    const handle = Math.random().toString(36).slice(2);
+    this._cleanupFns[handle] = fn;
+    return handle;
+  }
+
+  removeCleanup(handle: string) {
+    const value = this._cleanupFns[handle];
+    delete this._cleanupFns[handle];
+    return value ?? null;
+  }
+
+  bigBrainAuth(): BigBrainAuth | null {
+    return this._bigBrainAuth;
+  }
+
+  _updateBigBrainAuth(auth: BigBrainAuth | null): void {
+    this._bigBrainAuth = auth;
+  }
+}
diff --git a/synced/convex/libs/cli/login.ts b/synced/convex/libs/cli/login.ts
new file mode 100644
index 0000000..37baeda
--- /dev/null
+++ b/synced/convex/libs/cli/login.ts
@@ -0,0 +1,317 @@
+import { Command, Option } from "@commander-js/extra-typings";
+import {
+  Context,
+  logFailure,
+  logFinishedStep,
+  logMessage,
+  oneoffContext,
+} from "../bundler/context.js";
+import { checkAuthorization, performLogin } from "./lib/login.js";
+import { loadUuidForAnonymousUser } from "./lib/localDeployment/filePaths.js";
+import {
+  handleLinkToProject,
+  listExistingAnonymousDeployments,
+} from "./lib/localDeployment/anonymous.js";
+import {
+  DASHBOARD_HOST,
+  deploymentDashboardUrlPage,
+  teamDashboardUrl,
+} from "./lib/dashboard.js";
+import { promptSearch, promptYesNo } from "./lib/utils/prompts.js";
+import { bigBrainAPI, validateOrSelectTeam } from "./lib/utils/utils.js";
+import {
+  selectProject,
+  updateEnvAndConfigForDeploymentSelection,
+} from "./configure.js";
+import {
+  getDeploymentSelection,
+  shouldAllowAnonymousDevelopment,
+} from "./lib/deploymentSelection.js";
+import { removeAnonymousPrefix } from "./lib/deployment.js";
+
+export const login = new Command("login")
+  .description("Login to Convex")
+  .allowExcessArguments(false)
+  .option(
+    "--device-name <name>",
+    "Provide a name for the device being authorized",
+  )
+  .option(
+    "-f, --force",
+    "Proceed with login even if a valid access token already exists for this device",
+  )
+  .option(
+    "--no-open",
+    "Don't automatically open the login link in the default browser",
+  )
+  .addOption(
+    new Option(
+      "--login-flow <mode>",
+      `How to log in; defaults to guessing based on the environment.`,
+    )
+      .choices(["paste", "auto", "poll"] as const)
+      .default("auto" as const),
+  )
+  .addOption(new Option("--link-deployments").hideHelp())
+  // These options are hidden from the help/usage message, but allow overriding settings for testing.
+  // Change the auth credentials with the auth provider
+  .addOption(new Option("--override-auth-url <url>").hideHelp())
+  .addOption(new Option("--override-auth-client <id>").hideHelp())
+  .addOption(new Option("--override-auth-username <username>").hideHelp())
+  .addOption(new Option("--override-auth-password <password>").hideHelp())
+  // Skip the auth provider login and directly use this access token
+  .addOption(new Option("--override-access-token <token>").hideHelp())
+  // Automatically accept opt ins without prompting
+  .addOption(new Option("--accept-opt-ins").hideHelp())
+  // Dump the access token from the auth provider and skip authorization with Convex
+  .addOption(new Option("--dump-access-token").hideHelp())
+  // Hidden option for tests to check if the user is logged in.
+  .addOption(new Option("--check-login").hideHelp())
+  .action(async (options, cmd: Command) => {
+    const ctx = await oneoffContext({
+      url: undefined,
+      adminKey: undefined,
+      envFile: undefined,
+    });
+    if (
+      !options.force &&
+      (await checkAuthorization(ctx, !!options.acceptOptIns))
+    ) {
+      logFinishedStep(
+        ctx,
+        "This device has previously been authorized and is ready for use with Convex.",
+      );
+      await handleLinkingDeployments(ctx, {
+        interactive: !!options.linkDeployments,
+      });
+      return;
+    }
+    if (!options.force && options.checkLogin) {
+      const isLoggedIn = await checkAuthorization(ctx, !!options.acceptOptIns);
+      if (!isLoggedIn) {
+        return ctx.crash({
+          exitCode: 1,
+          errorType: "fatal",
+          errForSentry: "You are not logged in.",
+          printedMessage: "You are not logged in.",
+        });
+      }
+    }
+    if (!!options.overrideAuthUsername !== !!options.overrideAuthPassword) {
+      cmd.error(
+        "If overriding credentials, both username and password must be provided",
+      );
+    }
+
+    const uuid = loadUuidForAnonymousUser(ctx);
+    await performLogin(ctx, {
+      ...options,
+      anonymousId: uuid,
+    });
+
+    await handleLinkingDeployments(ctx, {
+      interactive: !!options.linkDeployments,
+    });
+  });
+
+async function handleLinkingDeployments(
+  ctx: Context,
+  args: {
+    interactive: boolean;
+  },
+) {
+  if (!shouldAllowAnonymousDevelopment()) {
+    return;
+  }
+  const anonymousDeployments = await listExistingAnonymousDeployments(ctx);
+  if (anonymousDeployments.length === 0) {
+    if (args.interactive) {
+      logMessage(
+        ctx,
+        "It doesn't look like you have any deployments to link. You can run `npx convex dev` to set up a new project or select an existing one.",
+      );
+    }
+    return;
+  }
+
+  if (!args.interactive) {
+    const message = getMessage(
+      anonymousDeployments.map((d) => d.deploymentName),
+    );
+    const createProjects = await promptYesNo(ctx, {
+      message,
+      default: true,
+    });
+    if (!createProjects) {
+      logMessage(
+        ctx,
+        "Not linking your existing deployments. If you want to link them later, run `npx convex login --link-deployments`.",
+      );
+      logMessage(
+        ctx,
+        `Visit ${DASHBOARD_HOST} or run \`npx convex dev\` to get started with your new account.`,
+      );
+      return;
+    }
+
+    const { teamSlug } = await validateOrSelectTeam(
+      ctx,
+      undefined,
+      "Choose a team for your deployments:",
+    );
+    const projectsRemaining = await getProjectsRemaining(ctx, teamSlug);
+    if (anonymousDeployments.length > projectsRemaining) {
+      logFailure(
+        ctx,
+        `You have ${anonymousDeployments.length} deployments to link, but only have ${projectsRemaining} projects remaining. If you'd like to choose which ones to link, run this command with the --link-deployments flag.`,
+      );
+      return;
+    }
+
+    const deploymentSelection = await getDeploymentSelection(ctx, {
+      url: undefined,
+      adminKey: undefined,
+      envFile: undefined,
+    });
+    const configuredDeployment =
+      deploymentSelection.kind === "anonymous"
+        ? deploymentSelection.deploymentName
+        : null;
+
+    let dashboardUrl = teamDashboardUrl(teamSlug);
+
+    for (const deployment of anonymousDeployments) {
+      const linkedDeployment = await handleLinkToProject(ctx, {
+        deploymentName: deployment.deploymentName,
+        teamSlug,
+        projectSlug: null,
+      });
+      logFinishedStep(
+        ctx,
+        `Added ${deployment.deploymentName} to project ${linkedDeployment.projectSlug}`,
+      );
+      if (deployment.deploymentName === configuredDeployment) {
+        // If the current project has a `CONVEX_DEPLOYMENT` env var configured, replace
+        // it with the new value.
+        await updateEnvAndConfigForDeploymentSelection(
+          ctx,
+          {
+            url: linkedDeployment.deploymentUrl,
+            deploymentName: linkedDeployment.deploymentName,
+            teamSlug,
+            projectSlug: linkedDeployment.projectSlug,
+            deploymentType: "local",
+          },
+          configuredDeployment,
+        );
+        dashboardUrl = deploymentDashboardUrlPage(
+          linkedDeployment.deploymentName,
+          "",
+        );
+      }
+    }
+    logFinishedStep(
+      ctx,
+      `Sucessfully linked your deployments! Visit ${dashboardUrl} to get started.`,
+    );
+    return;
+  }
+
+  const deploymentSelection = await getDeploymentSelection(ctx, {
+    url: undefined,
+    adminKey: undefined,
+    envFile: undefined,
+  });
+  const configuredDeployment =
+    deploymentSelection.kind === "anonymous"
+      ? deploymentSelection.deploymentName
+      : null;
+  while (true) {
+    logMessage(
+      ctx,
+      getDeploymentListMessage(
+        anonymousDeployments.map((d) => d.deploymentName),
+      ),
+    );
+    const updatedAnonymousDeployments =
+      await listExistingAnonymousDeployments(ctx);
+    const deploymentToLink = await promptSearch(ctx, {
+      message: "Which deployment would you like to link to your account?",
+      choices: updatedAnonymousDeployments.map((d) => ({
+        name: d.deploymentName,
+        value: d.deploymentName,
+      })),
+    });
+    const { teamSlug } = await validateOrSelectTeam(
+      ctx,
+      undefined,
+      "Choose a team for your deployment:",
+    );
+    const { projectSlug } = await selectProject(ctx, "ask", {
+      team: teamSlug,
+      devDeployment: "local",
+      defaultProjectName: removeAnonymousPrefix(deploymentToLink),
+    });
+    const linkedDeployment = await handleLinkToProject(ctx, {
+      deploymentName: deploymentToLink,
+      teamSlug,
+      projectSlug,
+    });
+    logFinishedStep(
+      ctx,
+      `Added ${deploymentToLink} to project ${linkedDeployment.projectSlug}`,
+    );
+    if (deploymentToLink === configuredDeployment) {
+      await updateEnvAndConfigForDeploymentSelection(
+        ctx,
+        {
+          url: linkedDeployment.deploymentUrl,
+          deploymentName: linkedDeployment.deploymentName,
+          teamSlug,
+          projectSlug: linkedDeployment.projectSlug,
+          deploymentType: "local",
+        },
+        configuredDeployment,
+      );
+    }
+    const shouldContinue = await promptYesNo(ctx, {
+      message: "Would you like to link another deployment?",
+      default: true,
+    });
+    if (!shouldContinue) {
+      break;
+    }
+  }
+}
+
+async function getProjectsRemaining(ctx: Context, teamSlug: string) {
+  const response = await bigBrainAPI<{ projectsRemaining: number }>({
+    ctx,
+    method: "GET",
+    url: `/api/teams/${teamSlug}/projects_remaining`,
+  });
+
+  return response.projectsRemaining;
+}
+
+function getDeploymentListMessage(anonymousDeploymentNames: string[]) {
+  let message = `You have ${anonymousDeploymentNames.length} existing deployments.`;
+  message += `\n\nDeployments:`;
+  for (const deploymentName of anonymousDeploymentNames) {
+    message += `\n- ${deploymentName}`;
+  }
+  return message;
+}
+
+function getMessage(anonymousDeploymentNames: string[]) {
+  if (anonymousDeploymentNames.length === 1) {
+    return `Would you like to link your existing deployment to your account? ("${anonymousDeploymentNames[0]}")`;
+  }
+  let message = `You have ${anonymousDeploymentNames.length} existing deployments. Would you like to link them to your account?`;
+  message += `\n\nDeployments:`;
+  for (const deploymentName of anonymousDeploymentNames) {
+    message += `\n- ${deploymentName}`;
+  }
+  message += `\n\nYou can alternatively run \`npx convex login --link-deployments\` to interactively choose which deployments to add.`;
+  return message;
+}
diff --git a/synced/convex/libs/cli/logout.ts b/synced/convex/libs/cli/logout.ts
new file mode 100644
index 0000000..f762cdd
--- /dev/null
+++ b/synced/convex/libs/cli/logout.ts
@@ -0,0 +1,24 @@
+import { Command } from "@commander-js/extra-typings";
+import { logFinishedStep, oneoffContext } from "../bundler/context.js";
+import { recursivelyDelete } from "./lib/fsUtils.js";
+import { globalConfigPath } from "./lib/utils/globalConfig.js";
+
+export const logout = new Command("logout")
+  .description("Log out of Convex on this machine")
+  .allowExcessArguments(false)
+  .action(async () => {
+    const ctx = await oneoffContext({
+      url: undefined,
+      adminKey: undefined,
+      envFile: undefined,
+    });
+
+    if (ctx.fs.exists(globalConfigPath())) {
+      recursivelyDelete(ctx, globalConfigPath());
+    }
+
+    logFinishedStep(
+      ctx,
+      "You have been logged out of Convex.\n  Run `npx convex dev` to log in.",
+    );
+  });
diff --git a/synced/convex/libs/cli/logs.ts b/synced/convex/libs/cli/logs.ts
new file mode 100644
index 0000000..def1155
--- /dev/null
+++ b/synced/convex/libs/cli/logs.ts
@@ -0,0 +1,40 @@
+import { Command } from "@commander-js/extra-typings";
+import { oneoffContext } from "../bundler/context.js";
+import {
+  deploymentSelectionWithinProjectFromOptions,
+  loadSelectedDeploymentCredentials,
+} from "./lib/api.js";
+import { actionDescription } from "./lib/command.js";
+import { logsForDeployment } from "./lib/logs.js";
+import { getDeploymentSelection } from "./lib/deploymentSelection.js";
+
+export const logs = new Command("logs")
+  .summary("Watch logs from your deployment")
+  .description(
+    "Stream function logs from your Convex deployment.\nBy default, this streams from your project's dev deployment.",
+  )
+  .allowExcessArguments(false)
+  .addLogsOptions()
+  .addDeploymentSelectionOptions(actionDescription("Watch logs from"))
+  .showHelpAfterError()
+  .action(async (cmdOptions) => {
+    const ctx = await oneoffContext(cmdOptions);
+
+    const selectionWithinProject =
+      await deploymentSelectionWithinProjectFromOptions(ctx, cmdOptions);
+    const deploymentSelection = await getDeploymentSelection(ctx, cmdOptions);
+    const deployment = await loadSelectedDeploymentCredentials(
+      ctx,
+      deploymentSelection,
+      selectionWithinProject,
+    );
+    const deploymentName = deployment.deploymentFields?.deploymentName
+      ? ` ${deployment.deploymentFields.deploymentName}`
+      : "";
+    const deploymentNotice = ` for ${cmdOptions.prod ? "production" : "dev"} deployment${deploymentName}`;
+    await logsForDeployment(ctx, deployment, {
+      history: cmdOptions.history,
+      success: cmdOptions.success,
+      deploymentNotice,
+    });
+  });
diff --git a/synced/convex/libs/cli/mcp.ts b/synced/convex/libs/cli/mcp.ts
new file mode 100644
index 0000000..64ffa55
--- /dev/null
+++ b/synced/convex/libs/cli/mcp.ts
@@ -0,0 +1,171 @@
+import { Command } from "@commander-js/extra-typings";
+import { oneoffContext } from "../bundler/context.js";
+import { Server } from "@modelcontextprotocol/sdk/server/index.js";
+import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
+import { actionDescription } from "./lib/command.js";
+import { checkAuthorization } from "./lib/login.js";
+import {
+  CallToolRequest,
+  CallToolRequestSchema,
+  ListToolsRequestSchema,
+} from "@modelcontextprotocol/sdk/types.js";
+import {
+  McpOptions,
+  RequestContext,
+  RequestCrash,
+} from "./lib/mcp/requestContext.js";
+import { mcpTool, convexTools, ConvexTool } from "./lib/mcp/tools/index.js";
+import { Mutex } from "./lib/utils/mutex.js";
+import { initializeBigBrainAuth } from "./lib/deploymentSelection.js";
+
+const allToolNames = convexTools.map((t) => t.name).sort();
+
+export const mcp = new Command("mcp")
+  .summary("Manage the Model Context Protocol server for Convex [BETA]")
+  .description(
+    "Commands to initialize and run a Model Context Protocol server for Convex that can be used with AI tools.\n" +
+      "This server exposes your Convex codebase to AI tools in a structured way.",
+  )
+  .allowExcessArguments(false);
+
+mcp
+  .command("start")
+  .summary("Start the MCP server")
+  .description(
+    "Start the Model Context Protocol server for Convex that can be used with AI tools.",
+  )
+  .option(
+    "--project-dir <project-dir>",
+    "Run the MCP server for a single project. By default, the MCP server can run for multiple projects, and each tool call specifies its project directory.",
+  )
+  .option(
+    "--disable-tools <tool-names>",
+    `Comma separated list of tool names to disable (options: ${allToolNames.join(", ")})`,
+  )
+  .option(
+    "--disable-production-deployments",
+    "Disable the MCP server from accessing production deployments.",
+  )
+  .addDeploymentSelectionOptions(actionDescription("Run the MCP server on"))
+  .action(async (options) => {
+    const ctx = await oneoffContext(options);
+    try {
+      const server = makeServer(options);
+      const transport = new StdioServerTransport();
+      await server.connect(transport);
+      // Keep the process running
+      await new Promise(() => {});
+    } catch (error: any) {
+      await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        errForSentry: `Failed to start MCP server: ${error}`,
+        printedMessage: `Failed to start MCP server: ${error}`,
+      });
+    }
+  });
+
+function makeServer(options: McpOptions) {
+  const disabledToolNames = new Set<string>();
+  for (const toolName of options.disableTools?.split(",") ?? []) {
+    const name = toolName.trim();
+    if (!allToolNames.includes(name)) {
+      // eslint-disable-next-line no-restricted-syntax
+      throw new Error(
+        `Disabled tool ${name} not found (valid tools: ${allToolNames.join(", ")})`,
+      );
+    }
+    disabledToolNames.add(name);
+  }
+
+  const enabledToolsByName: Record<string, ConvexTool<any, any>> = {};
+  for (const tool of convexTools) {
+    if (!disabledToolNames.has(tool.name)) {
+      enabledToolsByName[tool.name] = tool;
+    }
+  }
+
+  const mutex = new Mutex();
+  const server = new Server(
+    {
+      name: "Convex MCP Server",
+      version: "0.0.1",
+    },
+    {
+      capabilities: {
+        tools: {},
+      },
+    },
+  );
+  server.setRequestHandler(
+    CallToolRequestSchema,
+    async (request: CallToolRequest) => {
+      const ctx = new RequestContext(options);
+      await initializeBigBrainAuth(ctx, options);
+      try {
+        const authorized = await checkAuthorization(ctx, false);
+        if (!authorized) {
+          await ctx.crash({
+            exitCode: 1,
+            errorType: "fatal",
+            printedMessage:
+              "Not Authorized: Run `npx convex dev` to login to your Convex project.",
+          });
+        }
+        if (!request.params.arguments) {
+          await ctx.crash({
+            exitCode: 1,
+            errorType: "fatal",
+            printedMessage: "No arguments provided",
+          });
+        }
+        const convexTool = enabledToolsByName[request.params.name];
+        if (!convexTool) {
+          await ctx.crash({
+            exitCode: 1,
+            errorType: "fatal",
+            printedMessage: `Tool ${request.params.name} not found`,
+          });
+        }
+        const input = convexTool.inputSchema.parse(request.params.arguments);
+
+        // Serialize tool handlers since they're mutating the current working directory.
+        const result = await mutex.runExclusive(async () => {
+          return await convexTool.handler(ctx, input);
+        });
+        return {
+          content: [
+            {
+              type: "text",
+              text: JSON.stringify(result),
+            },
+          ],
+        };
+      } catch (error: any) {
+        let message: string;
+        if (error instanceof RequestCrash) {
+          message = error.printedMessage;
+        } else if (error instanceof Error) {
+          message = error.message;
+        } else {
+          message = String(error);
+        }
+        return {
+          content: [
+            {
+              type: "text",
+              text: JSON.stringify({ error: message }),
+            },
+          ],
+          isError: true,
+        };
+      }
+    },
+  );
+  server.setRequestHandler(ListToolsRequestSchema, async () => {
+    return {
+      tools: Object.values(enabledToolsByName).map(mcpTool),
+    };
+  });
+  return server;
+}
diff --git a/synced/convex/libs/cli/network_test.ts b/synced/convex/libs/cli/network_test.ts
new file mode 100644
index 0000000..d5c9430
--- /dev/null
+++ b/synced/convex/libs/cli/network_test.ts
@@ -0,0 +1,75 @@
+import { Command } from "@commander-js/extra-typings";
+import {
+  deploymentSelectionWithinProjectFromOptions,
+  loadSelectedDeploymentCredentials,
+} from "./lib/api.js";
+import {
+  Context,
+  oneoffContext,
+  showSpinner,
+  logMessage,
+} from "../bundler/context.js";
+import chalk from "chalk";
+import { actionDescription } from "./lib/command.js";
+import { runNetworkTestOnUrl, withTimeout } from "./lib/networkTest.js";
+import { getDeploymentSelection } from "./lib/deploymentSelection.js";
+
+export const networkTest = new Command("network-test")
+  .description("Run a network test to Convex's servers")
+  .allowExcessArguments(false)
+  .addNetworkTestOptions()
+  .addDeploymentSelectionOptions(
+    actionDescription("Perform the network test on"),
+  )
+  .option("--url <url>") // unhide help
+  .action(async (options) => {
+    const ctx = await oneoffContext(options);
+    const timeoutSeconds = options.timeout
+      ? Number.parseFloat(options.timeout)
+      : 30;
+    await withTimeout(
+      ctx,
+      "Network test",
+      timeoutSeconds * 1000,
+      runNetworkTest(ctx, options),
+    );
+  });
+
+async function runNetworkTest(
+  ctx: Context,
+  options: {
+    prod?: boolean | undefined;
+    previewName?: string | undefined;
+    deploymentName?: string | undefined;
+    url?: string | undefined;
+    adminKey?: string | undefined;
+    ipFamily?: string;
+    speedTest?: boolean;
+  },
+) {
+  showSpinner(ctx, "Performing network test...");
+  // Try to fetch the URL following the usual paths, but special case the
+  // `--url` argument in case the developer doesn't have network connectivity.
+  let url: string;
+  let adminKey: string | null;
+  if (options.url !== undefined && options.adminKey !== undefined) {
+    url = options.url;
+    adminKey = options.adminKey;
+  } else if (options.url !== undefined) {
+    url = options.url;
+    adminKey = null;
+  } else {
+    const selectionWithinProject =
+      await deploymentSelectionWithinProjectFromOptions(ctx, options);
+    const deploymentSelection = await getDeploymentSelection(ctx, options);
+    const credentials = await loadSelectedDeploymentCredentials(
+      ctx,
+      deploymentSelection,
+      selectionWithinProject,
+    );
+    url = credentials.url;
+    adminKey = credentials.adminKey;
+  }
+  logMessage(ctx, `${chalk.green(``)} Deployment URL: ${url}`);
+  await runNetworkTestOnUrl(ctx, { url, adminKey }, options);
+}
diff --git a/synced/convex/libs/cli/reinit.ts b/synced/convex/libs/cli/reinit.ts
new file mode 100644
index 0000000..d6b4af7
--- /dev/null
+++ b/synced/convex/libs/cli/reinit.ts
@@ -0,0 +1,39 @@
+import { Command, Option } from "@commander-js/extra-typings";
+import { oneoffContext } from "../bundler/context.js";
+
+// Reinitialize an existing Convex project.
+// This command is deprecated and hidden from the command help.
+// `npx convex dev --once --configure=existing` replaces it.
+export const reinit = new Command("reinit")
+  .description(
+    "Reinitialize a Convex project in the local directory if you've lost your convex.json file",
+  )
+  .allowExcessArguments(false)
+  .addOption(
+    new Option(
+      "--team <team_slug>",
+      "The identifier of the team the project belongs to.",
+    ),
+  )
+  .addOption(
+    new Option(
+      "--project <project_slug>",
+      "The identifier of the project you'd like to reinitialize.",
+    ),
+  )
+  .action(async (_options) => {
+    return (
+      await oneoffContext({
+        url: undefined,
+        adminKey: undefined,
+        envFile: undefined,
+      })
+    ).crash({
+      exitCode: 1,
+      errorType: "fatal",
+      errForSentry:
+        "The `reinit` command is deprecated. Use `npx convex dev --once --configure=existing` instead.",
+      printedMessage:
+        "The `reinit` command is deprecated. Use `npx convex dev --once --configure=existing` instead.",
+    });
+  });
diff --git a/synced/convex/libs/cli/run.ts b/synced/convex/libs/cli/run.ts
new file mode 100644
index 0000000..1e2b052
--- /dev/null
+++ b/synced/convex/libs/cli/run.ts
@@ -0,0 +1,58 @@
+import { Command } from "@commander-js/extra-typings";
+import { oneoffContext } from "../bundler/context.js";
+import {
+  deploymentSelectionWithinProjectFromOptions,
+  loadSelectedDeploymentCredentials,
+} from "./lib/api.js";
+import { actionDescription } from "./lib/command.js";
+import { runInDeployment } from "./lib/run.js";
+import { ensureHasConvexDependency } from "./lib/utils/utils.js";
+import { getDeploymentSelection } from "./lib/deploymentSelection.js";
+
+export const run = new Command("run")
+  .description("Run a function (query, mutation, or action) on your deployment")
+  .allowExcessArguments(false)
+  .addRunOptions()
+  .addDeploymentSelectionOptions(actionDescription("Run the function on"))
+  .showHelpAfterError()
+  .action(async (functionName, argsString, options) => {
+    const ctx = await oneoffContext(options);
+    await ensureHasConvexDependency(ctx, "run");
+    const selectionWithinProject =
+      await deploymentSelectionWithinProjectFromOptions(ctx, options);
+    const deploymentSelection = await getDeploymentSelection(ctx, options);
+    const deployment = await loadSelectedDeploymentCredentials(
+      ctx,
+      deploymentSelection,
+      selectionWithinProject,
+    );
+
+    if (
+      deployment.deploymentFields?.deploymentType === "prod" &&
+      options.push
+    ) {
+      return await ctx.crash({
+        exitCode: 1,
+        errorType: "fatal",
+        printedMessage:
+          `\`convex run\` doesn't support pushing functions to prod deployments. ` +
+          `Remove the --push flag. To push to production use \`npx convex deploy\`.`,
+      });
+    }
+
+    await runInDeployment(ctx, {
+      deploymentUrl: deployment.url,
+      adminKey: deployment.adminKey,
+      deploymentName: deployment.deploymentFields?.deploymentName ?? null,
+      functionName,
+      argsString: argsString ?? "{}",
+      componentPath: options.component,
+      identityString: options.identity,
+      push: !!options.push,
+      watch: !!options.watch,
+      typecheck: options.typecheck,
+      typecheckComponents: options.typecheckComponents,
+      codegen: options.codegen === "enable",
+      liveComponentSources: !!options.liveComponentSources,
+    });
+  });
diff --git a/synced/convex/libs/cli/typecheck.ts b/synced/convex/libs/cli/typecheck.ts
new file mode 100644
index 0000000..fd63e08
--- /dev/null
+++ b/synced/convex/libs/cli/typecheck.ts
@@ -0,0 +1,69 @@
+import chalk from "chalk";
+import { functionsDir, ensureHasConvexDependency } from "./lib/utils/utils.js";
+import { Command } from "@commander-js/extra-typings";
+import { readConfig } from "./lib/config.js";
+import { typeCheckFunctions } from "./lib/typecheck.js";
+import {
+  logFinishedStep,
+  logMessage,
+  oneoffContext,
+} from "../bundler/context.js";
+
+// Experimental (it's going to fail sometimes) TypeScript type checking.
+// Includes a separate command to help users debug their TypeScript configs.
+
+export type TypecheckResult = "cantTypeCheck" | "success" | "typecheckFailed";
+
+/** Run the TypeScript compiler, as configured during  */
+export const typecheck = new Command("typecheck")
+  .description(
+    "Run TypeScript typechecking on your Convex functions with `tsc --noEmit`.",
+  )
+  .allowExcessArguments(false)
+  .action(async () => {
+    const ctx = await oneoffContext({
+      url: undefined,
+      adminKey: undefined,
+      envFile: undefined,
+    });
+    const { configPath, config: localConfig } = await readConfig(ctx, false);
+    await ensureHasConvexDependency(ctx, "typecheck");
+    await typeCheckFunctions(
+      ctx,
+      functionsDir(configPath, localConfig.projectConfig),
+      async (typecheckResult, logSpecificError, runOnError) => {
+        logSpecificError?.();
+        if (typecheckResult === "typecheckFailed") {
+          logMessage(ctx, chalk.gray("Typecheck failed"));
+          try {
+            await runOnError?.();
+            // If runOnError doesn't throw then it worked the second time.
+            // No errors to report, but it's still a failure.
+          } catch {
+            // As expected, `runOnError` threw
+          }
+          return await ctx.crash({
+            exitCode: 1,
+            errorType: "invalid filesystem data",
+            printedMessage: null,
+          });
+        } else if (typecheckResult === "cantTypeCheck") {
+          logMessage(
+            ctx,
+            chalk.gray("Unable to typecheck; is TypeScript installed?"),
+          );
+          return await ctx.crash({
+            exitCode: 1,
+            errorType: "invalid filesystem data",
+            printedMessage: null,
+          });
+        } else {
+          logFinishedStep(
+            ctx,
+            "Typecheck passed: `tsc --noEmit` completed with exit code 0.",
+          );
+          return await ctx.flushAndExit(0);
+        }
+      },
+    );
+  });
diff --git a/synced/convex/libs/cli/update.ts b/synced/convex/libs/cli/update.ts
new file mode 100644
index 0000000..196ba09
--- /dev/null
+++ b/synced/convex/libs/cli/update.ts
@@ -0,0 +1,30 @@
+import chalk from "chalk";
+import { Command } from "@commander-js/extra-typings";
+import { logMessage, oneoffContext } from "../bundler/context.js";
+import { loadPackageJson } from "./lib/utils/utils.js";
+
+export const update = new Command("update")
+  .description("Print instructions for updating the convex package")
+  .allowExcessArguments(false)
+  .action(async () => {
+    const ctx = await oneoffContext({
+      url: undefined,
+      adminKey: undefined,
+      envFile: undefined,
+    });
+    let updateInstructions = "npm install convex@latest\n";
+    const packages = await loadPackageJson(ctx);
+    const oldPackageNames = Object.keys(packages).filter((name) =>
+      name.startsWith("@convex-dev"),
+    );
+    for (const pkg of oldPackageNames) {
+      updateInstructions += `npm uninstall ${pkg}\n`;
+    }
+
+    logMessage(
+      ctx,
+      chalk.green(
+        `To view the Convex changelog, go to https://news.convex.dev/tag/releases/\nWhen you are ready to upgrade, run the following commands:\n${updateInstructions}`,
+      ),
+    );
+  });
diff --git a/synced/convex/libs/cli/version.ts b/synced/convex/libs/cli/version.ts
new file mode 100644
index 0000000..74922b7
--- /dev/null
+++ b/synced/convex/libs/cli/version.ts
@@ -0,0 +1,3 @@
+import { version as versionInner } from "../index.js";
+
+export const version = process.env.CONVEX_VERSION_OVERRIDE || versionInner;
